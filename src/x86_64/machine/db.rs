use super::instructions::INSTRUCTION_COUNT;

pub const OPERAND_COUNT_TABLE: [u8; INSTRUCTION_COUNT] = [
    0, 0, 1, 0, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 4, 4, 4, 2, 2, 3, 4, 4, 5,
    2, 3, 4, 2, 2, 3, 2, 3, 3, 2, 3, 3, 2, 2, 2, 3, 2, 3, 2, 3, 2, 3, 2, 2, 3, 3, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2, 3, 3, 4, 4, 4, 2, 3, 3, 4, 4, 4, 2, 3,
    3, 4, 4, 4, 2, 2, 3, 4, 4, 4, 2, 3, 3, 3, 4, 4, 3, 4, 4, 3, 4, 4, 3, 4, 4, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,
    0, 1, 1, 0, 0, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 3, 4, 4, 5, 5, 5, 3, 4, 4, 5, 5, 5, 2, 2, 2, 2, 0, 0,
    0, 0, 3, 4, 5, 3, 4, 5, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3,
    3, 3, 2, 2, 2, 3, 3, 3, 2, 2, 2, 3, 3, 3, 2, 2, 2, 2, 3, 3, 3, 2, 2, 2, 2, 2, 3, 3, 3, 2, 2, 2,
    3, 3, 3, 2, 1, 1, 1, 1, 1, 1, 2, 2, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 4, 1, 1, 1, 1,
    1, 1, 2, 2, 2, 3, 3, 3, 2, 2, 2, 2, 3, 3, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,
    0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 4, 4, 4, 2, 3, 3, 4, 4, 4, 2, 3, 4, 2, 3, 4, 3,
    3, 3, 3, 4, 0, 2, 1, 2, 3, 3, 3, 0, 0, 1, 1, 2, 2, 2, 0, 1, 1, 1, 1, 0, 0, 0, 2, 2, 2, 2, 2, 2,
    2, 2, 1, 1, 1, 0, 1, 1, 1, 0, 0, 2, 2, 2, 2, 0, 0, 1, 1, 2, 2, 2, 0, 1, 1, 1, 1, 2, 2, 2, 0, 1,
    1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,
    1, 1, 1, 2, 2, 2, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 0, 1, 1, 1, 1, 2, 2, 2, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1,
    1, 1, 0, 0, 0, 2, 2, 3, 2, 3, 3, 0, 2, 2, 3, 2, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3,
    3, 3, 3, 3, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 0, 0, 0, 3, 4, 4, 1, 0, 0, 1, 2, 2,
    0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 3, 3,
    3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    1, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2,
    2, 2, 3, 3, 4, 4, 4, 2, 3, 3, 4, 4, 4, 2, 3, 4, 2, 3, 4, 0, 2, 3, 3, 4, 4, 4, 2, 3, 3, 4, 4, 4,
    2, 3, 4, 1, 2, 4, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 2,
    2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    1, 2, 2, 2, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2, 3, 3, 2, 2,
    2, 2, 3, 3, 2, 2, 2, 2, 3, 3, 1, 1, 1, 1, 1, 1, 2, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 0, 0, 0, 0, 2, 2, 2, 3, 2, 3, 2, 4, 3, 4, 3, 2, 2, 2, 3, 3, 3, 2, 2, 2, 3, 3, 3, 2,
    2, 3, 2, 2, 3, 2, 4, 3, 4, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2,
    2, 2, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 3, 4, 4, 1, 1, 1, 1, 1, 2, 2, 3, 4, 4, 4, 2, 2, 3, 4, 4,
    5, 1, 2, 5, 1, 2, 5, 3, 3, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 4, 4, 4, 2, 2, 3, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 3, 3, 4, 4, 4,
    4, 2, 2, 3, 3, 3, 2, 2, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4,
    4, 4, 4, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3,
    3, 4, 4, 5, 5, 5, 2, 2, 3, 3, 4, 4, 4, 4, 4, 4, 2, 2, 3, 3, 4, 4, 4, 4, 4, 4, 0, 2, 2, 2, 2, 3,
    3, 3, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 3, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 3, 3, 4, 4, 4, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 1, 3, 3, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3,
    3, 3, 3, 2, 2, 3, 3, 2, 2, 2, 2, 3, 3, 3, 3, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2, 3, 3, 3, 3, 1, 1, 1,
    1, 1, 1, 1, 1, 1, 3, 3, 4, 4, 2, 2, 3, 3, 4, 4, 4, 2, 2, 3, 3, 4, 4, 4, 2, 2, 2, 2, 3, 3, 3, 3,
    3, 3, 3, 3, 3, 3, 3, 3, 4, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 4, 4, 4, 4, 4, 4, 2,
    2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 4, 4, 4, 4, 4, 4, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 3,
    3, 3, 2, 3, 3, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 4, 4, 4, 2, 2, 3, 3, 4, 4,
    4, 2, 2, 3, 3, 4, 4, 4, 2, 2, 3, 3, 4, 4, 4, 2, 3, 3, 4, 4, 4, 4, 4, 4, 2, 2, 3, 3, 4, 4, 4, 2,
    2, 3, 3, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 2, 2, 2, 0, 0, 0, 2, 2, 3,
    3, 4, 4, 4, 4, 4, 4, 1, 1, 1, 1, 1, 1, 2, 2, 3, 3, 3, 3, 3, 2, 2, 3, 3, 4, 4, 4, 3, 3, 3, 4, 4,
    4, 3, 3, 3, 4, 4, 4, 3, 3, 3, 4, 4, 4, 3, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 2, 3, 3, 2, 3, 3,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,
    4, 4, 4, 4, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3,
    3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3,
    3, 3, 4, 4, 4, 4, 4, 4, 2, 2, 3, 3, 4, 4, 4, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 4, 2, 2, 2, 2,
    3, 3, 3, 3, 4, 4, 4, 4, 4, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4, 4,
    4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    1, 1, 1, 0, 0, 0, 0, 0, 2, 2, 3, 3, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1,
    1, 1, 0, 0, 0, 0, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 4, 0, 2, 2, 2, 2, 3, 0, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1,
    2, 2, 1, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1,
    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    1, 1, 0, 1, 2, 2, 2, 3, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 3, 4, 4,
    4, 4, 4, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 2, 2, 2, 3, 3, 3, 1, 2, 4, 2, 3, 4, 0, 0, 0, 0, 1,
    1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 3, 4, 4, 4, 2, 2, 3, 4, 4, 4, 2, 2, 4, 2, 2, 4, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 4, 4, 4, 2, 3, 3, 4, 4, 4, 2,
    2, 2, 4, 4, 4, 2, 2, 1, 4, 4, 4, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 3, 3,
    3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 3, 3, 4, 3, 3, 4, 4,
    4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
    3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 5, 5, 5, 1, 1, 4,
    4, 3, 3, 3, 3, 3, 3, 3, 4, 4, 3, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,
    4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 4, 4, 4, 3, 3, 3, 4, 4, 4, 1,
    1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3,
    3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 4, 4,
    4, 3, 3, 3, 4, 4, 4, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4,
    4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4,
    4, 4, 4, 3, 3, 3, 4, 4, 4, 3, 3, 3, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3,
    3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 4, 4, 4, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
    4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3,
    3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4,
    4, 4, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 3, 4, 4, 4, 4,
    4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 4, 4, 4, 3, 3, 4, 4, 4, 3, 3, 3, 3, 4, 4,
    4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
    3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
    3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
    3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
    3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4,
    4, 4, 4, 4, 4, 4, 4, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5,
    5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 5, 5,
    5, 5, 5, 5, 5, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 4, 4, 4, 4, 4, 4, 5, 5, 4, 4, 4, 4, 4, 4, 5,
    5, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
    3, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 2, 2, 2, 2, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 2,
    2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 1, 0, 0, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 4, 4, 4, 2, 2, 3, 4, 4, 4, 1, 1, 1,
    1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,
];

/// Each bit corresponds to one instruction.
/// If the bit 1 is the instruction is available in 64-bit long mode.
pub const X64_FLAG_TABLE: [u128; INSTRUCTION_COUNT / 128 + 1] = [
        0b00000011111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111,
        0b11111111110111111111111111111110101011010101100111111111111111111111111111111111101001001111111111111111111111111111111111111111,
        0b11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111,
        0b11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111001111100111111111111111111111111,
        0b11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111,
        0b11111111111111111111111111111111111111111111111111111111111111111111111111111110011111111110110111111111011111111111111111111111,
        0b11110101010101010101010101010101010101010101010101010101010101010100100111111111111111111111111111111111111111111111111111111111,
        0b11111111101111111001110011111111110110011111111111111111111111111111111111111111111111111111111111111111111111111111111111111111,
        0b11111111101101101011111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111,
        0b11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111,
        0b11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111,
        0b11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111,
        0b11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111,
        0b11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111,
        0b11111111111111111111111111111111111111111111111111111111111111111111111011010001011010011110111111111111111111111111111111111111,
        0b11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111,
        0b11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111101101111000,
        0b01100101111111111111111111111111111111111111111111111111111111111111111111111111111111110111111111111111111111111111111111011111,
        0b11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111,
        0b11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111,
        0b11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111,
        0b11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111,
        0b11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111,
        0b11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111,
        0b11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111,
        0b11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111,
        0b11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111,
        0b11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111,
        0b11111111111000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000
];

/// Each bit corresponds to one instruction.
/// If the bit 1 is the instruction is available in 32-bit protected mode.
pub const X32_FLAG_TABLE: [u128; INSTRUCTION_COUNT / 128 + 1] = [
        0b11111111101011011010110101101011101011011010110101101111111111111111111111111011111111111111101011011010110101101011111111111111,
        0b11111111110101111111111111010101010101101010111110110101101101101101101101101101011110111101101111111111101101101101101101101101,
        0b10110110110110110110110110110110110110110110110110110110111010110110101101011011111111111111101110111111101101011111111011001111,
        0b11111111111111111111111111111111111110101011110101010101011110101011111111111111101010101010110111011011101101111111111111111111,
        0b11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111,
        0b11111111111111111111111111111110101111111111111111101101110110110110111111101101111111111111111011011111110111111111111111111111,
        0b11111111111111111111111111111111111111111111111111111111111111111111011110111111111111111111111101110111111111111111111111111111,
        0b11111111111111111111101111011011011011100111111011101111101110111111111111111111111111111111111111111111011010110101010110101101,
        0b01101011010010010101111111111111111111111111101101010101010101010111111111111111111111111111111111111111111111111111111111111111,
        0b11111111111111111111111111111111111111111011111111111111111111111110111011111111111111111111111111111111111101001111111111111111,
        0b11111111110101111011011111111111111111110110110111101101110101101101011010110111111111111111111111111111111111111111111111111111,
        0b11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111,
        0b11111111111111111111111111111111111111111111111101011011111011111111111111111111111111111111111011011011111111111111111111111111,
        0b11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111,
        0b11111111111111111111111111111111111111111111111111111111111111111111111101101111101101111011011111111111111111111111111111111111,
        0b11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111,
        0b11111111111111111111111111111111111111111111111111111111111111111111111111110111111111111111111111111111111111111111110110111111,
        0b11111110111111111110101011110101010101011110101010101011110101010101011110101011111000011011110110111111101111111111111111110101,
        0b01111010101010101111010101010101111010101010101111010101110001110101101101011010110111011101010101010101010101010101010101010101,
        0b01111111111111010111010111111111111110110111111111111111111111111111011101111010110110101101011011111111111111111100110001110101,
        0b10101101101111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111010111111111111,
        0b11111110101111111111111010111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111,
        0b11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111,
        0b11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111,
        0b11111111111100011111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111,
        0b11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111,
        0b11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111,
        0b11111111111111111111111111111111111111111111111111111100001111110110111110101010111010111101110101101101011010110111111111111101,
        0b01010111011000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000
];

/// Each bit corresponds to one instruction.
/// If the bit 1 is the instruction is available in 16-bit real mode.
pub const X16_FLAG_TABLE: [u128; INSTRUCTION_COUNT / 128 + 1] = [
        0b11111111101011011010110101100011101011011010110101100000000000000000000000000000000000000011101011011010110101100000000000000000,
        0b00000000000000000000000000000000000000000000011110110101101101101101101101101100010100101001100111111011101101101101101101101101,
        0b10110110110110110110110110110110110110110110110110110110111010110110101101011000000000000011101110000000101101000000011011000000,
        0b00000000000000100000011000000000000100000000000000000000000000000000000010000001000000000000110111011011101100000000000000000000,
        0b00001111000111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111,
        0b11111111111111111111111111111110101110000001000000101101110110110110111111101101111111100011110011011111110111111111111111111111,
        0b11111111111111111111111111111111111111111111111111111111111111111010010100000000000000000000000000000000000000000000000000000000,
        0b00000000011100000101001010010011011011100111111011101111101110001000000000000000000100000000000000000011011010110101010110101101,
        0b01101011010010010100000000000000000000000001101100000000000000000000000100000000000000000000000000000000000000000000000000000000,
        0b00000000000000000000000000000000000000001000000000000010000000011110111000000000000000000000000000000000001101000000000000000000,
        0b00000000110100001011000000000000000000000110110111101101110101101101011010110000000000000111111111111000000000000000000000000000,
        0b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000010000000000000000000000000000000000000,
        0b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000,
        0b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000,
        0b00000000000000000000000000000000000000000000000000000000000000000000001101101111101101111011000000000001111000000000000000000000,
        0b00000000000001000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000,
        0b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000110110111111,
        0b11111110000000000010101011110101010101011110101010101011110101010101011110101000000000010011000000111111000000000000100000110101,
        0b01111010101010101111010101010101111010101010101111010100000001110101101101011010110111011101010101010101010101010101010101010101,
        0b01110000000111010111010000000000000110110000000000000000000011100111011101111010110110101101011000000000000000000000110001110101,
        0b10101100000000001110000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000,
        0b00000000000000000000000000000110000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000,
        0b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000,
        0b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000,
        0b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000,
        0b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000,
        0b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000,
        0b00000000000000000000000000000000000000000000000000011100001100010110001110101010111010011101110101101101011010110000000000000101,
        0b01010001010000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000
];

pub const DESCRIPTION_TABLE: [&str; INSTRUCTION_COUNT] = [
    "ASCII adjust AL after addition.",
    "ASCII adjust AX before division.",
    "Adjust AX before division to number base imm8.",
    "ASCII adjust AX after multiply.",
    "Adjust AX after multiply to number base imm8.",
    "ASCII adjust AL after subtraction.",
    "Add with carry imm8 to AL.",
    "Add with carry imm16 to AX.",
    "Add with carry imm32 to EAX.",
    "Add with carry imm32 sign extended to 64- bits to RAX.",
    "Add with carry imm8 to r/m8.",
    "Add with carry imm8 to r/m8.",
    "Add with carry imm16 to r/m16.",
    "Add with CF imm32 to r/m32.",
    "Add with CF imm32 sign extended to 64-bits to r/m64.",
    "Add with CF sign-extended imm8 to r/m16.",
    "Add with CF sign-extended imm8 into r/m32.",
    "Add with CF sign-extended imm8 into r/m64.",
    "Add with carry byte register to r/m8.",
    "Add with carry byte register to r/m64.",
    "Add with carry r16 to r/m16.",
    "Add with CF r32 to r/m32.",
    "Add with CF r64 to r/m64.",
    "Add with carry r/m8 to byte register.",
    "Add with carry r/m64 to byte register.",
    "Add with carry r/m16 to r16.",
    "Add with CF r/m32 to r32.",
    "Add with CF r/m64 to r64.",
    "Unsigned addition of r32 with CF, r/m32 to r32, writes CF.",
    "Unsigned addition of r64 with CF, r/m64 to r64, writes CF.",
    "Add imm8 to AL.",
    "Add imm16 to AX.",
    "Add imm32 to EAX.",
    "Add imm32 sign-extended to 64-bits to RAX.",
    "Add imm8 to r/m8.",
    "Add sign-extended imm8 to r/m8.",
    "Add imm16 to r/m16.",
    "Add imm32 to r/m32.",
    "Add imm32 sign-extended to 64-bits to r/m64.",
    "Add sign-extended imm8 to r/m16.",
    "Add sign-extended imm8 to r/m32.",
    "Add sign-extended imm8 to r/m64.",
    "Add r8 to r/m8.",
    "Add r8 to r/m8.",
    "Add r16 to r/m16.",
    "Add r32 to r/m32.",
    "Add r64 to r/m64.",
    "Add r/m8 to r8.",
    "Add r/m8 to r8.",
    "Add r/m16 to r16.",
    "Add r/m32 to r32.",
    "Add r/m64 to r64.",
    "Add packed double-precision floating-point values from xmm2/mem to xmm1 and store result in xmm1.",
    "Add packed double-precision floating-point values from xmm3/mem to xmm2 and store result in xmm1.",
    "Add packed double-precision floating-point values from ymm3/mem to ymm2 and store result in ymm1.",
    "Add packed double-precision floating-point values from xmm3/m128/m64bcst to xmm2 and store result in xmm1 with writemask k1.",
    "Add packed double-precision floating-point values from ymm3/m256/m64bcst to ymm2 and store result in ymm1 with writemask k1.",
    "Add packed double-precision floating-point values from zmm3/m512/m64bcst to zmm2 and store result in zmm1 with writemask k1.",
    "Add packed single-precision floating-point values from xmm2/m128 to xmm1 and store result in xmm1.",
    "Add packed single-precision floating-point values from xmm3/m128 to xmm2 and store result in xmm1.",
    "Add packed single-precision floating-point values from ymm3/m256 to ymm2 and store result in ymm1.",
    "Add packed single-precision floating-point values from xmm3/m128/m32bcst to xmm2 and store result in xmm1 with writemask k1.",
    "Add packed single-precision floating-point values from ymm3/m256/m32bcst to ymm2 and store result in ymm1 with writemask k1.",
    "Add packed single-precision floating-point values from zmm3/m512/m32bcst to zmm2 and store result in zmm1 with writemask k1.",
    "Add the low double-precision floating-point value from xmm2/mem to xmm1 and store the result in xmm1.",
    "Add the low double-precision floating-point value from xmm3/mem to xmm2 and store the result in xmm1.",
    "Add the low double-precision floating-point value from xmm3/m64 to xmm2 and store the result in xmm1 with writemask k1.",
    "Add the low single-precision floating-point value from xmm2/mem to xmm1 and store the result in xmm1.",
    "Add the low single-precision floating-point value from xmm3/mem to xmm2 and store the result in xmm1.",
    "Add the low single-precision floating-point value from xmm3/m32 to xmm2 and store the result in xmm1with writemask k1.",
    "Add/subtract double-precision floating-point values from xmm2/m128 to xmm1.",
    "Add/subtract packed double-precision floating-point values from xmm3/mem to xmm2 and stores result in xmm1.",
    "Add / subtract packed double-precision floating-point values from ymm3/mem to ymm2 and stores result in ymm1.",
    "Add/subtract single-precision floating-point values from xmm2/m128 to xmm1.",
    "Add/subtract single-precision floating-point values from xmm3/mem to xmm2 and stores result in xmm1.",
    "Add / subtract single-precision floating-point values from ymm3/mem to ymm2 and stores result in ymm1.",
    "Unsigned addition of r32 with OF, r/m32 to r32, writes OF.",
    "Unsigned addition of r64 with OF, r/m64 to r64, writes OF.",
    "Perform one round of an AES decryption flow, using the Equivalent Inverse Cipher, operating on a 128-bit data (state) from xmm1 with a 128-bit round key from xmm2/m128.",
    "Perform one round of an AES decryption flow, using the Equivalent Inverse Cipher, operating on a 128-bit data (state) from xmm2 with a 128-bit round key from xmm3/m128; store the result in xmm1.",
    "Perform the last round of an AES decryption flow, using the Equivalent Inverse Cipher, operating on a 128-bit data (state) from xmm1 with a 128-bit round key from xmm2/m128.",
    "Perform the last round of an AES decryption flow, using the Equivalent Inverse Cipher, operating on a 128-bit data (state) from xmm2 with a 128-bit round key from xmm3/m128; store the result in xmm1.",
    "Perform one round of an AES encryption flow, operating on a 128-bit data (state) from xmm1 with a 128-bit round key from xmm2/m128.",
    "Perform one round of an AES encryption flow, operating on a 128-bit data (state) from xmm2 with a 128-bit round key from the xmm3/m128; store the result in xmm1.",
    "Perform the last round of an AES encryption flow, operating on a 128-bit data (state) from xmm1 with a 128-bit round key from xmm2/m128.",
    "Perform the last round of an AES encryption flow, operating on a 128-bit data (state) from xmm2 with a 128 bit round key from xmm3/m128; store the result in xmm1.",
    "Perform the InvMixColumn transformation on a 128-bit round key from xmm2/m128 and store the result in xmm1.",
    "Perform the InvMixColumn transformation on a 128-bit round key from xmm2/m128 and store the result in xmm1.",
    "Assist in AES round key generation using an 8 bits Round Constant (RCON) specified in the immediate byte, operating on 128 bits of data specified in xmm2/m128 and stores the result in xmm1.",
    "Assist in AES round key generation using 8 bits Round Constant (RCON) specified in the immediate byte, operating on 128 bits of data specified in xmm2/m128 and stores the result in xmm1.",
    "AL AND imm8.",
    "AX AND imm16.",
    "EAX AND imm32.",
    "RAX AND imm32 sign-extended to 64-bits.",
    "r/m8 AND imm8.",
    "r/m8 AND imm8.",
    "r/m16 AND imm16.",
    "r/m32 AND imm32.",
    "r/m64 AND imm32 sign extended to 64-bits.",
    "r/m16 AND imm8 (sign-extended).",
    "r/m32 AND imm8 (sign-extended).",
    "r/m64 AND imm8 (sign-extended).",
    "r/m8 AND r8.",
    "r/m64 AND r8 (sign-extended).",
    "r/m16 AND r16.",
    "r/m32 AND r32.",
    "r/m64 AND r32.",
    "r8 AND r/m8.",
    "r/m64 AND r8 (sign-extended).",
    "r16 AND r/m16.",
    "r32 AND r/m32.",
    "r64 AND r/m64.",
    "Bitwise AND of inverted r32b with r/m32, store result in r32a.",
    "Bitwise AND of inverted r64b with r/m64, store result in r64a.",
    "Return the bitwise logical AND NOT of packed double-precision floating-point values in xmm1 and xmm2/mem.",
    "Return the bitwise logical AND NOT of packed double-precision floating-point values in xmm2 and xmm3/mem.",
    "Return the bitwise logical AND NOT of packed double-precision floating-point values in ymm2 and ymm3/mem.",
    "Return the bitwise logical AND NOT of packed double-precision floating-point values in xmm2 and xmm3/m128/m64bcst subject to writemask k1.",
    "Return the bitwise logical AND NOT of packed double-precision floating-point values in ymm2 and ymm3/m256/m64bcst subject to writemask k1.",
    "Return the bitwise logical AND NOT of packed double-precision floating-point values in zmm2 and zmm3/m512/m64bcst subject to writemask k1.",
    "Return the bitwise logical AND NOT of packed single-precision floating-point values in xmm1 and xmm2/mem.",
    "Return the bitwise logical AND NOT of packed single-precision floating-point values in xmm2 and xmm3/mem.",
    "Return the bitwise logical AND NOT of packed single-precision floating-point values in ymm2 and ymm3/mem.",
    "Return the bitwise logical AND of packed single-precision floating-point values in xmm2 and xmm3/m128/m32bcst subject to writemask k1.",
    "Return the bitwise logical AND of packed single-precision floating-point values in ymm2 and ymm3/m256/m32bcst subject to writemask k1.",
    "Return the bitwise logical AND of packed single-precision floating-point values in zmm2 and zmm3/m512/m32bcst subject to writemask k1.",
    "Return the bitwise logical AND of packed double-precision floating-point values in xmm1 and xmm2/mem.",
    "Return the bitwise logical AND of packed double-precision floating-point values in xmm2 and xmm3/mem.",
    "Return the bitwise logical AND of packed double-precision floating-point values in ymm2 and ymm3/mem.",
    "Return the bitwise logical AND of packed double-precision floating-point values in xmm2 and xmm3/m128/m64bcst subject to writemask k1.",
    "Return the bitwise logical AND of packed double-precision floating-point values in ymm2 and ymm3/m256/m64bcst subject to writemask k1.",
    "Return the bitwise logical AND of packed double-precision floating-point values in zmm2 and zmm3/m512/m64bcst subject to writemask k1.",
    "Return the bitwise logical AND of packed single-precision floating-point values in xmm1 and xmm2/mem.",
    "Return the bitwise logical AND of packed single-precision floating-point values in xmm2 and xmm3/mem.",
    "Return the bitwise logical AND of packed single-precision floating-point values in ymm2 and ymm3/mem.",
    "Return the bitwise logical AND of packed single-precision floating-point values in xmm2 and xmm3/m128/m32bcst subject to writemask k1.",
    "Return the bitwise logical AND of packed single-precision floating-point values in ymm2 and ymm3/m256/m32bcst subject to writemask k1.",
    "Return the bitwise logical AND of packed single-precision floating-point values in zmm2 and zmm3/m512/m32bcst subject to writemask k1.",
    "Valid Adjust RPL of r/m16 to not less than RPL of r16.",
    "Contiguous bitwise extract from r/m32 using r32b as control; store result in r32a.",
    "Contiguous bitwise extract from r/m64 using r64b as control; store result in r64a",
    "Select packed DP-FP values from xmm1 and xmm2/m128 from mask specified in imm8 and store the values into xmm1.",
    "Select packed double-precision floating-point Values from xmm2 and xmm3/m128 from mask in imm8 and store the values in xmm1.",
    "Select packed double-precision floating-point Values from ymm2 and ymm3/m256 from mask in imm8 and store the values in ymm1.",
    "Select packed single precision floating-point values from xmm1 and xmm2/m128 from mask specified in imm8 and store the values into xmm1.",
    "Select packed single-precision floating-point values from xmm2 and xmm3/m128 from mask in imm8 and store the values in xmm1.",
    "Select packed single-precision floating-point values from ymm2 and ymm3/m256 from mask in imm8 and store the values in ymm1.",
    "Select packed DP FP values from xmm1 and xmm2 from mask specified in XMM0 and store the values in xmm1.",
    "Conditionally copy double-precision floating-point values from xmm2 or xmm3/m128 to xmm1, based on mask bits in the mask operand, xmm4.",
    "Conditionally copy double-precision floating-point values from ymm2 or ymm3/m256 to ymm1, based on mask bits in the mask operand, ymm4.",
    "Select packed single precision floating-point values from xmm1 and xmm2/m128 from mask specified in XMM0 and store the values into xmm1.",
    "Conditionally copy single-precision floating-point values from xmm2 or xmm3/m128 to xmm1, based on mask bits in the specified mask operand, xmm4.",
    "Conditionally copy single-precision floating-point values from ymm2 or ymm3/m256 to ymm1, based on mask bits in the specified mask register, ymm4.",
    "Extract lowest set bit from r/m32 and set that bit in r32.",
    "Extract lowest set bit from r/m64, and set that bit in r64.",
    "Set all lower bits in r32 to â€œ1â€ starting from bit 0 to lowest set bit in r/m32.",
    "Set all lower bits in r64 to â€œ1â€ starting from bit 0 to lowest set bit in r/m64.",
    "Reset lowest set bit of r/m32, keep all other bits of r/m32 and write result to r32.",
    "Reset lowest set bit of r/m64, keep all other bits of r/m64 and write result to r64.",
    "Generate a #BR if the address in r/m32 is lower than the lower bound in bnd.LB.",
    "Generate a #BR if the address in r/m64 is lower than the lower bound in bnd.LB.",
    "Generate a #BR if the address in r/m32 is higher than the upper bound in bnd.UB (bnb.UB in 1's complement form).",
    "Generate a #BR if the address in r/m64 is higher than the upper bound in bnd.UB (bnb.UB in 1's complement form).",
    "Generate a #BR if the address in r/m32 is higher than the upper bound in bnd.UB (bnb.UB not in 1's complement form).",
    "Generate a #BR if the address in r/m64 is higher than the upper bound in bnd.UB (bnb.UB not in 1's complement form).",
    "Load the bounds stored in a bound table entry (BTE) into bnd with address translation using the base of mib and conditional on the index of mib matching the pointer value in the BTE.",
    "Make lower and upper bounds from m32 and store them in bnd.",
    "Make lower and upper bounds from m64 and store them in bnd.",
    "Move lower and upper bound from bnd2/m64 to bound register bnd1.",
    "Move lower and upper bound from bnd2/m128 to bound register bnd1.",
    "Move lower and upper bound from bnd2 to bnd1/m64.",
    "Move lower and upper bound from bnd2 to bound register bnd1/m128.",
    "Store the bounds in bnd and the pointer value in the index regis-ter of mib to a bound table entry (BTE) with address translation using the base of mib.",
    "Check if r16 (array index) is within bounds specified by m16&16.",
    "Check if r32 (array index) is within bounds specified by m32&32.",
    "Bit scan forward on r/m16.",
    "Bit scan forward on r/m32.",
    "Bit scan forward on r/m64.",
    "Bit scan reverse on r/m16.",
    "Bit scan reverse on r/m32.",
    "Bit scan reverse on r/m64.",
    "Reverses the byte order of a 32-bit register.",
    "Reverses the byte order of a 64-bit register.",
    "Store selected bit in CF flag.",
    "Store selected bit in CF flag.",
    "Store selected bit in CF flag.",
    "Store selected bit in CF flag.",
    "Store selected bit in CF flag.",
    "Store selected bit in CF flag.",
    "Store selected bit in CF flag and complement.",
    "Store selected bit in CF flag and complement.",
    "Store selected bit in CF flag and complement.",
    "Store selected bit in CF flag and complement.",
    "Store selected bit in CF flag and complement.",
    "Store selected bit in CF flag and complement.",
    "Store selected bit in CF flag and clear.",
    "Store selected bit in CF flag and clear.",
    "Store selected bit in CF flag and clear.",
    "Store selected bit in CF flag and clear.",
    "Store selected bit in CF flag and clear.",
    "Store selected bit in CF flag and clear.",
    "Store selected bit in CF flag and set.",
    "Store selected bit in CF flag and set.",
    "Store selected bit in CF flag and set.",
    "Store selected bit in CF flag and set.",
    "Store selected bit in CF flag and set.",
    "Store selected bit in CF flag and set.",
    "Zero bits in r/m32 starting with the position in r32b, write result to r32a.",
    "Zero bits in r/m64 starting with the position in r64b, write result to r64a.",
    "Call near, relative, displacement relative to next instruction.",
    "Call near, relative, displacement relative to next instruction. 32-bit displacement sign extended to 64-bits in 64-bit mode.",
    "Call near, absolute indirect, address given in r/m16.",
    "Call near, absolute indirect, address given in r/m32.",
    "Call near, absolute indirect, address given in r/m64.",
    "Call far, absolute, address given in operand.",
    "Call far, absolute, address given in operand.",
    "Call far, absolute indirect address given in m16:16. In 32-bit mode: if selector points to a gate, then RIP = 32-bit zero extended displacement taken from gate; else RIP = zero extended 16-bit offset from far pointer referenced in the instruction.",
    "In 64-bit mode: If selector points to a gate, then RIP = 64-bit displacement taken from gate; else RIP = zero extended 32-bit offset from far pointer referenced in the instruction.",
    "In 64-bit mode: If selector points to a gate, then RIP = 64-bit displacement taken from gate; else RIP = 64-bit offset from far pointer referenced in the instruction.",
    "AX â† sign-extend of AL.",
    "EAX â† sign-extend of AX.",
    "RAX â† sign-extend of EAX.",
    "Clear the AC flag in the EFLAGS register.",
    "Clear CF flag.",
    "Clear DF flag.",
    "Flushes cache line containing m8.",
    "Flushes cache line containing m8.",
    "Clear interrupt flag; interrupts disabled when interrupt flag cleared.",
    "Clears TS flag in CR0.",
    "Writes back modified cache line containing m8, and may retain the line in cache hierarchy in non-modified state.",
    "Complement CF flag.",
    "Move if above (CF=0 and ZF=0).",
    "Move if above (CF=0 and ZF=0).",
    "Move if above (CF=0 and ZF=0).",
    "Move if above or equal (CF=0).",
    "Move if above or equal (CF=0).",
    "Move if above or equal (CF=0).",
    "Move if below (CF=1).",
    "Move if below (CF=1).",
    "Move if below (CF=1).",
    "Move if below or equal (CF=1 or ZF=1).",
    "Move if below or equal (CF=1 or ZF=1).",
    "Move if below or equal (CF=1 or ZF=1).",
    "Move if carry (CF=1).",
    "Move if carry (CF=1).",
    "Move if carry (CF=1).",
    "Move if equal (ZF=1).",
    "Move if equal (ZF=1).",
    "Move if equal (ZF=1).",
    "Move if greater (ZF=0 and SF=OF).",
    "Move if greater (ZF=0 and SF=OF).",
    "Move if greater (ZF=0 and SF=OF).",
    "Move if greater or equal (SF=OF).",
    "Move if greater or equal (SF=OF).",
    "Move if greater or equal (SF=OF).",
    "Move if less (SFâ‰  OF).",
    "Move if less (SFâ‰  OF).",
    "Move if less (SFâ‰  OF).",
    "Move if less or equal (ZF=1 or SFâ‰  OF).",
    "Move if less or equal (ZF=1 or SFâ‰  OF).",
    "Move if less or equal (ZF=1 or SFâ‰  OF).",
    "Move if not above (CF=1 or ZF=1).",
    "Move if not above (CF=1 or ZF=1).",
    "Move if not above (CF=1 or ZF=1).",
    "Move if not above or equal (CF=1).",
    "Move if not above or equal (CF=1).",
    "Move if not above or equal (CF=1).",
    "Move if not below (CF=0).",
    "Move if not below (CF=0).",
    "Move if not below (CF=0).",
    "Move if not below or equal (CF=0 and ZF=0).CMOVccâ€”Conditional Move",
    "Move if not below or equal (CF=0 and ZF=0).",
    "Move if not below or equal (CF=0 and ZF=0).",
    "Move if not carry (CF=0).",
    "Move if not carry (CF=0).",
    "Move if not carry (CF=0).",
    "Move if not equal (ZF=0).",
    "Move if not equal (ZF=0).",
    "Move if not equal (ZF=0).",
    "Move if not greater (ZF=1 or SFâ‰  OF).",
    "Move if not greater (ZF=1 or SFâ‰  OF).",
    "Move if not greater (ZF=1 or SFâ‰  OF).",
    "Move if not greater or equal (SFâ‰  OF).",
    "Move if not greater or equal (SFâ‰  OF).",
    "Move if not greater or equal (SFâ‰  OF).",
    "Move if not less (SF=OF).",
    "Move if not less (SF=OF).",
    "Move if not less (SF=OF).",
    "Move if not less or equal (ZF=0 and SF=OF).",
    "Move if not less or equal (ZF=0 and SF=OF).",
    "Move if not less or equal (ZF=0 and SF=OF).",
    "Move if not overflow (OF=0).",
    "Move if not overflow (OF=0).",
    "Move if not overflow (OF=0).",
    "Move if not parity (PF=0).",
    "Move if not parity (PF=0).",
    "Move if not parity (PF=0).",
    "Move if not sign (SF=0).",
    "Move if not sign (SF=0).",
    "Move if not sign (SF=0).",
    "Move if not zero (ZF=0).",
    "Move if not zero (ZF=0).",
    "Move if not zero (ZF=0).",
    "Move if overflow (OF=1).",
    "Move if overflow (OF=1).",
    "Move if overflow (OF=1).",
    "Move if parity (PF=1).",
    "Move if parity (PF=1).",
    "Move if parity (PF=1).",
    "Move if parity even (PF=1).",
    "Move if parity even (PF=1).",
    "Move if parity even (PF=1).CMOVccâ€”Conditional Move",
    "Compare imm8 with AL.",
    "Compare imm16 with AX.",
    "Compare imm32 with EAX.",
    "Compare imm32 sign-extended to 64-bits with RAX.",
    "Compare imm8 with r/m8.",
    "Compare imm8 with r/m8.",
    "Compare imm16 with r/m16.",
    "Compare imm32 with r/m32.",
    "Compare imm32 sign-extended to 64-bits with r/m64.",
    "Compare imm8 with r/m16.",
    "Compare imm8 with r/m32.",
    "Compare imm8 with r/m64.",
    "Compare r8 with r/m8.",
    "Compare r8 with r/m8.",
    "Compare r16 with r/m16.",
    "Compare r32 with r/m32.",
    "Compare r64 with r/m64.",
    "Compare r/m8 with r8.",
    "Compare r/m8 with r8.",
    "Compare r/m16 with r16.",
    "Compare r/m32 with r32.",
    "Compare r/m64 with r64.",
    "Compare packed double-precision floating-point values in xmm2/m128 and xmm1 using bits 2:0 of imm8 as a comparison predicate.",
    "Compare packed double-precision floating-point values in xmm3/m128 and xmm2 using bits 4:0 of imm8 as a comparison predicate.",
    "Compare packed double-precision floating-point values in ymm3/m256 and ymm2 using bits 4:0 of imm8 as a comparison predicate.",
    "Compare packed double-precision floating-point values in xmm3/m128/m64bcst and xmm2 using bits 4:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.",
    "Compare packed double-precision floating-point values in ymm3/m256/m64bcst and ymm2 using bits 4:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.",
    "Compare packed double-precision floating-point values in zmm3/m512/m64bcst and zmm2 using bits 4:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.",
    "Compare packed single-precision floating-point values in xmm2/m128 and xmm1 using bits 2:0 of imm8 as a comparison predicate.",
    "Compare packed single-precision floating-point values in xmm3/m128 and xmm2 using bits 4:0 of imm8 as a comparison predicate.",
    "Compare packed single-precision floating-point values in ymm3/m256 and ymm2 using bits 4:0 of imm8 as a comparison predicate.",
    "Compare packed single-precision floating-point values in xmm3/m128/m32bcst and xmm2 using bits 4:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.",
    "Compare packed single-precision floating-point values in ymm3/m256/m32bcst and ymm2 using bits 4:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.",
    "Compare packed single-precision floating-point values in zmm3/m512/m32bcst and zmm2 using bits 4:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.",
    "For legacy mode, compare byte at address DS:(E)SI with byte at address ES:(E)DI; For 64-bit mode compare byte at address (R|E)SI to byte at address (R|E)DI. The status flags are set accordingly.",
    "For legacy mode, compare word at address DS:(E)SI with word at address ES:(E)DI; For 64-bit mode compare word at address (R|E)SI with word at address (R|E)DI. The status flags are set accordingly.",
    "For legacy mode, compare dword at address DS:(E)SI at dword at address ES:(E)DI; For 64-bit mode compare dword at address (R|E)SI at dword at address (R|E)DI. The status flags are set accordingly.",
    "Compares quadword at address (R|E)SI with quadword at address (R|E)DI and sets the status flags accordingly.",
    "For legacy mode, compare byte at address DS:(E)SI with byte at address ES:(E)DI; For 64-bit mode compare byte at address (R|E)SI with byte at address (R|E)DI. The status flags are set accordingly.",
    "For legacy mode, compare word at address DS:(E)SI with word at address ES:(E)DI; For 64-bit mode compare word at address (R|E)SI with word at address (R|E)DI. The status flags are set accordingly.",
    "For legacy mode, compare dword at address DS:(E)SI with dword at address ES:(E)DI; For 64-bit mode compare dword at address (R|E)SI with dword at address (R|E)DI. The status flags are set accordingly.",
    "Compares quadword at address (R|E)SI with quadword at address (R|E)DI and sets the status flags accordingly.",
    "Compare low double-precision floating-point value in xmm2/m64 and xmm1 using bits 2:0 of imm8 as comparison predicate.",
    "Compare low double-precision floating-point value in xmm3/m64 and xmm2 using bits 4:0 of imm8 as comparison predicate.",
    "Compare low double-precision floating-point value in xmm3/m64 and xmm2 using bits 4:0 of imm8 as comparison predicate with writemask k2 and leave the result in mask register k1.",
    "Compare low single-precision floating-point value in xmm2/m32 and xmm1 using bits 2:0 of imm8 as comparison predicate.",
    "Compare low single-precision floating-point value in xmm3/m32 and xmm2 using bits 4:0 of imm8 as comparison predicate.",
    "Compare low single-precision floating-point value in xmm3/m32 and xmm2 using bits 4:0 of imm8 as comparison predicate with writemask k2 and leave the result in mask register k1.",
    "Compare AL with r/m8. If equal, ZF is set and r8 is loaded into r/m8. Else, clear ZF and load r/m8 into AL.",
    "Compare AL with r/m8. If equal, ZF is set and r8 is loaded into r/m8. Else, clear ZF and load r/m8 into AL.",
    "Compare AX with r/m16. If equal, ZF is set and r16 is loaded into r/m16. Else, clear ZF and load r/m16 into AX.",
    "Compare EAX with r/m32. If equal, ZF is set and r32 is loaded into r/m32. Else, clear ZF and load r/m32 into EAX.",
    "Compare RAX with r/m64. If equal, ZF is set and r64 is loaded into r/m64. Else, clear ZF and load r/m64 into RAX.",
    "Compare EDX:EAX with m64. If equal, set ZF and load ECX:EBX into m64. Else, clear ZF and load m64 into EDX:EAX.",
    "Compare RDX:RAX with m128. If equal, set ZF and load RCX:RBX into m128. Else, clear ZF and load m128 into RDX:RAX.",
    "Compare low double-precision floating-point values in xmm1 and xmm2/mem64 and set the EFLAGS flags accordingly.",
    "Compare low double-precision floating-point values in xmm1 and xmm2/mem64 and set the EFLAGS flags accordingly.",
    "Compare low double-precision floating-point values in xmm1 and xmm2/mem64 and set the EFLAGS flags accordingly.",
    "Compare low single-precision floating-point values in xmm1 and xmm2/mem32 and set the EFLAGS flags accordingly.",
    "Compare low single-precision floating-point values in xmm1 and xmm2/mem32 and set the EFLAGS flags accordingly.",
    "Compare low single-precision floating-point values in xmm1 and xmm2/mem32 and set the EFLAGS flags accordingly.",
    "Returns processor identification and feature information to the EAX, EBX, ECX, and EDX registers, as determined by input entered in EAX (in some cases, ECX as well).",
    "Accumulate CRC32 on r/m8.",
    "Accumulate CRC32 on r/m8.",
    "Accumulate CRC32 on r/m16.",
    "Accumulate CRC32 on r/m32.",
    "Accumulate CRC32 on r/m8.",
    "Accumulate CRC32 on r/m64.",
    "Convert two packed signed doubleword integers from xmm2/mem to two packed double-precision floating-point values in xmm1.",
    "Convert two packed signed doubleword integers from xmm2/mem to two packed double-precision floating-point values in xmm1.",
    "Convert four packed signed doubleword integers from xmm2/mem to four packed double-precision floating-point values in ymm1.",
    "Convert 2 packed signed doubleword integers from xmm2/m128/m32bcst to eight packed double-precision floating-point values in xmm1 with writemask k1.",
    "Convert 4 packed signed doubleword integers from xmm2/m128/m32bcst to 4 packed double-precision floating-point values in ymm1 with writemask k1.",
    "Convert eight packed signed doubleword integers from ymm2/m256/m32bcst to eight packed double-precision floating-point values in zmm1 with writemask k1.",
    "Convert four packed signed doubleword integers from xmm2/mem to four packed single-precision floating-point values in xmm1.",
    "Convert four packed signed doubleword integers from xmm2/mem to four packed single-precision floating-point values in xmm1.",
    "Convert eight packed signed doubleword integers from ymm2/mem to eight packed single-precision floating-point values in ymm1.",
    "Convert four packed signed doubleword integers from xmm2/m128/m32bcst to four packed single-precision floating-point values in xmm1with writemask k1.",
    "Convert eight packed signed doubleword integers from ymm2/m256/m32bcst to eight packed single-precision floating-point values in ymm1with writemask k1.",
    "Convert sixteen packed signed doubleword integers from zmm2/m512/m32bcst to sixteen packed single-precision floating-point values in zmm1with writemask k1.",
    "Convert two packed double-precision floating-point values in xmm2/mem to two signed doubleword integers in xmm1.",
    "Convert two packed double-precision floating-point values in xmm2/mem to two signed doubleword integers in xmm1.",
    "Convert four packed double-precision floating-point values in ymm2/mem to four signed doubleword integers in xmm1.",
    "Convert two packed double-precision floating-point values in xmm2/m128/m64bcst to two signed doubleword integers in xmm1 subject to writemask k1.",
    "Convert four packed double-precision floating-point values in ymm2/m256/m64bcst to four signed doubleword integers in xmm1 subject to writemask k1.",
    "Convert eight packed double-precision floating-point values in zmm2/m512/m64bcst to eight signed doubleword integers in ymm1 subject to writemask k1.",
    "Convert two packed double-precision floating-point values from xmm/m128 to two packed signed doubleword integers in mm.",
    "Convert two packed double-precision floating-point values in xmm2/mem to two single-precision floating-point values in xmm1.",
    "Convert two packed double-precision floating-point values in xmm2/mem to two single-precision floating-point values in xmm1.",
    "Convert four packed double-precision floating-point values in ymm2/mem to four single-precision floating-point values in xmm1.",
    "Convert two packed double-precision floating-point values in xmm2/m128/m64bcst to two single-precision floating-point values in xmm1with writemask k1.",
    "Convert four packed double-precision floating-point values in ymm2/m256/m64bcst to four single-precision floating-point values in xmm1with writemask k1.",
    "Convert eight packed double-precision floating-point values in zmm2/m512/m64bcst to eight single-precision floating-point values in ymm1with writemask k1.",
    "Convert two packed signed doubleword integers from mm/mem64 to two packed double-precision floating-point values in xmm.",
    "Convert two signed doubleword integers from mm/m64 to two single-precision floating-point values in xmm.",
    "Convert four packed single-precision floating-point values from xmm2/mem to four packed signed doubleword values in xmm1.",
    "Convert four packed single-precision floating-point values from xmm2/mem to four packed signed doubleword values in xmm1.",
    "Convert eight packed single-precision floating-point values from ymm2/mem to eight packed signed doubleword values in ymm1.",
    "Convert four packed single precision floating-point values from xmm2/m128/m32bcst to four packed signed doubleword values in xmm1 subject to writemask k1.",
    "Convert eight packed single precision floating-point values from ymm2/m256/m32bcst to eight packed signed doubleword values in ymm1 subject to writemask k1.",
    "Convert sixteen packed single-precision floating-point values from zmm2/m512/m32bcst to sixteen packed signed doubleword values in zmm1 subject to writemask k1.",
    "Convert two packed single-precision floating-point values in xmm2/m64 to two packed double-precision floating-point values in xmm1.",
    "Convert two packed single-precision floating-point values in xmm2/m64 to two packed double-precision floating-point values in xmm1.",
    "Convert four packed single-precision floating-point values in xmm2/m128 to four packed double-precision floating-point values in ymm1.",
    "Convert two packed single-precision floating-point values in xmm2/m64/m32bcst to packed double-precision floating-point values in xmm1 with writemask k1.",
    "Convert four packed single-precision floating-point values in xmm2/m128/m32bcst to packed double-precision floating-point values in ymm1 with writemask k1.",
    "Convert eight packed single-precision floating-point values in ymm2/m256/b32bcst to eight packed double-precision floating-point values in zmm1 with writemask k1.",
    "Convert two packed single-precision floating-point values from xmm/m64 to two packed signed doubleword integers in mm.",
    "Convert one double-precision floating-point value from xmm1/m64 to one signed doubleword integer r32.",
    "Convert one double-precision floating-point value from xmm1/m64 to one signed quadword integer signextended into r64.",
    "Convert one double-precision floating-point value from xmm1/m64 to one signed doubleword integer r32.",
    "Convert one double-precision floating-point value from xmm1/m64 to one signed quadword integer signextended into r64.",
    "Convert one double-precision floating-point value from xmm1/m64 to one signed doubleword integer r32.",
    "Convert one double-precision floating-point value from xmm1/m64 to one signed quadword integer signextended into r64.",
    "Convert one double-precision floating-point value in xmm2/m64 to one single-precision floating-point value in xmm1.",
    "Convert one double-precision floating-point value in xmm3/m64 to one single-precision floating-point value and merge with high bits in xmm2.",
    "Convert one double-precision floating-point value in xmm3/m64 to one single-precision floating-point value and merge with high bits in xmm2 under writemask k1.",
    "Convert one signed doubleword integer from r32/m32 to one double-precision floating-point value in xmm1.",
    "Convert one signed quadword integer from r/m64 to one double-precision floating-point value in xmm1.",
    "Convert one signed doubleword integer from r/m32 to one double-precision floating-point value in xmm1.",
    "Convert one signed quadword integer from r/m64 to one double-precision floating-point value in xmm1.",
    "Convert one signed doubleword integer from r/m32 to one double-precision floating-point value in xmm1.",
    "Convert one signed quadword integer from r/m64 to one double-precision floating-point value in xmm1.",
    "Convert one signed doubleword integer from r/m32 to one single-precision floating-point value in xmm1.",
    "Convert one signed quadword integer from r/m64 to one single-precision floating-point value in xmm1.",
    "Convert one signed doubleword integer from r/m32 to one single-precision floating-point value in xmm1.",
    "Convert one signed quadword integer from r/m64 to one single-precision floating-point value in xmm1.",
    "Convert one signed doubleword integer from r/m32 to one single-precision floating-point value in xmm1.",
    "Convert one signed quadword integer from r/m64 to one single-precision floating-point value in xmm1.",
    "Convert one single-precision floating-point value in xmm2/m32 to one double-precision floating-point value in xmm1.",
    "Convert one single-precision floating-point value in xmm3/m32 to one double-precision floating-point value and merge with high bits of xmm2.",
    "Convert one single-precision floating-point value in xmm3/m32 to one double-precision floating-point value and merge with high bits of xmm2 under writemask k1.",
    "Convert one single-precision floating-point value from xmm1/m32 to one signed doubleword integer in r32.",
    "Convert one single-precision floating-point value from xmm1/m32 to one signed quadword integer in r64.",
    "Convert one single-precision floating-point value from xmm1/m32 to one signed doubleword integer in r32.",
    "Convert one single-precision floating-point value from xmm1/m32 to one signed quadword integer in r64.",
    "Convert one single-precision floating-point value from xmm1/m32 to one signed doubleword integer in r32.",
    "Convert one single-precision floating-point value from xmm1/m32 to one signed quadword integer in r64.",
    "Convert two packed double-precision floating-point values in xmm2/mem to two signed doubleword integers in xmm1 using truncation.",
    "Convert two packed double-precision floating-point values in xmm2/mem to two signed doubleword integers in xmm1 using truncation.",
    "Convert four packed double-precision floating-point values in ymm2/mem to four signed doubleword integers in xmm1 using truncation.",
    "Convert two packed double-precision floating-point values in xmm2/m128/m64bcst to two signed doubleword integers in xmm1 using truncation subject to writemask k1.",
    "Convert four packed double-precision floating-point values in ymm2/m256/m64bcst to four signed doubleword integers in xmm1 using truncation subject to writemask k1.",
    "Convert eight packed double-precision floating-point values in zmm2/m512/m64bcst to eight signed doubleword integers in ymm1 using truncation subject to writemask k1.",
    "Convert two packer double-precision floating-point values from xmm/m128 to two packed signed doubleword integers in mm using truncation.",
    "Convert four packed single-precision floating-point values from xmm2/mem to four packed signed doubleword values in xmm1 using truncation.",
    "Convert four packed single-precision floating-point values from xmm2/mem to four packed signed doubleword values in xmm1 using truncation.",
    "Convert eight packed single-precision floating-point values from ymm2/mem to eight packed signed doubleword values in ymm1 using truncation.",
    "Convert four packed single precision floating-point values from xmm2/m128/m32bcst to four packed signed doubleword values in xmm1 using truncation subject to writemask k1.",
    "Convert eight packed single precision floating-point values from ymm2/m256/m32bcst to eight packed signed doubleword values in ymm1 using truncation subject to writemask k1.",
    "Convert sixteen packed single-precision floating-point values from zmm2/m512/m32bcst to sixteen packed signed doubleword values in zmm1 using truncation subject to writemask k1.",
    "Convert two single-precision floating-point values from xmm/m64 to two signed doubleword signed integers in mm using truncation.",
    "Convert one double-precision floating-point value from xmm1/m64 to one signed doubleword integer in r32 using truncation.",
    "Convert one double-precision floating-point value from xmm1/m64 to one signed quadword integer in r64 using truncation.",
    "Convert one double-precision floating-point value from xmm1/m64 to one signed doubleword integer in r32 using truncation.",
    "Convert one double-precision floating-point value from xmm1/m64 to one signed quadword integer in r64 using truncation.",
    "Convert one double-precision floating-point value from xmm1/m64 to one signed doubleword integer in r32 using truncation.",
    "Convert one double-precision floating-point value from xmm1/m64 to one signed quadword integer in r64 using truncation.",
    "Convert one single-precision floating-point value from xmm1/m32 to one signed doubleword integer in r32 using truncation.",
    "Convert one single-precision floating-point value from xmm1/m32 to one signed quadword integer in r64 using truncation.",
    "Convert one single-precision floating-point value from xmm1/m32 to one signed doubleword integer in r32 using truncation.",
    "Convert one single-precision floating-point value from xmm1/m32 to one signed quadword integer in r64 using truncation.",
    "Convert one single-precision floating-point value from xmm1/m32 to one signed doubleword integer in r32 using truncation.",
    "Convert one single-precision floating-point value from xmm1/m32 to one signed quadword integer in r64 using truncation.",
    "DX:AX â† sign-extend of AX.",
    "EDX:EAX â† sign-extend of EAX.",
    "RDX:RAXâ† sign-extend of RAX.",
    "Decimal adjust AL after addition.",
    "Decimal adjust AL after subtraction.",
    "Decrement r/m8 by 1.",
    "Decrement r/m8 by 1.",
    "Decrement r/m16 by 1.",
    "Decrement r/m32 by 1.",
    "Decrement r/m64 by 1.",
    "Decrement r16 by 1.",
    "Decrement r32 by 1.",
    "Unsigned divide AX by r/m8, with result stored in AL â† Quotient, AH â† Remainder.",
    "Unsigned divide AX by r/m8, with result stored in AL â† Quotient, AH â† Remainder.",
    "Unsigned divide DX:AX by r/m16, with result stored in AX â† Quotient, DX â† Remainder.",
    "Unsigned divide EDX:EAX by r/m32, with result stored in EAX â† Quotient, EDX â† Remainder.",
    "Unsigned divide RDX:RAX by r/m64, with result stored in RAX â† Quotient, RDX â† Remainder.",
    "Divide packed double-precision floating-point values in xmm1 by packed double-precision floating-point values in xmm2/mem.",
    "Divide packed double-precision floating-point values in xmm2 by packed double-precision floating-point values in xmm3/mem.",
    "Divide packed double-precision floating-point values in ymm2 by packed double-precision floating-point values in ymm3/mem.",
    "Divide packed double-precision floating-point values in xmm2 by packed double-precision floating-point values in xmm3/m128/m64bcst and write results to xmm1 subject to writemask k1.",
    "Divide packed double-precision floating-point values in ymm2 by packed double-precision floating-point values in ymm3/m256/m64bcst and write results to ymm1 subject to writemask k1.",
    "Divide packed double-precision floating-point values in zmm2 by packed double-precision FP values in zmm3/m512/m64bcst and write results to zmm1 subject to writemask k1.",
    "Divide packed single-precision floating-point values in xmm1 by packed single-precision floating-point values in xmm2/mem.",
    "Divide packed single-precision floating-point values in xmm2 by packed single-precision floating-point values in xmm3/mem.",
    "Divide packed single-precision floating-point values in ymm2 by packed single-precision floating-point values in ymm3/mem.",
    "Divide packed single-precision floating-point values in xmm2 by packed single-precision floating-point values in xmm3/m128/m32bcst and write results to xmm1 subject to writemask k1.",
    "Divide packed single-precision floating-point values in ymm2 by packed single-precision floating-point values in ymm3/m256/m32bcst and write results to ymm1 subject to writemask k1.",
    "Divide packed single-precision floating-point values in zmm2 by packed single-precision floating-point values in zmm3/m512/m32bcst and write results to zmm1 subject to writemask k1.",
    "Divide low double-precision floating-point value in xmm1 by low double-precision floating-point value in xmm2/m64.",
    "Divide low double-precision floating-point value in xmm2 by low double-precision floating-point value in xmm3/m64.",
    "Divide low double-precision floating-point value in xmm2 by low double-precision floating-point value in xmm3/m64.",
    "Divide low single-precision floating-point value in xmm1 by low single-precision floating-point value in xmm2/m32.",
    "Divide low single-precision floating-point value in xmm2 by low single-precision floating-point value in xmm3/m32.",
    "Divide low single-precision floating-point value in xmm2 by low single-precision floating-point value in xmm3/m32.",
    "Selectively multiply packed DP floating-point values from xmm1 with packed DP floating-point values from xmm2, add and selectively store the packed DP floating-point values to xmm1.",
    "Selectively multiply packed DP floating-point values from xmm2 with packed DP floating-point values from xmm3, add and selectively store the packed DP floating-point values to xmm1.",
    "Selectively multiply packed SP floating-point values from xmm1 with packed SP floating-point values from xmm2, add and selectively store the packed SP floating-point values or zero values to xmm1.",
    "Multiply packed SP floating point values from xmm1 with packed SP floating point values from xmm2/mem selectively add and store to xmm1.",
    "Multiply packed single-precision floating-point values from ymm2 with packed SP floating point values from ymm3/mem, selectively add pairs of elements and store to ymm1.",
    "Set the x87 FPU tag word to empty.",
    "Create a stack frame for a procedure.",
    "Create a stack frame with a nested pointer for a procedure.",
    "Create a stack frame with nested pointers for a procedure.",
    "Extract one single-precision floating-point value from xmm1 at the offset specified by imm8 and store the result in AnyRegister or m32. Zero extend the results in 64-bit register if applicable.",
    "Extract one single-precision floating-point value from xmm1 at the offset specified by imm8 and store the result in AnyRegister or m32. Zero extend the results in 64-bit register if applicable.",
    "Extract one single-precision floating-point value from xmm1 at the offset specified by imm8 and store the result in AnyRegister or m32. Zero extend the results in 64-bit register if applicable.",
    "Replace ST(0) with (2 ST(0) â€“ 1).",
    "Replace ST with its absolute value.",
    "Add m32fp to ST(0) and store result in ST(0).",
    "Add m64fp to ST(0) and store result in ST(0).",
    "Add ST(0) to ST(i) and store result in ST(0).",
    "Add ST(i) to ST(0) and store result in ST(i).",
    "Add ST(0) to ST(i), store result in ST(i), and pop the register stack.",
    "Add ST(0) to ST(1), store result in ST(1), and pop the register stack.",
    "Add m32int to ST(0) and store result in ST(0).",
    "Add m16int to ST(0) and store result in ST(0).FADD/FADDP/FIADDâ€”Add This instructionâ€™s operation is the same in non-64-bit modes and 64-bit mode.",
    "Convert BCD value to floating-point and push onto the FPU stack.",
    "Store ST(0) in m80bcd and pop ST(0).",
    "Complements sign of ST(0).",
    "Clear floating-point exception flags after checking for pending unmasked floating-point exceptions.",
    "Clear floating-point exception flags without checking for pending unmasked floating-point exceptions.",
    "Move if below (CF=1).",
    "Move if equal (ZF=1).",
    "Move if below or equal (CF=1 or ZF=1).",
    "Move if unordered (PF=1).",
    "Move if not below (CF=0).",
    "Move if not equal (ZF=0).",
    "Move if not below or equal (CF=0 and ZF=0).",
    "Move if not unordered (PF=0).",
    "Compare ST(0) with m32fp.",
    "Compare ST(0) with m64fp.",
    "Compare ST(0) with ST(i).",
    "Compare ST(0) with ST(1).",
    "Compare ST(0) with m32fp and pop register stack.",
    "Compare ST(0) with m64fp and pop register stack.",
    "Compare ST(0) with ST(i) and pop register stack.",
    "Compare ST(0) with ST(1) and pop register stack.",
    "Compare ST(0) with ST(1) and pop register stack twice.",
    "Compare ST(0) with ST(i) and set status flags accordingly.",
    "Compare ST(0) with ST(i), set status flags accordingly, and pop register stack.",
    "Compare ST(0) with ST(i), check for ordered values, and set status flags accordingly.",
    "Compare ST(0) with ST(i), check for ordered values, set status flags accordingly, and pop register stack.",
    "Replace ST(0) with its approximate cosine.",
    "Decrement TOP field in FPU status word.",
    "Divide ST(0) by m32fp and store result in ST(0).",
    "Divide ST(0) by m64fp and store result in ST(0).",
    "Divide ST(0) by ST(i) and store result in ST(0).",
    "Divide ST(i) by ST(0) and store result in ST(i).",
    "Divide ST(i) by ST(0), store result in ST(i), and pop the register stack.",
    "Divide ST(1) by ST(0), store result in ST(1), and pop the register stack.",
    "Divide ST(0) by m32int and store result in ST(0).",
    "Divide ST(0) by m16int and store result in ST(0).FDIV/FDIVP/FIDIVâ€”Divide This instructionâ€™s operation is the same in non-64-bit modes and 64-bit mode.",
    "Divide m32fp by ST(0) and store result in ST(0).",
    "Divide m64fp by ST(0) and store result in ST(0).",
    "Divide ST(i) by ST(0) and store result in ST(0).",
    "Divide ST(0) by ST(i) and store result in ST(i).",
    "Divide ST(0) by ST(i), store result in ST(i), and pop the register stack.",
    "Divide ST(0) by ST(1), store result in ST(1), and pop the register stack.",
    "Divide m32int by ST(0) and store result in ST(0).",
    "Divide m16int by ST(0) and store result in ST(0).FDIVR/FDIVRP/FIDIVRâ€”Reverse Divide When the source operand is an integer 0, it is treated as a +0. This instructionâ€™s operation is the same in non-64-bit modes and 64-bit mode.",
    "Sets tag for ST(i) to empty.",
    "Compare ST(0) with m16int.",
    "Compare ST(0) with m32int.",
    "Compare ST(0) with m16int and pop stack register.",
    "Compare ST(0) with m32int and pop stack register.",
    "Push m16int onto the FPU register stack.",
    "Push m32int onto the FPU register stack.",
    "Push m64int onto the FPU register stack.FILDâ€”Load Integer Compatibility Mode Exceptions Same exceptions as in protected mode. 64-Bit Mode Exceptions #SS(0) If a memory address referencing the SS segment is in a non-canonical form. #GP(0) If the memory address is in a non-canonical form. #NM CR0.EM[bit 2] or CR0.TS[bit 3] = 1. #MF If there is a pending x87 FPU exception. #PF(fault-code) If a page fault occurs. #AC(0) If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3. #UD If the LOCK prefix is used.",
    "Increment the TOP field in the FPU status register.",
    "Initialize FPU after checking for pending unmasked floating-point exceptions.",
    "Initialize FPU without checking for pending unmasked floating-point exceptions.",
    "Store ST(0) in m16int.",
    "Store ST(0) in m32int.",
    "Store ST(0) in m16int and pop register stack.",
    "Store ST(0) in m32int and pop register stack.",
    "Store ST(0) in m64int and pop register stack.",
    "Store ST(0) in m16int with truncation.",
    "Store ST(0) in m32int with truncation.",
    "Store ST(0) in m64int with truncation.",
    "Push m32fp onto the FPU register stack.",
    "Push m64fp onto the FPU register stack.",
    "Push m80fp onto the FPU register stack.",
    "Push ST(i) onto the FPU register stack.FLDâ€”Load Floating Point Value Protected Mode Exceptions #GP(0) If destination is located in a non-writable segment. If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit. If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector. #SS(0) If a memory operand effective address is outside the SS segment limit. #NM CR0.EM[bit 2] or CR0.TS[bit 3] = 1. #PF(fault-code) If a page fault occurs. #AC(0) If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3. #UD If the LOCK prefix is used. Real-Address Mode Exceptions #GP If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit. #SS If a memory operand effective address is outside the SS segment limit. #NM CR0.EM[bit 2] or CR0.TS[bit 3] = 1. #UD If the LOCK prefix is used. Virtual-8086 Mode Exceptions #GP(0) If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit. #SS(0) If a memory operand effective address is outside the SS segment limit. #NM CR0.EM[bit 2] or CR0.TS[bit 3] = 1. #PF(fault-code) If a page fault occurs. #AC(0) If alignment checking is enabled and an unaligned memory reference is made. #UD If the LOCK prefix is used. Compatibility Mode Exceptions Same exceptions as in protected mode. 64-Bit Mode Exceptions #SS(0) If a memory address referencing the SS segment is in a non-canonical form. #GP(0) If the memory address is in a non-canonical form. #NM CR0.EM[bit 2] or CR0.TS[bit 3] = 1. #MF If there is a pending x87 FPU exception. #PF(fault-code) If a page fault occurs. #AC(0) If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3. #UD If the LOCK prefix is used.",
    "Push +1.0 onto the FPU register stack.",
    "Push log 10 onto the FPU register stack.",
    "Push log e onto the FPU register stack.",
    "Push Ï€ onto the FPU register stack.",
    "Push log 10 2 onto the FPU register stack.",
    "Push log 2 onto the FPU register stack.",
    "Push +0.0 onto the FPU register stack.",
    "Load FPU control word from m2byte.FLDCWâ€”Load x87 FPU Control Word Virtual-8086 Mode Exceptions #GP(0) If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit. #SS(0) If a memory operand effective address is outside the SS segment limit. #NM CR0.EM[bit 2] or CR0.TS[bit 3] = 1. #PF(fault-code) If a page fault occurs. #AC(0) If alignment checking is enabled and an unaligned memory reference is made. #UD If the LOCK prefix is used. Compatibility Mode Exceptions Same exceptions as in protected mode. 64-Bit Mode Exceptions #SS(0) If a memory address referencing the SS segment is in a non-canonical form. #GP(0) If the memory address is in a non-canonical form. #NM CR0.EM[bit 2] or CR0.TS[bit 3] = 1. #MF If there is a pending x87 FPU exception. #PF(fault-code) If a page fault occurs. #AC(0) If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3. #UD If the LOCK prefix is used.",
    "Load FPU environment from m14byte or m28byte.FLDENVâ€”Load x87 FPU Environment Protected Mode Exceptions #GP(0) If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit. If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector. #SS(0) If a memory operand effective address is outside the SS segment limit. #NM CR0.EM[bit 2] or CR0.TS[bit 3] = 1. #PF(fault-code) If a page fault occurs. #AC(0) If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3. #UD If the LOCK prefix is used. Real-Address Mode Exceptions #GP If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit. #SS If a memory operand effective address is outside the SS segment limit. #NM CR0.EM[bit 2] or CR0.TS[bit 3] = 1. #UD If the LOCK prefix is used. Virtual-8086 Mode Exceptions #GP(0) If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit. #SS(0) If a memory operand effective address is outside the SS segment limit. #NM CR0.EM[bit 2] or CR0.TS[bit 3] = 1. #PF(fault-code) If a page fault occurs. #AC(0) If alignment checking is enabled and an unaligned memory reference is made. #UD If the LOCK prefix is used. Compatibility Mode Exceptions Same exceptions as in protected mode. 64-Bit Mode Exceptions #SS(0) If a memory address referencing the SS segment is in a non-canonical form. #GP(0) If the memory address is in a non-canonical form. #NM CR0.EM[bit 2] or CR0.TS[bit 3] = 1. #MF If there is a pending x87 FPU exception. #PF(fault-code) If a page fault occurs. #AC(0) If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3. #UD If the LOCK prefix is used.",
    "Multiply ST(0) by m32fp and store result in ST(0).",
    "Multiply ST(0) by m64fp and store result in ST(0).",
    "Multiply ST(0) by ST(i) and store result in ST(0).",
    "Multiply ST(i) by ST(0) and store result in ST(i).",
    "Multiply ST(i) by ST(0), store result in ST(i), and pop the register stack.",
    "Multiply ST(1) by ST(0), store result in ST(1), and pop the register stack.",
    "Multiply ST(0) by m32int and store result in ST(0).",
    "Multiply ST(0) by m16int and store result in ST(0).FMUL/FMULP/FIMULâ€”Multiply This instructionâ€™s operation is the same in non-64-bit modes and 64-bit mode.",
    "No operation is performed.",
    "Replace ST(1) with arctan(ST(1)/ST(0)) and pop the register stack.",
    "Replace ST(0) with the remainder obtained from dividing ST(0) by ST(1).",
    "Replace ST(0) with the IEEE remainder obtained from dividing ST(0) by ST(1).",
    "Replace ST(0) with its approximate tangent and push 1 onto the FPU stack.",
    "Round ST(0) to an integer.",
    "Load FPU state from m94byte or m108byte.FRSTORâ€”Restore x87 FPU State Protected Mode Exceptions #GP(0) If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit. If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector. #SS(0) If a memory operand effective address is outside the SS segment limit. #NM CR0.EM[bit 2] or CR0.TS[bit 3] = 1. #PF(fault-code) If a page fault occurs. #AC(0) If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3. #UD If the LOCK prefix is used. Real-Address Mode Exceptions #GP If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit. #SS If a memory operand effective address is outside the SS segment limit. #NM CR0.EM[bit 2] or CR0.TS[bit 3] = 1. #UD If the LOCK prefix is used. Virtual-8086 Mode Exceptions #GP(0) If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit. #SS(0) If a memory operand effective address is outside the SS segment limit. #NM CR0.EM[bit 2] or CR0.TS[bit 3] = 1. #PF(fault-code) If a page fault occurs. #AC(0) If alignment checking is enabled and an unaligned memory reference is made. #UD If the LOCK prefix is used. Compatibility Mode Exceptions Same exceptions as in protected mode. 64-Bit Mode Exceptions #SS(0) If a memory address referencing the SS segment is in a non-canonical form. #GP(0) If the memory address is in a non-canonical form. #NM CR0.EM[bit 2] or CR0.TS[bit 3] = 1. #PF(fault-code) If a page fault occurs. #AC(0) If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3. #UD If the LOCK prefix is used.",
    "Store FPU state to m94byte or m108byte after checking for pending unmasked floating-point exceptions. Then re-initialize the FPU.",
    "Store FPU environment to m94byte or m108byte without checking for pending unmasked floating- point exceptions. Then re-initialize the FPU.",
    "Scale ST(0) by ST(1).",
    "Replace ST(0) with the approximate of its sine.",
    "Compute the sine and cosine of ST(0); replace ST(0) with the approximate sine, and push the approximate cosine onto the register stack.",
    "Computes square root of ST(0) and stores the result in ST(0).",
    "Copy ST(0) to m32fp.",
    "Copy ST(0) to m64fp.",
    "Copy ST(0) to ST(i).",
    "Copy ST(0) to m32fp and pop register stack.",
    "Copy ST(0) to m64fp and pop register stack.",
    "Copy ST(0) to m80fp and pop register stack.",
    "Copy ST(0) to ST(i) and pop register stack.FST/FSTPâ€”Store Floating Point Value Floating-Point Exceptions #IS Stack underflow occurred. #IA If destination result is an SNaN value or unsupported format, except when the destination format is in double extended-precision floating-point format. #U Result is too small for the destination format. #O Result is too large for the destination format. #P Value cannot be represented exactly in destination format. Protected Mode Exceptions #GP(0) If the destination is located in a non-writable segment. If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit. If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector. #SS(0) If a memory operand effective address is outside the SS segment limit. #NM CR0.EM[bit 2] or CR0.TS[bit 3] = 1. #PF(fault-code) If a page fault occurs. #AC(0) If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3. #UD If the LOCK prefix is used. Real-Address Mode Exceptions #GP If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit. #SS If a memory operand effective address is outside the SS segment limit. #NM CR0.EM[bit 2] or CR0.TS[bit 3] = 1. #UD If the LOCK prefix is used. Virtual-8086 Mode Exceptions #GP(0) If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit. #SS(0) If a memory operand effective address is outside the SS segment limit. #NM CR0.EM[bit 2] or CR0.TS[bit 3] = 1. #PF(fault-code) If a page fault occurs. #AC(0) If alignment checking is enabled and an unaligned memory reference is made. #UD If the LOCK prefix is used. Compatibility Mode Exceptions Same exceptions as in protected mode. 64-Bit Mode Exceptions #SS(0) If a memory address referencing the SS segment is in a non-canonical form. #GP(0) If the memory address is in a non-canonical form. #NM CR0.EM[bit 2] or CR0.TS[bit 3] = 1. #MF If there is a pending x87 FPU exception. #PF(fault-code) If a page fault occurs. #AC(0) If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3. #UD If the LOCK prefix is used.",
    "Store FPU control word to m2byte after checking for pending unmasked floating-point exceptions.",
    "Store FPU control word to m2byte without checking for pending unmasked floating-point exceptions.",
    "Store FPU environment to m14byte or m28byte after checking for pending unmasked floating-point exceptions. Then mask all floating-point exceptions.",
    "Store FPU environment to m14byte or m28byte without checking for pending unmasked floating- point exceptions. Then mask all floating- point exceptions.",
    "Store FPU status word at m2byte after checking for pending unmasked floating-point exceptions.",
    "Store FPU status word in AX register after checking for pending unmasked floating-point exceptions.",
    "Store FPU status word at m2byte without checking for pending unmasked floating-point exceptions.",
    "Store FPU status word in AX register without checking for pending unmasked floating-point exceptions.",
    "Subtract m32fp from ST(0) and store result in ST(0).",
    "Subtract m64fp from ST(0) and store result in ST(0).",
    "Subtract ST(i) from ST(0) and store result in ST(0).",
    "Subtract ST(0) from ST(i) and store result in ST(i).",
    "Subtract ST(0) from ST(i), store result in ST(i), and pop register stack.",
    "Subtract ST(0) from ST(1), store result in ST(1), and pop register stack.",
    "Subtract m32int from ST(0) and store result in ST(0).",
    "Subtract m16int from ST(0) and store result in ST(0).FSUB/FSUBP/FISUBâ€”Subtract This instructionâ€™s operation is the same in non-64-bit modes and 64-bit mode.",
    "Subtract ST(0) from m32fp and store result in ST(0).",
    "Subtract ST(0) from m64fp and store result in ST(0).",
    "Subtract ST(0) from ST(i) and store result in ST(0).",
    "Subtract ST(i) from ST(0) and store result in ST(i).",
    "Subtract ST(i) from ST(0), store result in ST(i), and pop register stack.",
    "Subtract ST(1) from ST(0), store result in ST(1), and pop register stack.",
    "Subtract ST(0) from m32int and store result in ST(0).",
    "Subtract ST(0) from m16int and store result in ST(0).FSUBR/FSUBRP/FISUBRâ€”Reverse Subtract This instructionâ€™s operation is the same in non-64-bit modes and 64-bit mode.",
    "Compare ST(0) with 0.0.",
    "Compare ST(0) with ST(i).",
    "Compare ST(0) with ST(1).",
    "Compare ST(0) with ST(i) and pop register stack.",
    "Compare ST(0) with ST(1) and pop register stack.",
    "Compare ST(0) with ST(1) and pop register stack twice.",
    "Classify value or number in ST(0).",
    "Exchange the contents of ST(0) and ST(i).",
    "Exchange the contents of ST(0) and ST(1).FXCHâ€”Exchange Register Contents Compatibility Mode Exceptions Same exceptions as in protected mode. 64-Bit Mode Exceptions Same exceptions as in protected mode.",
    "Restore the x87 FPU, MMX, XMM, and MXCSR register state from m512byte.",
    "Restore the x87 FPU, MMX, XMM, and MXCSR register state from m512byte.",
    "Save the x87 FPU, MMX, XMM, and MXCSR register state to m512byte.",
    "Save the x87 FPU, MMX, XMM, and MXCSR register state to m512byte.",
    "Separate value in ST(0) into exponent and significand, store exponent in ST(0), and push the significand onto the register stack.",
    "Replace ST(1) with (ST(1) âˆ— log ST(0)) and pop the register stack.",
    "Replace ST(1) with ST(1) âˆ— log (ST(0) + 1.0) and pop the register stack.",
    "Horizontal add packed double-precision floating-point values from xmm2/m128 to xmm1.",
    "Horizontal add packed double-precision floating-point values from xmm2 and xmm3/mem.",
    "Horizontal add packed double-precision floating-point values from ymm2 and ymm3/mem.",
    "Horizontal add packed single-precision floating-point values from xmm2/m128 to xmm1.",
    "Horizontal add packed single-precision floating-point values from xmm2 and xmm3/mem.",
    "Horizontal add packed single-precision floating-point values from ymm2 and ymm3/mem.",
    "Halt",
    "Horizontal subtract packed double-precision floating-point values from xmm2/m128 to xmm1.",
    "Horizontal subtract packed double-precision floating-point values from xmm2 and xmm3/mem.",
    "Horizontal subtract packed double-precision floating-point values from ymm2 and ymm3/mem.",
    "Horizontal subtract packed single-precision floating-point values from xmm2/m128 to xmm1.",
    "Horizontal subtract packed single-precision floating-point values from xmm2 and xmm3/mem.",
    "Horizontal subtract packed single-precision floating-point values from ymm2 and ymm3/mem.",
    "Signed divide AX by r/m8, with result stored in: AL â† Quotient, AH â† Remainder.",
    "Signed divide AX by r/m8, with result stored in AL â† Quotient, AH â† Remainder.",
    "Signed divide DX:AX by r/m16, with result stored in AX â† Quotient, DX â† Remainder.",
    "Signed divide EDX:EAX by r/m32, with result stored in EAX â† Quotient, EDX â† Remainder.",
    "Signed divide RDX:RAX by r/m64, with result stored in RAX â† Quotient, RDX â† Remainder.",
    "AXâ† AL âˆ— r/m byte.",
    "DX:AX â† AX âˆ— r/m word.",
    "EDX:EAX â† EAX âˆ— r/m32.",
    "RDX:RAX â† RAX âˆ— r/m64.",
    "word register â† word register âˆ— r/m16.",
    "doubleword register â† doubleword register âˆ— r/m32.",
    "Quadword register â† Quadword register âˆ— r/m64.",
    "word register â† r/m16 âˆ— sign-extended immediate byte.",
    "doubleword register â† r/m32 âˆ— sign- extended immediate byte.",
    "Quadword register â† r/m64 âˆ— sign-extended immediate byte.",
    "word register â† r/m16 âˆ— immediate word.",
    "doubleword register â† r/m32 âˆ— immediate doubleword.",
    "Quadword register â† r/m64 âˆ— immediate doubleword.",
    "Input byte from imm8 I/O port address into AL.",
    "Input word from imm8 I/O port address into AX.",
    "Input dword from imm8 I/O port address into EAX.",
    "Input byte from I/O port in DX into AL.",
    "Input word from I/O port in DX into AX.",
    "Input doubleword from I/O port in DX into EAX.",
    "Increment r/m byte by 1.",
    "Increment r/m byte by 1.",
    "Increment r/m word by 1.",
    "Increment r/m doubleword by 1.",
    "Increment r/m quadword by 1.",
    "Increment word register by 1.",
    "Increment doubleword register by 1.",
    "Input byte from I/O port specified in DX into memory location specified in ES:(E)DI or RDI.",
    "Input word from I/O port specified in DX into memory location specified in ES:(E)DI or RDI.",
    "Input doubleword from I/O port specified in DX into memory location specified in ES:(E)DI or RDI.",
    "Input byte from I/O port specified in DX into memory location specified with ES:(E)DI or RDI.",
    "Input word from I/O port specified in DX into memory location specified in ES:(E)DI or RDI.",
    "Input doubleword from I/O port specified in DX into memory location specified in ES:(E)DI or RDI.",
    "Insert a single-precision floating-point value selected by imm8 from xmm2/m32 into xmm1 at the specified destination element specified by imm8 and zero out destination elements in xmm1 as indicated in imm8.",
    "Insert a single-precision floating-point value selected by imm8 from xmm3/m32 and merge with values in xmm2 at the specified destination element specified by imm8 and write out the result and zero out destination elements in xmm1 as indicated in imm8.",
    "Insert a single-precision floating-point value selected by imm8 from xmm3/m32 and merge with values in xmm2 at the specified destination element specified by imm8 and write out the result and zero out destination elements in xmm1 as indicated in imm8.",
    "Interrupt 3â€”trap to debugger. CD ib INT imm8 I Valid Valid Interrupt vector specified by immediate byte.",
    "Interrupt 4â€”if overflow flag is 1.",
    "Flush internal caches; initiate flushing of external caches.",
    "Invalidate TLB entries for page containing m.",
    "Invalidates entries in the TLBs and paging-structure caches based on invalidation type in r32 and descrip-tor in m128.",
    "Invalidates entries in the TLBs and paging-structure caches based on invalidation type in r64 and descrip-tor in m128.",
    "Interrupt return (16-bit operand size).",
    "Interrupt return (32-bit operand size).",
    "Interrupt return (64-bit operand size).",
    "Jump short if above (CF=0 and ZF=0).",
    "Jump short if above or equal (CF=0).",
    "Jump short if below (CF=1).",
    "Jump short if below or equal (CF=1 or ZF=1).",
    "Jump short if carry (CF=1).",
    "Jump short if CX register is 0.",
    "Jump short if ECX register is 0.",
    "Jump short if RCX register is 0.",
    "Jump short if equal (ZF=1).",
    "Jump short if greater (ZF=0 and SF=OF).",
    "Jump short if greater or equal (SF=OF).",
    "Jump short if less (SFâ‰  OF).",
    "Jump short if less or equal (ZF=1 or SFâ‰  OF).",
    "Jump short if not above (CF=1 or ZF=1).",
    "Jump short if not above or equal (CF=1).",
    "Jump short if not below (CF=0).",
    "Jump short if not below or equal (CF=0 and ZF=0).",
    "Jump short if not carry (CF=0).",
    "Jump short if not equal (ZF=0).",
    "Jump short if not greater (ZF=1 or SFâ‰  OF).",
    "Jump short if not greater or equal (SFâ‰  OF).",
    "Jump short if not less (SF=OF).",
    "Jump short if not less or equal (ZF=0 and SF=OF).",
    "Jump short if not overflow (OF=0).",
    "Jump short if not parity (PF=0).",
    "Jump short if not sign (SF=0).",
    "Jump short if not zero (ZF=0).",
    "Jump short if overflow (OF=1).",
    "Jump short if parity (PF=1).",
    "Jump short if parity even (PF=1).",
    "Jump short if parity odd (PF=0).",
    "Jump short if sign (SF=1).",
    "Jump short if zero (ZF = 1).",
    "Jump near if above (CF=0 and ZF=0). Not supported in 64-bit mode.",
    "Jump near if above (CF=0 and ZF=0).",
    "Jump near if above or equal (CF=0). Not supported in 64-bit mode.Jccâ€”Jump if Condition Is Met",
    "Jump near if above or equal (CF=0).",
    "Jump near if below (CF=1). Not supported in 64-bit mode.",
    "Jump near if below (CF=1).",
    "Jump near if below or equal (CF=1 or ZF=1). Not supported in 64-bit mode.",
    "Jump near if below or equal (CF=1 or ZF=1).",
    "Jump near if carry (CF=1). Not supported in 64-bit mode.",
    "Jump near if carry (CF=1).",
    "Jump near if equal (ZF=1). Not supported in 64-bit mode.",
    "Jump near if equal (ZF=1).",
    "Jump near if 0 (ZF=1). Not supported in 64-bit mode.",
    "Jump near if 0 (ZF=1).",
    "Jump near if greater (ZF=0 and SF=OF). Not supported in 64-bit mode.",
    "Jump near if greater (ZF=0 and SF=OF).",
    "Jump near if greater or equal (SF=OF). Not supported in 64-bit mode.",
    "Jump near if greater or equal (SF=OF).",
    "Jump near if less (SFâ‰  OF). Not supported in 64-bit mode.",
    "Jump near if less (SFâ‰  OF).",
    "Jump near if less or equal (ZF=1 or SFâ‰  OF). Not supported in 64-bit mode.",
    "Jump near if less or equal (ZF=1 or SFâ‰  OF).",
    "Jump near if not above (CF=1 or ZF=1). Not supported in 64-bit mode.",
    "Jump near if not above (CF=1 or ZF=1).",
    "Jump near if not above or equal (CF=1). Not supported in 64-bit mode.",
    "Jump near if not above or equal (CF=1).",
    "Jump near if not below (CF=0). Not supported in 64-bit mode.",
    "Jump near if not below (CF=0).",
    "Jump near if not below or equal (CF=0 and ZF=0). Not supported in 64-bit mode.",
    "Jump near if not below or equal (CF=0 and ZF=0).",
    "Jump near if not carry (CF=0). Not supported in 64-bit mode.",
    "Jump near if not carry (CF=0).",
    "Jump near if not equal (ZF=0). Not supported in 64-bit mode.",
    "Jump near if not equal (ZF=0).",
    "Jump near if not greater (ZF=1 or SFâ‰  OF). Not supported in 64-bit mode.",
    "Jump near if not greater (ZF=1 or SFâ‰  OF).",
    "Jump near if not greater or equal (SFâ‰  OF). Not supported in 64-bit mode.",
    "Jump near if not greater or equal (SFâ‰  OF).",
    "Jump near if not less (SF=OF). Not supported in 64-bit mode.",
    "Jump near if not less (SF=OF).",
    "Jump near if not less or equal (ZF=0 and SF=OF). Not supported in 64-bit mode.",
    "Jump near if not less or equal (ZF=0 and SF=OF).",
    "Jump near if not overflow (OF=0). Not supported in 64-bit mode.",
    "Jump near if not overflow (OF=0).",
    "Jump near if not parity (PF=0). Not supported in 64-bit mode.",
    "Jump near if not parity (PF=0).",
    "Jump near if not sign (SF=0). Not supported in 64-bit mode.",
    "Jump near if not sign (SF=0).",
    "Jump near if not zero (ZF=0). Not supported in 64-bit mode.",
    "Jump near if not zero (ZF=0).",
    "Jump near if overflow (OF=1). Not supported in 64-bit mode.",
    "Jump near if overflow (OF=1).",
    "Jump near if parity (PF=1). Not supported in 64-bit mode.",
    "Jump near if parity (PF=1).",
    "Jump near if parity even (PF=1). Not supported in 64-bit mode.",
    "Jump near if parity even (PF=1).",
    "Jump near if parity odd (PF=0). Not supported in 64-bit mode.",
    "Jump near if parity odd (PF=0).",
    "Jump near if sign (SF=1). Not supported in 64- bit mode.",
    "Jump short, RIP = RIP + 8-bit displacement sign extended to 64-bits",
    "Jump near, relative, displacement relative to next instruction. Not supported in 64-bit mode.",
    "Jump near, relative, RIP = RIP + 32-bit displacement sign extended to 64-bits",
    "Jump near, absolute indirect, address = zero- extended r/m16. Not supported in 64-bit mode.",
    "Jump near, absolute indirect, address given in r/m32. Not supported in 64-bit mode.",
    "Jump near, absolute indirect, RIP = 64-Bit offset from register or memory",
    "Jump far, absolute, address given in operand",
    "Jump far, absolute, address given in operand",
    "Jump far, absolute indirect, address given in m16:16",
    "Jump far, absolute indirect, address given in m16:32.",
    "Jump far, absolute indirect, address given in m16:64.",
    "Add 16 bits masks in k2 and k3 and place result in k1.",
    "Add 8 bits masks in k2 and k3 and place result in k1.",
    "Add 64 bits masks in k2 and k3 and place result in k1.",
    "Add 32 bits masks in k2 and k3 and place result in k1.",
    "Bitwise AND NOT 16 bits masks k2 and k3 and place result in k1.",
    "Bitwise AND NOT 8 bits masks k1 and k2 and place result in k1.",
    "Bitwise AND NOT 64 bits masks k2 and k3 and place result in k1.",
    "Bitwise AND NOT 32 bits masks k2 and k3 and place result in k1.",
    "Bitwise AND 16 bits masks k2 and k3 and place result in k1.",
    "Bitwise AND 8 bits masks k2 and k3 and place result in k1.",
    "Bitwise AND 64 bits masks k2 and k3 and place result in k1.",
    "Bitwise AND 32 bits masks k2 and k3 and place result in k1.",
    "Move 16 bits mask from k2/m16 and store the result in k1.",
    "Move 8 bits mask from k2/m8 and store the result in k1.",
    "Move 64 bits mask from k2/m64 and store the result in k1.",
    "Move 32 bits mask from k2/m32 and store the result in k1.",
    "Move 16 bits mask from k1 and store the result in m16.",
    "Move 8 bits mask from k1 and store the result in m8.",
    "Move 64 bits mask from k1 and store the result in m64.",
    "Move 32 bits mask from k1 and store the result in m32.",
    "Move 16 bits mask from r32 to k1.",
    "Move 8 bits mask from r32 to k1.",
    "Move 64 bits mask from r64 to k1.",
    "Move 32 bits mask from r32 to k1.",
    "Move 16 bits mask from k1 to r32.",
    "Move 8 bits mask from k1 to r32.",
    "Move 64 bits mask from k1 to r64.",
    "Move 32 bits mask from k1 to r32.",
    "Bitwise NOT of 16 bits mask k2.",
    "Bitwise NOT of 8 bits mask k2.",
    "Bitwise NOT of 64 bits mask k2.",
    "Bitwise NOT of 32 bits mask k2.",
    "Bitwise OR 16 bits masks k1 and k2 and update ZF and CF accordingly.",
    "Bitwise OR 8 bits masks k1 and k2 and update ZF and CF accordingly.",
    "Bitwise OR 64 bits masks k1 and k2 and update ZF and CF accordingly.",
    "Bitwise OR 32 bits masks k1 and k2 and update ZF and CF accordingly.",
    "Bitwise OR 16 bits masks k2 and k3 and place result in k1.",
    "Bitwise OR 8 bits masks k2 and k3 and place result in k1.",
    "Bitwise OR 64 bits masks k2 and k3 and place result in k1.",
    "Bitwise OR 32 bits masks k2 and k3 and place result in k1.",
    "Shift left 16 bits in k2 by immediate and write result in k1.",
    "Shift left 8 bits in k2 by immediate and write result in k1.",
    "Shift left 64 bits in k2 by immediate and write result in k1.",
    "Shift left 32 bits in k2 by immediate and write result in k1.",
    "Shift right 16 bits in k2 by immediate and write result in k1.",
    "Shift right 8 bits in k2 by immediate and write result in k1.",
    "Shift right 64 bits in k2 by immediate and write result in k1.",
    "Shift right 32 bits in k2 by immediate and write result in k1.",
    "Set ZF and CF depending on sign bit AND and ANDN of 16 bits mask register sources.",
    "Set ZF and CF depending on sign bit AND and ANDN of 8 bits mask register sources.",
    "Set ZF and CF depending on sign bit AND and ANDN of 64 bits mask register sources.",
    "Set ZF and CF depending on sign bit AND and ANDN of 32 bits mask register sources.",
    "Unpack and interleave 8 bits masks in k2 and k3 and write word result in k1.",
    "Unpack and interleave 16 bits in k2 and k3 and write double-word result in k1.",
    "Unpack and interleave 32 bits masks in k2 and k3 and write quadword result in k1.",
    "Bitwise XNOR 16 bits masks k2 and k3 and place result in k1.",
    "Bitwise XNOR 8 bits masks k2 and k3 and place result in k1.",
    "Bitwise XNOR 64 bits masks k2 and k3 and place result in k1.",
    "Bitwise XNOR 32 bits masks k2 and k3 and place result in k1.",
    "Bitwise XOR 16 bits masks k2 and k3 and place result in k1.",
    "Bitwise XOR 8 bits masks k2 and k3 and place result in k1.",
    "Bitwise XOR 64 bits masks k2 and k3 and place result in k1.",
    "Bitwise XOR 32 bits masks k2 and k3 and place result in k1.",
    "Load: AH â† EFLAGS(SF:ZF:0:AF:0:PF:1:CF).",
    "r16 â† access rights referenced by r16/m16",
    "AnyRegister â† access rights referenced by r32/m16",
    "Load unaligned data from mem and return double quadword in xmm1.",
    "Load unaligned packed integer values from mem to xmm1.",
    "Load unaligned packed integer values from mem to ymm1.",
    "Load MXCSR register from m32.",
    "Load MXCSR register from m32.",
    "Load DS:r16 with far pointer from memory.",
    "Load DS:r32 with far pointer from memory.",
    "Load SS:r16 with far pointer from memory.",
    "Load SS:r32 with far pointer from memory.",
    "Load SS:r64 with far pointer from memory.",
    "Load ES:r16 with far pointer from memory.",
    "Load ES:r32 with far pointer from memory.",
    "Load FS:r16 with far pointer from memory.",
    "Load FS:r32 with far pointer from memory.",
    "Load FS:r64 with far pointer from memory.",
    "Load GS:r16 with far pointer from memory.",
    "Load GS:r32 with far pointer from memory.",
    "Load GS:r64 with far pointer from memory.",
    "Store effective address for m in register r16.",
    "Store effective address for m in register r32.",
    "Store effective address for m in register r64.",
    "Set SP to BP, then pop BP.",
    "Set ESP to EBP, then pop EBP.",
    "Set RSP to RBP, then pop RBP.",
    "Serializes load operations.",
    "Load m into GDTR.",
    "Load m into IDTR.",
    "Load m into GDTR.",
    "Load m into IDTR.",
    "Load segment selector r/m16 into LDTR.",
    "Loads r/m16 in machine status word of CR0.",
    "Asserts LOCK# signal for duration of the accompanying instruction.",
    "For legacy mode, Load byte at address DS:(E)SI into AL. For 64-bit mode load byte at address (R)SI into AL.",
    "For legacy mode, Load word at address DS:(E)SI into AX. For 64-bit mode load word at address (R)SI into AX.",
    "For legacy mode, Load dword at address DS:(E)SI into EAX. For 64-bit mode load dword at address (R)SI into EAX.",
    "Load qword at address (R)SI into RAX.",
    "For legacy mode, Load byte at address DS:(E)SI into AL. For 64-bit mode load byte at address (R)SI into AL.",
    "For legacy mode, Load word at address DS:(E)SI into AX. For 64-bit mode load word at address (R)SI into AX.",
    "For legacy mode, Load dword at address DS:(E)SI into EAX. For 64-bit mode load dword at address (R)SI into EAX.",
    "Load qword at address (R)SI into RAX.",
    "Decrement count; jump short if count â‰  0.",
    "Decrement count; jump short if count â‰  0 and ZF = 1.",
    "Decrement count; jump short if count â‰  0 and ZF = 0.",
    "Load: r16 â† segment limit, selector r16/m16.",
    "Load: r32 â† segment limit, selector r32/m16.",
    "Load: r64 â† segment limit, selector r32/m16",
    "Load r/m16 into task register.",
    "Count the number of leading zero bits in r/m16, return result in r16.",
    "Count the number of leading zero bits in r/m32, return result in r32.",
    "Count the number of leading zero bits in r/m64, return result in r64.",
    "Selectively write bytes from xmm1 to memory location using the byte mask in xmm2. The default memory location is specified by DS:DI/EDI/RDI.",
    "Selectively write bytes from xmm1 to memory location using the byte mask in xmm2. The default memory location is specified by DS:DI/EDI/RDI.",
    "Selectively write bytes from mm1 to memory location using the byte mask in mm2. The default memory location is specified by DS:DI/EDI/RDI.",
    "Return the maximum double-precision floating-point values between xmm1 and xmm2/m128.",
    "Return the maximum double-precision floating-point values between xmm2 and xmm3/m128.",
    "Return the maximum packed double-precision floating-point values between ymm2 and ymm3/m256.",
    "Return the maximum packed double-precision floating-point values between xmm2 and xmm3/m128/m64bcst and store result in xmm1 subject to writemask k1.",
    "Return the maximum packed double-precision floating-point values between ymm2 and ymm3/m256/m64bcst and store result in ymm1 subject to writemask k1.",
    "Return the maximum packed double-precision floating-point values between zmm2 and zmm3/m512/m64bcst and store result in zmm1 subject to writemask k1.",
    "Return the maximum single-precision floating-point values between xmm1 and xmm2/mem.",
    "Return the maximum single-precision floating-point values between xmm2 and xmm3/mem.",
    "Return the maximum single-precision floating-point values between ymm2 and ymm3/mem.",
    "Return the maximum packed single-precision floating-point values between xmm2 and xmm3/m128/m32bcst and store result in xmm1 subject to writemask k1.",
    "Return the maximum packed single-precision floating-point values between ymm2 and ymm3/m256/m32bcst and store result in ymm1 subject to writemask k1.",
    "Return the maximum packed single-precision floating-point values between zmm2 and zmm3/m512/m32bcst and store result in zmm1 subject to writemask k1.",
    "Return the maximum scalar double-precision floating-point value between xmm2/m64 and xmm1.",
    "Return the maximum scalar double-precision floating-point value between xmm3/m64 and xmm2.",
    "Return the maximum scalar double-precision floating-point value between xmm3/m64 and xmm2.",
    "Return the maximum scalar single-precision floating-point value between xmm2/m32 and xmm1.",
    "Return the maximum scalar single-precision floating-point value between xmm3/m32 and xmm2.",
    "Return the maximum scalar single-precision floating-point value between xmm3/m32 and xmm2.",
    "Serializes load and store operations.",
    "Return the minimum double-precision floating-point values between xmm1 and xmm2/mem",
    "Return the minimum double-precision floating-point values between xmm2 and xmm3/mem.",
    "Return the minimum packed double-precision floating-point values between ymm2 and ymm3/mem.",
    "Return the minimum packed double-precision floating-point values between xmm2 and xmm3/m128/m64bcst and store result in xmm1 subject to writemask k1.",
    "Return the minimum packed double-precision floating-point values between ymm2 and ymm3/m256/m64bcst and store result in ymm1 subject to writemask k1.",
    "Return the minimum packed double-precision floating-point values between zmm2 and zmm3/m512/m64bcst and store result in zmm1 subject to writemask k1.",
    "Return the minimum single-precision floating-point values between xmm1 and xmm2/mem.",
    "Return the minimum single-precision floating-point values between xmm2 and xmm3/mem.",
    "Return the minimum single double-precision floating-point values between ymm2 and ymm3/mem.",
    "Return the minimum packed single-precision floating-point values between xmm2 and xmm3/m128/m32bcst and store result in xmm1 subject to writemask k1.",
    "Return the minimum packed single-precision floating-point values between ymm2 and ymm3/m256/m32bcst and store result in ymm1 subject to writemask k1.",
    "Return the minimum packed single-precision floating-point values between zmm2 and zmm3/m512/m32bcst and store result in zmm1 subject to writemask k1.",
    "Return the minimum scalar double-precision floating-point value between xmm2/m64 and xmm1.",
    "Return the minimum scalar double-precision floating-point value between xmm3/m64 and xmm2.",
    "Return the minimum scalar double-precision floating-point value between xmm3/m64 and xmm2.",
    "Return the minimum scalar single-precision floating-point value between xmm2/m32 and xmm1.",
    "Return the minimum scalar single-precision floating-point value between xmm3/m32 and xmm2.",
    "Return the minimum scalar single-precision floating-point value between xmm3/m32 and xmm2.",
    "Sets up a linear address range to be monitored by hardware and activates the monitor. The address range should be a write- back memory caching type. The address is DS:RAX/EAX/AX.",
    "Move r8 to r/m8.",
    "Move r8 to r/m8.",
    "Move r16 to r/m16.",
    "Move r32 to r/m32.",
    "Move r64 to r/m64.",
    "Move r/m8 to r8.",
    "Move r/m8 to r8.",
    "Move r/m16 to r16.",
    "Move r/m32 to r32.",
    "Move r/m64 to r64.",
    "Move segment register to r/m16.",
    "Move zero extended 16-bit segment register to r/m64.",
    "Move r/m16 to segment register.",
    "Move lower 16 bits of r/m64 to segment register.",
    "Move byte at (seg:offset) to AL.",
    "Move byte at (offset) to AL.",
    "Move word at (seg:offset) to AX.",
    "Move doubleword at (seg:offset) to EAX.",
    "Move quadword at (offset) to RAX.",
    "Move AL to (seg:offset).",
    "Move AL to (offset).",
    "Move AX to (seg:offset).",
    "Move EAX to (seg:offset).",
    "Move RAX to (offset).",
    "Move imm8 to r8.",
    "Move imm8 to r8.",
    "Move imm16 to r16.",
    "Move imm32 to r32.",
    "Move imm64 to r64.",
    "Move imm8 to r/m8.",
    "Move imm8 to r/m8.",
    "Move imm16 to r/m16.",
    "Move imm32 to r/m32.",
    "Move imm32 sign extended to 64-bits to r/m64.",
    "Move control register to r32.",
    "Move extended control register to r64.",
    "Move extended CR8 to r64.",
    "Move r32 to control register.",
    "Move r64 to extended control register.",
    "Move r64 to extended CR8.",
    "Move debug register to r32.",
    "Move extended debug register to r64.",
    "Move r32 to debug register.",
    "Move r64 to extended debug register.",
    "Move aligned packed double-precision floating-point values from xmm2/mem to xmm1.",
    "Move aligned packed double-precision floating-point values from xmm1 to xmm2/mem.",
    "Move aligned packed double-precision floating-point values from xmm2/mem to xmm1.",
    "Move aligned packed double-precision floating-point values from xmm1 to xmm2/mem.",
    "Move aligned packed double-precision floating-point values from ymm2/mem to ymm1.",
    "Move aligned packed double-precision floating-point values from ymm1 to ymm2/mem.",
    "Move aligned packed double-precision floating-point values from xmm2/m128 to xmm1 using writemask k1.",
    "Move aligned packed double-precision floating-point values from ymm2/m256 to ymm1 using writemask k1.",
    "Move aligned packed double-precision floating-point values from zmm2/m512 to zmm1 using writemask k1.",
    "Move aligned packed double-precision floating-point values from xmm1 to xmm2/m128 using writemask k1.",
    "Move aligned packed double-precision floating-point values from ymm1 to ymm2/m256 using writemask k1.",
    "Move aligned packed double-precision floating-point values from zmm1 to zmm2/m512 using writemask k1.",
    "Move aligned packed single-precision floating-point values from xmm2/mem to xmm1.",
    "Move aligned packed single-precision floating-point values from xmm1 to xmm2/mem.",
    "Move aligned packed single-precision floating-point values from xmm2/mem to xmm1.",
    "Move aligned packed single-precision floating-point values from xmm1 to xmm2/mem.",
    "Move aligned packed single-precision floating-point values from ymm2/mem to ymm1.",
    "Move aligned packed single-precision floating-point values from ymm1 to ymm2/mem.",
    "Move aligned packed single-precision floating-point values from xmm2/m128 to xmm1 using writemask k1.",
    "Move aligned packed single-precision floating-point values from ymm2/m256 to ymm1 using writemask k1.",
    "Move aligned packed single-precision floating-point values from zmm2/m512 to zmm1 using writemask k1.",
    "Move aligned packed single-precision floating-point values from xmm1 to xmm2/m128 using writemask k1.",
    "Move aligned packed single-precision floating-point values from ymm1 to ymm2/m256 using writemask k1.",
    "Move aligned packed single-precision floating-point values from zmm1 to zmm2/m512 using writemask k1.",
    "Reverse byte order in m16 and move to r16.",
    "Reverse byte order in m32 and move to r32.",
    "Reverse byte order in m64 and move to r64.",
    "Reverse byte order in r16 and move to m16.",
    "Reverse byte order in r32 and move to m32.",
    "Reverse byte order in r64 and move to m64.",
    "Move doubleword from r/m32 to mm.",
    "Move quadword from r/m64 to mm.",
    "Move doubleword from mm to r/m32.",
    "Move quadword from mm to r/m64.",
    "Move doubleword from r/m32 to xmm.",
    "Move quadword from r/m64 to xmm.",
    "Move doubleword from xmm register to r/m32.",
    "Move quadword from xmm register to r/m64.",
    "Move doubleword from r/m32 to xmm1.",
    "Move quadword from r/m64 to xmm1.",
    "Move doubleword from xmm1 register to r/m32.",
    "Move quadword from xmm1 register to r/m64.",
    "Move doubleword from r/m32 to xmm1.",
    "Move quadword from r/m64 to xmm1.",
    "Move doubleword from xmm1 register to r/m32.",
    "Move quadword from xmm1 register to r/m64.",
    "Move double-precision floating-point value from xmm2/m64 and duplicate into xmm1.",
    "Move double-precision floating-point value from xmm2/m64 and duplicate into xmm1.",
    "Move even index double-precision floating-point values from ymm2/mem and duplicate each element into ymm1.",
    "Move double-precision floating-point value from xmm2/m64 and duplicate each element into xmm1 subject to writemask k1.",
    "Move even index double-precision floating-point values from ymm2/m256 and duplicate each element into ymm1 subject to writemask k1.",
    "Move even index double-precision floating-point values from zmm2/m512 and duplicate each element into zmm1 subject to writemask k1.",
    "Move low quadword from xmm to mmx register.",
    "Move aligned packed integer values from xmm2/mem to xmm1.",
    "Move aligned packed integer values from xmm1 to xmm2/mem.",
    "Move aligned packed integer values from xmm2/mem to xmm1.",
    "Move aligned packed integer values from xmm1 to xmm2/mem.",
    "Move aligned packed integer values from ymm2/mem to ymm1.",
    "Move aligned packed integer values from ymm1 to ymm2/mem.",
    "Move aligned packed doubleword integer values from xmm2/m128 to xmm1 using writemask k1.",
    "Move aligned packed doubleword integer values from ymm2/m256 to ymm1 using writemask k1.",
    "Move aligned packed doubleword integer values from zmm2/m512 to zmm1 using writemask k1.",
    "Move aligned packed doubleword integer values from xmm1 to xmm2/m128 using writemask k1.",
    "Move aligned packed doubleword integer values from ymm1 to ymm2/m256 using writemask k1.",
    "Move aligned packed doubleword integer values from zmm1 to zmm2/m512 using writemask k1.",
    "Move aligned quadword integer values from xmm2/m128 to xmm1 using writemask k1.",
    "Move aligned quadword integer values from ymm2/m256 to ymm1 using writemask k1.",
    "Move aligned packed quadword integer values from zmm2/m512 to zmm1 using writemask k1.",
    "Move aligned packed quadword integer values from xmm1 to xmm2/m128 using writemask k1.",
    "Move aligned packed quadword integer values from ymm1 to ymm2/m256 using writemask k1.",
    "Move aligned packed quadword integer values from zmm1 to zmm2/m512 using writemask k1.MOVDQA,VMOVDQA32/64â€”Move Aligned Packed Integer Values",
    "Move unaligned packed integer values from xmm2/m128 to xmm1.",
    "Move unaligned packed integer values from xmm1 to xmm2/m128.",
    "Move unaligned packed integer values from xmm2/m128 to xmm1.",
    "Move unaligned packed integer values from xmm1 to xmm2/m128.",
    "Move unaligned packed integer values from ymm2/m256 to ymm1.",
    "Move unaligned packed integer values from ymm1 to ymm2/m256.",
    "Move unaligned packed byte integer values from xmm2/m128 to xmm1 using writemask k1.",
    "Move unaligned packed byte integer values from ymm2/m256 to ymm1 using writemask k1.",
    "Move unaligned packed byte integer values from zmm2/m512 to zmm1 using writemask k1.",
    "Move unaligned packed byte integer values from xmm1 to xmm2/m128 using writemask k1.",
    "Move unaligned packed byte integer values from ymm1 to ymm2/m256 using writemask k1.",
    "Move unaligned packed byte integer values from zmm1 to zmm2/m512 using writemask k1.",
    "Move unaligned packed word integer values from xmm2/m128 to xmm1 using writemask k1.",
    "Move unaligned packed word integer values from ymm2/m256 to ymm1 using writemask k1.",
    "Move unaligned packed word integer values from zmm2/m512 to zmm1 using writemask k1.",
    "Move unaligned packed word integer values from xmm1 to xmm2/m128 using writemask k1.",
    "Move unaligned packed word integer values from ymm1 to ymm2/m256 using writemask k1.",
    "Move unaligned packed word integer values from zmm1 to zmm2/m512 using writemask k1.",
    "Move unaligned packed doubleword integer values from xmm2/m128 to xmm1 using writemask k1.",
    "Move unaligned packed doubleword integer values from ymm2/m256 to ymm1 using writemask k1.",
    "Move unaligned packed doubleword integer values from zmm2/m512 to zmm1 using writemask k1.",
    "Move unaligned packed doubleword integer values from xmm1 to xmm2/m128 using writemask k1.",
    "Move unaligned packed doubleword integer values from ymm1 to ymm2/m256 using writemask k1.",
    "Move unaligned packed doubleword integer values from zmm1 to zmm2/m512 using writemask k1.",
    "Move unaligned packed quadword integer values from xmm2/m128 to xmm1 using writemask k1.",
    "Move unaligned packed quadword integer values from ymm2/m256 to ymm1 using writemask k1.",
    "Move unaligned packed quadword integer values from zmm2/m512 to zmm1 using writemask k1.",
    "Move unaligned packed quadword integer values from xmm1 to xmm2/m128 using writemask k1.",
    "Move unaligned packed quadword integer values from ymm1 to ymm2/m256 using writemask k1.",
    "Move unaligned packed quadword integer values from zmm1 to zmm2/m512 using writemask k1.",
    "Move two packed single-precision floating-point values from high quadword of xmm2 to low quadword of xmm1.",
    "Merge two packed single-precision floating-point values from high quadword of xmm3 and low quadword of xmm2.",
    "Merge two packed single-precision floating-point values from high quadword of xmm3 and low quadword of xmm2.",
    "Move double-precision floating-point value from m64 to high quadword of xmm1.",
    "Merge double-precision floating-point value from m64 and the low quadword of xmm1.",
    "Merge double-precision floating-point value from m64 and the low quadword of xmm1.",
    "Move double-precision floating-point value from high quadword of xmm1 to m64.",
    "Move double-precision floating-point value from high quadword of xmm1 to m64.",
    "Move double-precision floating-point value from high quadword of xmm1 to m64.",
    "Move two packed single-precision floating-point values from m64 to high quadword of xmm1.",
    "Merge two packed single-precision floating-point values from m64 and the low quadword of xmm1.",
    "Merge two packed single-precision floating-point values from m64 and the low quadword of xmm1.",
    "Move two packed single-precision floating-point values from high quadword of xmm1 to m64.",
    "Move two packed single-precision floating-point values from high quadword of xmm1 to m64.",
    "Move two packed single-precision floating-point values from high quadword of xmm1 to m64.",
    "Move two packed single-precision floating-point values from low quadword of xmm2 to high quadword of xmm1.",
    "Merge two packed single-precision floating-point values from low quadword of xmm3 and low quadword of xmm2.",
    "Merge two packed single-precision floating-point values from low quadword of xmm3 and low quadword of xmm2.",
    "Move double-precision floating-point value from m64 to low quadword of xmm1.",
    "Merge double-precision floating-point value from m64 and the high quadword of xmm1.",
    "Merge double-precision floating-point value from m64 and the high quadword of xmm1.",
    "Move double-precision floating-point value from low quadword of xmm1 to m64.",
    "Move double-precision floating-point value from low quadword of xmm1 to m64.",
    "Move double -precision floating-point value from low quadword of xmm1 to m64.",
    "Move two packed single-precision floating-point values from m64 to low quadword of xmm1.",
    "Merge two packed single-precision floating-point values from m64 and the high quadword of xmm1.",
    "Merge two packed single-precision floating-point values from m64 and the high quadword of xmm1.",
    "Move two packed single-precision floating-point values from low quadword of xmm1 to m64.",
    "Move two packed single-precision floating-point values from low quadword of xmm1 to m64.",
    "Move two packed single-precision floating-point values from low quadword of xmm1 to m64.",
    "Extract 2-bit sign mask from xmm and store in AnyRegister. The upper bits of r32 or r64 are filled with zeros.",
    "Extract 2-bit sign mask from xmm2 and store in AnyRegister. The upper bits of r32 or r64 are zeroed.",
    "Extract 4-bit sign mask from ymm2 and store in AnyRegister. The upper bits of r32 or r64 are zeroed.",
    "Extract 4-bit sign mask from xmm and store in AnyRegister. The upper bits of r32 or r64 are filled with zeros.",
    "Extract 4-bit sign mask from xmm2 and store in AnyRegister. The upper bits of r32 or r64 are zeroed.",
    "Extract 8-bit sign mask from ymm2 and store in AnyRegister. The upper bits of r32 or r64 are zeroed.",
    "Move packed integer values in xmm1 to m128 using non-temporal hint.",
    "Move packed integer values in xmm1 to m128 using non-temporal hint.",
    "Move packed integer values in ymm1 to m256 using non-temporal hint.",
    "Move packed integer values in xmm1 to m128 using non-temporal hint.",
    "Move packed integer values in zmm1 to m256 using non-temporal hint.",
    "Move packed integer values in zmm1 to m512 using non-temporal hint.",
    "Move double quadword from m128 to xmm1 using non-temporal hint if WC memory type.",
    "Move double quadword from m128 to xmm using non-temporal hint if WC memory type.",
    "Move 256-bit data from m256 to ymm using non-temporal hint if WC memory type.",
    "Move 128-bit data from m128 to xmm using non-temporal hint if WC memory type.",
    "Move 256-bit data from m256 to ymm using non-temporal hint if WC memory type.",
    "Move 512-bit data from m512 to zmm using non-temporal hint if WC memory type.",
    "Move doubleword from r32 to m32 using non- temporal hint.",
    "Move quadword from r64 to m64 using non- temporal hint.",
    "Move packed double-precision values in xmm1 to m128 using non-temporal hint.",
    "Move packed double-precision values in xmm1 to m128 using non-temporal hint.",
    "Move packed double-precision values in ymm1 to m256 using non-temporal hint.",
    "Move packed double-precision values in xmm1 to m128 using non-temporal hint.",
    "Move packed double-precision values in ymm1 to m256 using non-temporal hint.",
    "Move packed double-precision values in zmm1 to m512 using non-temporal hint.",
    "Move packed single-precision values xmm1 to mem using non-temporal hint.",
    "Move packed single-precision values xmm1 to mem using non-temporal hint.",
    "Move packed single-precision values ymm1 to mem using non-temporal hint.",
    "Move packed single-precision values in xmm1 to m128 using non-temporal hint.",
    "Move packed single-precision values in ymm1 to m256 using non-temporal hint.",
    "Move packed single-precision values in zmm1 to m512 using non-temporal hint.",
    "Move quadword from mm to m64 using non- temporal hint.",
    "Move quadword from mm/m64 to mm.",
    "Move quadword from mm to mm/m64.",
    "Move quadword from xmm2/mem64 to xmm1.",
    "Move quadword from xmm2 to xmm1.",
    "Move quadword from xmm2/m64 to xmm1.",
    "Move quadword from xmm1 to xmm2/mem64.",
    "Move quadword from xmm2 register to xmm1/m64.",
    "Move quadword from xmm2 register to xmm1/m64.",
    "Move quadword from mmx to low quadword of xmm.",
    "For legacy mode, Move byte from address DS:(E)SI to ES:(E)DI. For 64-bit mode move byte from address (R|E)SI to (R|E)DI.",
    "For legacy mode, move word from address DS:(E)SI to ES:(E)DI. For 64-bit mode move word at address (R|E)SI to (R|E)DI.",
    "For legacy mode, move dword from address DS:(E)SI to ES:(E)DI. For 64-bit mode move dword from address (R|E)SI to (R|E)DI.",
    "Move qword from address (R|E)SI to (R|E)DI.",
    "For legacy mode, Move byte from address DS:(E)SI to ES:(E)DI. For 64-bit mode move byte from address (R|E)SI to (R|E)DI.",
    "For legacy mode, move word from address DS:(E)SI to ES:(E)DI. For 64-bit mode move word at address (R|E)SI to (R|E)DI.",
    "For legacy mode, move dword from address DS:(E)SI to ES:(E)DI. For 64-bit mode move dword from address (R|E)SI to (R|E)DI.",
    "Move qword from address (R|E)SI to (R|E)DI.",
    "Move scalar double-precision floating-point value from xmm2 to xmm1 register.",
    "Load scalar double-precision floating-point value from m64 to xmm1 register.",
    "Move scalar double-precision floating-point value from xmm2 register to xmm1/m64.",
    "Merge scalar double-precision floating-point value from xmm2 and xmm3 to xmm1 register.",
    "Load scalar double-precision floating-point value from m64 to xmm1 register.",
    "Merge scalar double-precision floating-point value from xmm2 and xmm3 registers to xmm1.",
    "Store scalar double-precision floating-point value from xmm1 register to m64.",
    "Merge scalar double-precision floating-point value from xmm2 and xmm3 registers to xmm1 under writemask k1.",
    "Load scalar double-precision floating-point value from m64 to xmm1 register under writemask k1.",
    "Merge scalar double-precision floating-point value from xmm2 and xmm3 registers to xmm1 under writemask k1.",
    "Store scalar double-precision floating-point value from xmm1 register to m64 under writemask k1.",
    "Move odd index single-precision floating-point values from xmm2/mem and duplicate each element into xmm1.",
    "Move odd index single-precision floating-point values from xmm2/mem and duplicate each element into xmm1.",
    "Move odd index single-precision floating-point values from ymm2/mem and duplicate each element into ymm1.",
    "Move odd index single-precision floating-point values from xmm2/m128 and duplicate each element into xmm1 under writemask.",
    "Move odd index single-precision floating-point values from ymm2/m256 and duplicate each element into ymm1 under writemask.",
    "Move odd index single-precision floating-point values from zmm2/m512 and duplicate each element into zmm1 under writemask.",
    "Move even index single-precision floating-point values from xmm2/mem and duplicate each element into xmm1.",
    "Move even index single-precision floating-point values from xmm2/mem and duplicate each element into xmm1.",
    "Move even index single-precision floating-point values from ymm2/mem and duplicate each element into ymm1.",
    "Move even index single-precision floating-point values from xmm2/m128 and duplicate each element into xmm1 under writemask.",
    "Move even index single-precision floating-point values from ymm2/m256 and duplicate each element into ymm1 under writemask.",
    "Move even index single-precision floating-point values from zmm2/m512 and duplicate each element into zmm1 under writemask.",
    "Merge scalar single-precision floating-point value from xmm2 to xmm1 register.",
    "Load scalar single-precision floating-point value from m32 to xmm1 register.",
    "Merge scalar single-precision floating-point value from xmm2 and xmm3 to xmm1 register",
    "Load scalar single-precision floating-point value from m32 to xmm1 register.",
    "Move scalar single-precision floating-point value from xmm1 register to xmm2/m32.",
    "Move scalar single-precision floating-point value from xmm2 and xmm3 to xmm1 register.",
    "Move scalar single-precision floating-point value from xmm1 register to m32.",
    "Move scalar single-precision floating-point value from xmm2 and xmm3 to xmm1 register under writemask k1.",
    "Move scalar single-precision floating-point values from m32 to xmm1 under writemask k1.",
    "Move scalar single-precision floating-point value from xmm2 and xmm3 to xmm1 register under writemask k1.",
    "Move scalar single-precision floating-point values from xmm1 to m32 under writemask k1.",
    "Move byte to word with sign-extension.",
    "Move byte to doubleword with sign- extension.",
    "Move byte to quadword with sign-extension.",
    "Move word to doubleword, with sign- extension.",
    "Move word to quadword with sign-extension.",
    "Move doubleword to quadword with sign- extension.",
    "Move unaligned packed double-precision floating-point from xmm2/mem to xmm1.",
    "Move unaligned packed double-precision floating-point from xmm1 to xmm2/mem.",
    "Move unaligned packed double-precision floating-point from xmm2/mem to xmm1.",
    "Move unaligned packed double-precision floating-point from xmm1 to xmm2/mem.",
    "Move unaligned packed double-precision floating-point from ymm2/mem to ymm1.",
    "Move unaligned packed double-precision floating-point from ymm1 to ymm2/mem.",
    "Move unaligned packed double-precision floating-point from xmm2/m128 to xmm1 using writemask k1.",
    "Move unaligned packed double-precision floating-point from xmm1 to xmm2/m128 using writemask k1.",
    "Move unaligned packed double-precision floating-point from ymm2/m256 to ymm1 using writemask k1.",
    "Move unaligned packed double-precision floating-point from ymm1 to ymm2/m256 using writemask k1.",
    "Move unaligned packed double-precision floating-point values from zmm2/m512 to zmm1 using writemask k1.",
    "Move unaligned packed double-precision floating-point values from zmm1 to zmm2/m512 using writemask k1.",
    "Move unaligned packed single-precision floating-point from xmm2/mem to xmm1.",
    "Move unaligned packed single-precision floating-point from xmm1 to xmm2/mem.",
    "Move unaligned packed single-precision floating-point from xmm2/mem to xmm1.",
    "Move unaligned packed single-precision floating-point from xmm1 to xmm2/mem.",
    "Move unaligned packed single-precision floating-point from ymm2/mem to ymm1.",
    "Move unaligned packed single-precision floating-point from ymm1 to ymm2/mem.",
    "Move unaligned packed single-precision floating-point values from xmm2/m128 to xmm1 using writemask k1.",
    "Move unaligned packed single-precision floating-point values from ymm2/m256 to ymm1 using writemask k1.",
    "Move unaligned packed single-precision floating-point values from zmm2/m512 to zmm1 using writemask k1.",
    "Move unaligned packed single-precision floating-point values from xmm1 to xmm2/m128 using writemask k1.",
    "Move unaligned packed single-precision floating-point values from ymm1 to ymm2/m256 using writemask k1.",
    "Move unaligned packed single-precision floating-point values from zmm1 to zmm2/m512 using writemask k1.",
    "Move byte to word with zero-extension.",
    "Move byte to doubleword, zero-extension.",
    "Move byte to quadword, zero-extension.",
    "Move word to doubleword, zero-extension.",
    "Move word to quadword, zero-extension.",
    "Sums absolute 8-bit integer difference of adjacent groups of 4 byte integers in xmm1 and xmm2/m128 and writes the results in xmm1. Starting offsets within xmm1 and xmm2/m128 are determined by imm8.",
    "Sums absolute 8-bit integer difference of adjacent groups of 4 byte integers in xmm2 and xmm3/m128 and writes the results in xmm1. Starting offsets within xmm2 and xmm3/m128 are determined by imm8.",
    "Sums absolute 8-bit integer difference of adjacent groups of 4 byte integers in xmm2 and ymm3/m128 and writes the results in ymm1. Starting offsets within ymm2 and xmm3/m128 are determined by imm8.",
    "Unsigned multiply (AX â† AL âˆ— r/m8).",
    "Unsigned multiply (AX â† AL âˆ— r/m8).",
    "Unsigned multiply (DX:AX â† AX âˆ— r/m16).",
    "Unsigned multiply (EDX:EAX â† EAX âˆ— r/m32).",
    "Unsigned multiply (RDX:RAX â† RAX âˆ— r/m64).",
    "Multiply packed double-precision floating-point values in xmm2/m128 with xmm1 and store result in xmm1.",
    "Multiply packed double-precision floating-point values in xmm3/m128 with xmm2 and store result in xmm1.",
    "Multiply packed double-precision floating-point values in ymm3/m256 with ymm2 and store result in ymm1.",
    "Multiply packed double-precision floating-point values from xmm3/m128/m64bcst to xmm2 and store result in xmm1.",
    "Multiply packed double-precision floating-point values from ymm3/m256/m64bcst to ymm2 and store result in ymm1.",
    "Multiply packed double-precision floating-point values in zmm3/m512/m64bcst with zmm2 and store result in zmm1.",
    "Multiply packed single-precision floating-point values in xmm2/m128 with xmm1 and store result in xmm1.",
    "Multiply packed single-precision floating-point values in xmm3/m128 with xmm2 and store result in xmm1.",
    "Multiply packed single-precision floating-point values in ymm3/m256 with ymm2 and store result in ymm1.",
    "Multiply packed single-precision floating-point values from xmm3/m128/m32bcst to xmm2 and store result in xmm1.",
    "Multiply packed single-precision floating-point values from ymm3/m256/m32bcst to ymm2 and store result in ymm1.",
    "Multiply packed single-precision floating-point values in zmm3/m512/m32bcst with zmm2 and store result in zmm1.",
    "Multiply the low double-precision floating-point value in xmm2/m64 by low double-precision floating-point value in xmm1.",
    "Multiply the low double-precision floating-point value in xmm3/m64 by low double-precision floating-point value in xmm2.",
    "Multiply the low double-precision floating-point value in xmm3/m64 by low double-precision floating-point value in xmm2.",
    "Multiply the low single-precision floating-point value in xmm2/m32 by the low single-precision floating-point value in xmm1.",
    "Multiply the low single-precision floating-point value in xmm3/m32 by the low single-precision floating-point value in xmm2.",
    "Multiply the low single-precision floating-point value in xmm3/m32 by the low single-precision floating-point value in xmm2.",
    "Unsigned multiply of r/m32 with EDX without affecting arithmetic flags.",
    "Unsigned multiply of r/m64 with RDX without affecting arithmetic flags.",
    "A hint that allow the processor to stop instruction execution and enter an implementation-dependent optimized state until occurrence of a class of events.",
    "Two's complement negate r/m8.",
    "Two's complement negate r/m8.",
    "Two's complement negate r/m16.",
    "Two's complement negate r/m32.",
    "Two's complement negate r/m64.",
    "One byte no-operation instruction.",
    "Multi-byte no-operation instruction.",
    "Multi-byte no-operation instruction.",
    "Reverse each bit of r/m8.",
    "Reverse each bit of r/m8.",
    "Reverse each bit of r/m16.",
    "Reverse each bit of r/m32.",
    "Reverse each bit of r/m64.",
    "AL OR imm8.",
    "AX OR imm16.",
    "EAX OR imm32.",
    "RAX OR imm32 (sign-extended).",
    "r/m8 OR imm8.",
    "r/m8 OR imm8.",
    "r/m16 OR imm16.",
    "r/m32 OR imm32.",
    "r/m64 OR imm32 (sign-extended).",
    "r/m16 OR imm8 (sign-extended).",
    "r/m32 OR imm8 (sign-extended).",
    "r/m64 OR imm8 (sign-extended).",
    "r/m8 OR r8.",
    "r/m8 OR r8.",
    "r/m16 OR r16.",
    "r/m32 OR r32.",
    "r/m64 OR r64.",
    "r8 OR r/m8.",
    "r8 OR r/m8.",
    "r16 OR r/m16.",
    "r32 OR r/m32.",
    "r64 OR r/m64.",
    "Return the bitwise logical OR of packed double-precision floating-point values in xmm1 and xmm2/mem.",
    "Return the bitwise logical OR of packed double-precision floating-point values in xmm2 and xmm3/mem.",
    "Return the bitwise logical OR of packed double-precision floating-point values in ymm2 and ymm3/mem.",
    "Return the bitwise logical OR of packed double-precision floating-point values in xmm2 and xmm3/m128/m64bcst subject to writemask k1.",
    "Return the bitwise logical OR of packed double-precision floating-point values in ymm2 and ymm3/m256/m64bcst subject to writemask k1.",
    "Return the bitwise logical OR of packed double-precision floating-point values in zmm2 and zmm3/m512/m64bcst subject to writemask k1.",
    "Return the bitwise logical OR of packed single-precision floating-point values in xmm1 and xmm2/mem.",
    "Return the bitwise logical OR of packed single-precision floating-point values in xmm2 and xmm3/mem.",
    "Return the bitwise logical OR of packed single-precision floating-point values in ymm2 and ymm3/mem.",
    "Return the bitwise logical OR of packed single-precision floating-point values in xmm2 and xmm3/m128/m32bcst subject to writemask k1.",
    "Return the bitwise logical OR of packed single-precision floating-point values in ymm2 and ymm3/m256/m32bcst subject to writemask k1.",
    "Return the bitwise logical OR of packed single-precision floating-point values in zmm2 and zmm3/m512/m32bcst subject to writemask k1.",
    "Output byte in AL to I/O port address imm8.",
    "Output word in AX to I/O port address imm8.",
    "Output doubleword in EAX to I/O port address imm8.",
    "Output byte in AL to I/O port address in DX.",
    "Output word in AX to I/O port address in DX.",
    "Output doubleword in EAX to I/O port address in DX.",
    "Output byte from memory location specified in DS:(E)SI or RSI to I/O port specified in DX.",
    "Output word from memory location specified in DS:(E)SI or RSI to I/O port specified in DX.",
    "Output doubleword from memory location specified in DS:(E)SI or RSI to I/O port specified in DX.",
    "Output byte from memory location specified in DS:(E)SI or RSI to I/O port specified in DX.",
    "Output word from memory location specified in DS:(E)SI or RSI to I/O port specified in DX.",
    "Output doubleword from memory location specified in DS:(E)SI or RSI to I/O port specified in DX.",
    "Compute the absolute value of bytes in mm2/m64 and store UNSIGNED result in mm1.",
    "Compute the absolute value of bytes in xmm2/m128 and store UNSIGNED result in xmm1.",
    "Compute the absolute value of 16-bit integers in mm2/m64 and store UNSIGNED result in mm1.",
    "Compute the absolute value of 16-bit integers in xmm2/m128 and store UNSIGNED result in xmm1.",
    "Compute the absolute value of 32-bit integers in mm2/m64 and store UNSIGNED result in mm1.",
    "Compute the absolute value of 32-bit integers in xmm2/m128 and store UNSIGNED result in xmm1.",
    "Compute the absolute value of bytes in xmm2/m128 and store UNSIGNED result in xmm1.",
    "Compute the absolute value of 16-bit integers in xmm2/m128 and store UNSIGNED result in xmm1.",
    "Compute the absolute value of 32-bit integers in xmm2/m128 and store UNSIGNED result in xmm1.",
    "Compute the absolute value of bytes in ymm2/m256 and store UNSIGNED result in ymm1.",
    "Compute the absolute value of 16-bit integers in ymm2/m256 and store UNSIGNED result in ymm1.",
    "Compute the absolute value of 32-bit integers in ymm2/m256 and store UNSIGNED result in ymm1.",
    "Compute the absolute value of bytes in xmm2/m128 and store UNSIGNED result in xmm1 using writemask k1.",
    "Compute the absolute value of bytes in ymm2/m256 and store UNSIGNED result in ymm1 using writemask k1.",
    "Compute the absolute value of bytes in zmm2/m512 and store UNSIGNED result in zmm1 using writemask k1.",
    "Compute the absolute value of 16-bit integers in xmm2/m128 and store UNSIGNED result in xmm1 using writemask k1.PABSB/PABSW/PABSD/PABSQ â€” Packed Absolute Value",
    "Converts 4 packed signed word integers from mm1 and from mm2/m64 into 8 packed signed byte integers in mm1 using signed saturation.",
    "Converts 8 packed signed word integers from xmm1 and from xxm2/m128 into 16 packed signed byte integers in xxm1 using signed saturation.",
    "Converts 2 packed signed doubleword integers from mm1 and from mm2/m64 into 4 packed signed word integers in mm1 using signed saturation.",
    "Converts 4 packed signed doubleword integers from xmm1 and from xxm2/m128 into 8 packed signed word integers in xxm1 using signed saturation.",
    "Converts 8 packed signed word integers from xmm2 and from xmm3/m128 into 16 packed signed byte integers in xmm1 using signed saturation.",
    "Converts 4 packed signed doubleword integers from xmm2 and from xmm3/m128 into 8 packed signed word integers in xmm1 using signed saturation.",
    "Converts 16 packed signed word integers from ymm2 and from ymm3/m256 into 32 packed signed byte integers in ymm1 using signed saturation.",
    "Converts 8 packed signed doubleword integers from ymm2 and from ymm3/m256 into 16 packed signed word integers in ymm1using signed saturation.",
    "Converts packed signed word integers from xmm2 and from xmm3/m128 into packed signed byte integers in xmm1 using signed saturation under writemask k1.",
    "Converts packed signed word integers from ymm2 and from ymm3/m256 into packed signed byte integers in ymm1 using signed saturation under writemask k1.",
    "Converts packed signed word integers from zmm2 and from zmm3/m512 into packed signed byte integers in zmm1 using signed saturation under writemask k1.",
    "Converts packed signed doubleword integers from xmm2 and from xmm3/m128/m32bcst into packed signed word integers in xmm1 using signed saturation under writemask k1.PACKSSWB/PACKSSDWâ€”Pack with Signed Saturation",
    "Convert 4 packed signed doubleword integers from xmm1 and 4 packed signed doubleword integers from xmm2/m128 into 8 packed unsigned word integers in xmm1 using unsigned saturation.",
    "Convert 4 packed signed doubleword integers from xmm2 and 4 packed signed doubleword integers from xmm3/m128 into 8 packed unsigned word integers in xmm1 using unsigned saturation.",
    "Convert 8 packed signed doubleword integers from ymm2 and 8 packed signed doubleword integers from ymm3/m256 into 16 packed unsigned word integers in ymm1 using unsigned saturation.",
    "Convert packed signed doubleword integers from xmm2 and packed signed doubleword integers from xmm3/m128/m32bcst into packed unsigned word integers in xmm1 using unsigned saturation under writemask k1. EVEX.NDS.256.66.0F38.W0 2B /r C V/V AVX512VL AVX512BW Convert packed signed doubleword integers from ymm2 and packed signed doubleword integers from ymm3/m256/m32bcst into packed unsigned word integers in ymm1 using unsigned saturation under writemask k1.",
    "Convert packed signed doubleword integers from zmm2 and packed signed doubleword integers from zmm3/m512/m32bcst into packed unsigned word integers in zmm1 using unsigned saturation under writemask k1.",
    "Converts 4 signed word integers from mm and 4 signed word integers from mm/m64 into 8 unsigned byte integers in mm using unsigned saturation.",
    "Converts 8 signed word integers from xmm1 and 8 signed word integers from xmm2/m128 into 16 unsigned byte integers in xmm1 using unsigned saturation.",
    "Converts 8 signed word integers from xmm2 and 8 signed word integers from xmm3/m128 into 16 unsigned byte integers in xmm1 using unsigned saturation.",
    "Converts 16 signed word integers from ymm2 and 16signed word integers from ymm3/m256 into 32 unsigned byte integers in ymm1 using unsigned saturation.",
    "Converts signed word integers from xmm2 and signed word integers from xmm3/m128 into unsigned byte integers in xmm1 using unsigned saturation under writemask k1.",
    "Converts signed word integers from ymm2 and signed word integers from ymm3/m256 into unsigned byte integers in ymm1 using unsigned saturation under writemask k1.",
    "Converts signed word integers from zmm2 and signed word integers from zmm3/m512 into unsigned byte integers in zmm1 using unsigned saturation under writemask k1.",
    "Add packed byte integers from mm/m64 and mm.",
    "Add packed word integers from mm/m64 and mm.",
    "Add packed doubleword integers from mm/m64 and mm.",
    "Add packed quadword integers from mm/m64 and mm.",
    "Add packed byte integers from xmm2/m128 and xmm1.",
    "Add packed word integers from xmm2/m128 and xmm1.",
    "Add packed doubleword integers from xmm2/m128 and xmm1.",
    "Add packed quadword integers from xmm2/m128 and xmm1.",
    "Add packed byte integers from xmm2, and xmm3/m128 and store in xmm1.",
    "Add packed word integers from xmm2, xmm3/m128 and store in xmm1.",
    "Add packed doubleword integers from xmm2, xmm3/m128 and store in xmm1.",
    "Add packed quadword integers from xmm2, xmm3/m128 and store in xmm1.",
    "Add packed byte integers from ymm2, and ymm3/m256 and store in ymm1.",
    "Add packed word integers from ymm2, ymm3/m256 and store in ymm1.",
    "Add packed doubleword integers from ymm2, ymm3/m256 and store in ymm1.",
    "Add packed quadword integers from ymm2, ymm3/m256 and store in ymm1.",
    "Add packed byte integers from xmm2, and xmm3/m128 and store in xmm1 using writemask k1.",
    "Add packed word integers from xmm2, and xmm3/m128 and store in xmm1 using writemask k1.",
    "Add packed doubleword integers from xmm2, and xmm3/m128/m32bcst and store in xmm1 using writemask k1.",
    "Add packed quadword integers from xmm2, and xmm3/m128/m64bcst and store in xmm1 using writemask k1.",
    "Add packed byte integers from ymm2, and ymm3/m256 and store in ymm1 using writemask k1.",
    "Add packed word integers from ymm2, and ymm3/m256 and store in ymm1 using writemask k1.PADDB/PADDW/PADDD/PADDQâ€”Add Packed Integers",
    "Add packed signed byte integers from mm/m64 and mm and saturate the results.",
    "Add packed signed byte integers from xmm2/m128 and xmm1 saturate the results.",
    "Add packed signed word integers from mm/m64 and mm and saturate the results.",
    "Add packed signed word integers from xmm2/m128 and xmm1 and saturate the results.",
    "Add packed signed byte integers from xmm3/m128 and xmm2 saturate the results.",
    "Add packed signed word integers from xmm3/m128 and xmm2 and saturate the results.",
    "Add packed signed byte integers from ymm2, and ymm3/m256 and store the saturated results in ymm1.",
    "Add packed signed word integers from ymm2, and ymm3/m256 and store the saturated results in ymm1.",
    "Add packed signed byte integers from xmm2, and xmm3/m128 and store the saturated results in xmm1 under writemask k1.",
    "Add packed signed byte integers from ymm2, and ymm3/m256 and store the saturated results in ymm1 under writemask k1.",
    "Add packed signed byte integers from zmm2, and zmm3/m512 and store the saturated results in zmm1 under writemask k1.",
    "Add packed signed word integers from xmm2, and xmm3/m128 and store the saturated results in xmm1 under writemask k1.",
    "Add packed signed word integers from ymm2, and ymm3/m256 and store the saturated results in ymm1 under writemask k1.",
    "Add packed signed word integers from zmm2, and zmm3/m512 and store the saturated results in zmm1 under writemask k1.",
    "Add packed unsigned byte integers from mm/m64 and mm and saturate the results.",
    "Add packed unsigned byte integers from xmm2/m128 and xmm1 saturate the results.",
    "Add packed unsigned word integers from mm/m64 and mm and saturate the results.",
    "Add packed unsigned word integers from xmm2/m128 to xmm1 and saturate the results.",
    "Add packed unsigned byte integers from xmm3/m128 to xmm2 and saturate the results.",
    "Add packed unsigned word integers from xmm3/m128 to xmm2 and saturate the results.",
    "Add packed unsigned byte integers from ymm2,and ymm3/m256 and store the saturated results in ymm1.",
    "Add packed unsigned word integers from ymm2,and ymm3/m256 and store the saturated results in ymm1.",
    "Add packed unsigned byte integers from xmm2,and xmm3/m128 and store the saturated results in xmm1 under writemask k1.",
    "Add packed unsigned byte integers from ymm2,and ymm3/m256 and store the saturated results in ymm1 under writemask k1.",
    "Add packed unsigned byte integers from zmm2,and zmm3/m512 and store the saturated results in zmm1 under writemask k1.",
    "Add packed unsigned word integers from xmm2,and xmm3/m128 and store the saturated results in xmm1 under writemask k1.",
    "Add packed unsigned word integers from ymm2,and ymm3/m256 and store the saturated results in ymm1 under writemask k1.",
    "Add packed unsigned word integers from zmm2,and zmm3/m512 and store the saturated results in zmm1 under writemask k1.",
    "Concatenate destination and source operands, extract byte-aligned result shifted to the right by constant value in imm8 into mm1.",
    "Concatenate destination and source operands, extract byte-aligned result shifted to the right by constant value in imm8 into xmm1.",
    "Concatenate xmm2 and xmm3/m128, extract byte aligned result shifted to the right by constant value in imm8 and result is stored in xmm1.",
    "Concatenate pairs of 16 bytes in ymm2 and ymm3/m256 into 32-byte intermediate result, extract byte-aligned, 16-byte result shifted to the right by constant values in imm8 from each intermediate result, and two 16-byte results are stored in ymm1.",
    "Concatenate xmm2 and xmm3/m128 into a 32-byte intermediate result, extract byte aligned result shifted to the right by constant value in imm8 and result is stored in xmm1.",
    "Concatenate pairs of 16 bytes in ymm2 and ymm3/m256 into 32-byte intermediate result, extract byte-aligned, 16-byte result shifted to the right by constant values in imm8 from each intermediate result, and two 16-byte results are stored in ymm1.",
    "Concatenate pairs of 16 bytes in zmm2 and zmm3/m512 into 32-byte intermediate result, extract byte-aligned, 16-byte result shifted to the right by constant values in imm8 from each intermediate result, and four 16-byte results are stored in zmm1.",
    "Bitwise AND mm/m64 and mm.",
    "Bitwise AND of xmm2/m128 and xmm1.",
    "Bitwise AND of xmm3/m128 and xmm.",
    "Bitwise AND of ymm2, and ymm3/m256 and store result in ymm1.",
    "Bitwise AND of packed doubleword integers in xmm2 and xmm3/m128/m32bcst and store result in xmm1 using writemask k1.",
    "Bitwise AND of packed doubleword integers in ymm2 and ymm3/m256/m32bcst and store result in ymm1 using writemask k1.",
    "Bitwise AND of packed doubleword integers in zmm2 and zmm3/m512/m32bcst and store result in zmm1 using writemask k1.",
    "Bitwise AND of packed quadword integers in xmm2 and xmm3/m128/m64bcst and store result in xmm1 using writemask k1.",
    "Bitwise AND of packed quadword integers in ymm2 and ymm3/m256/m64bcst and store result in ymm1 using writemask k1.",
    "Bitwise AND of packed quadword integers in zmm2 and zmm3/m512/m64bcst and store result in zmm1 using writemask k1.",
    "Bitwise AND NOT of mm/m64 and mm.",
    "Bitwise AND NOT of xmm2/m128 and xmm1.",
    "Bitwise AND NOT of xmm3/m128 and xmm2.",
    "Bitwise AND NOT of ymm2, and ymm3/m256 and store result in ymm1.",
    "Bitwise AND NOT of packed doubleword integers in xmm2 and xmm3/m128/m32bcst and store result in xmm1 using writemask k1.",
    "Bitwise AND NOT of packed doubleword integers in ymm2 and ymm3/m256/m32bcst and store result in ymm1 using writemask k1.",
    "Bitwise AND NOT of packed doubleword integers in zmm2 and zmm3/m512/m32bcst and store result in zmm1 using writemask k1.",
    "Bitwise AND NOT of packed quadword integers in xmm2 and xmm3/m128/m64bcst and store result in xmm1 using writemask k1.",
    "Bitwise AND NOT of packed quadword integers in ymm2 and ymm3/m256/m64bcst and store result in ymm1 using writemask k1.",
    "Bitwise AND NOT of packed quadword integers in zmm2 and zmm3/m512/m64bcst and store result in zmm1 using writemask k1.",
    "Gives hint to processor that improves performance of spin-wait loops.",
    "Average packed unsigned byte integers from mm2/m64 and mm1 with rounding.",
    "Average packed unsigned byte integers from xmm2/m128 and xmm1 with rounding.",
    "Average packed unsigned word integers from mm2/m64 and mm1 with rounding.",
    "Average packed unsigned word integers from xmm2/m128 and xmm1 with rounding.",
    "Average packed unsigned byte integers from xmm3/m128 and xmm2 with rounding.",
    "Average packed unsigned word integers from xmm3/m128 and xmm2 with rounding.",
    "Average packed unsigned byte integers from ymm2, and ymm3/m256 with rounding and store to ymm1.",
    "Average packed unsigned word integers from ymm2, ymm3/m256 with rounding to ymm1.",
    "Average packed unsigned byte integers from xmm2, and xmm3/m128 with rounding and store to xmm1 under writemask k1.",
    "Average packed unsigned byte integers from ymm2, and ymm3/m256 with rounding and store to ymm1 under writemask k1.",
    "Average packed unsigned byte integers from zmm2, and zmm3/m512 with rounding and store to zmm1 under writemask k1.",
    "Average packed unsigned word integers from xmm2, xmm3/m128 with rounding to xmm1 under writemask k1.",
    "Average packed unsigned word integers from ymm2, ymm3/m256 with rounding to ymm1 under writemask k1.",
    "Average packed unsigned word integers from zmm2, zmm3/m512 with rounding to zmm1 under writemask k1.",
    "Select byte values from xmm1 and xmm2/m128 from mask specified in the high bit of each byte in XMM0 and store the values into xmm1.",
    "Select byte values from xmm2 and xmm3/m128 using mask bits in the specified mask register, xmm4, and store the values into xmm1.",
    "Select byte values from ymm2 and ymm3/m256 from mask specified in the high bit of each byte in ymm4 and store the values into ymm1.",
    "Select words from xmm1 and xmm2/m128 from mask specified in imm8 and store the values into xmm1.",
    "Select words from xmm2 and xmm3/m128 from mask specified in imm8 and store the values into xmm1.",
    "Select words from ymm2 and ymm3/m256 from mask specified in imm8 and store the values into ymm1.",
    "Carry-less multiplication of one quadword of xmm1 by one quadword of xmm2/m128, stores the 128-bit result in xmm1. The immediate is used to determine which quadwords of xmm1 and xmm2/m128 should be used.",
    "Carry-less multiplication of one quadword of xmm2 by one quadword of xmm3/m128, stores the 128-bit result in xmm1. The immediate is used to determine which quadwords of xmm2 and xmm3/m128 should be used.",
    "Compare packed bytes in mm/m64 and mm for equality.",
    "Compare packed bytes in xmm2/m128 and xmm1 for equality.",
    "Compare packed words in mm/m64 and mm for equality.",
    "Compare packed words in xmm2/m128 and xmm1 for equality.",
    "Compare packed doublewords in mm/m64 and mm for equality.",
    "Compare packed doublewords in xmm2/m128 and xmm1 for equality.",
    "Compare packed bytes in xmm3/m128 and xmm2 for equality.",
    "Compare packed words in xmm3/m128 and xmm2 for equality.",
    "Compare packed doublewords in xmm3/m128 and xmm2 for equality.",
    "Compare packed bytes in ymm3/m256 and ymm2 for equality.",
    "Compare packed words in ymm3/m256 and ymm2 for equality.",
    "Compare packed doublewords in ymm3/m256 and ymm2 for equality.",
    "Compare Equal between int32 vector xmm2 and int32 vector xmm3/m128/m32bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.",
    "Compare Equal between int32 vector ymm2 and int32 vector ymm3/m256/m32bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.",
    "Compare Equal between int32 vectors in zmm2 and zmm3/m512/m32bcst, and set destination k1 according to the comparison results under writemask k2.",
    "Compare packed bytes in xmm3/m128 and xmm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.",
    "Compare packed bytes in ymm3/m256 and ymm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.",
    "Compare packed bytes in zmm3/m512 and zmm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.",
    "Compare packed words in xmm3/m128 and xmm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.",
    "Compare packed words in ymm3/m256 and ymm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.",
    "Compare packed words in zmm3/m512 and zmm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.",
    "Compare packed qwords in xmm2/m128 and xmm1 for equality.",
    "Compare packed quadwords in xmm3/m128 and xmm2 for equality.",
    "Compare packed quadwords in ymm3/m256 and ymm2 for equality.",
    "Compare Equal between int64 vector xmm2 and int64 vector xmm3/m128/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.",
    "Compare Equal between int64 vector ymm2 and int64 vector ymm3/m256/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.",
    "Compare Equal between int64 vector zmm2 and int64 vector zmm3/m512/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.",
    "Perform a packed comparison of string data with explicit lengths, generating an index, and storing the result in ECX.",
    "Perform a packed comparison of string data with explicit lengths, generating an index, and storing the result in ECX.",
    "Perform a packed comparison of string data with explicit lengths, generating a mask, and storing the result in XMM0.",
    "Perform a packed comparison of string data with explicit lengths, generating a mask, and storing the result in XMM0.",
    "Compare packed signed byte integers in mm and mm/m64 for greater than.",
    "Compare packed signed byte integers in xmm1 and xmm2/m128 for greater than.",
    "Compare packed signed word integers in mm and mm/m64 for greater than.",
    "Compare packed signed word integers in xmm1 and xmm2/m128 for greater than.",
    "Compare packed signed doubleword integers in mm and mm/m64 for greater than.",
    "Compare packed signed doubleword integers in xmm1 and xmm2/m128 for greater than.",
    "Compare packed signed byte integers in xmm2 and xmm3/m128 for greater than.",
    "Compare packed signed word integers in xmm2 and xmm3/m128 for greater than.",
    "Compare packed signed doubleword integers in xmm2 and xmm3/m128 for greater than.",
    "Compare packed signed byte integers in ymm2 and ymm3/m256 for greater than.",
    "Compare packed signed word integers in ymm2 and ymm3/m256 for greater than.",
    "Compare packed signed doubleword integers in ymm2 and ymm3/m256 for greater than.",
    "Compare Greater between int32 vector xmm2 and int32 vector xmm3/m128/m32bcst,and set vector mask k1 to reflect the zero/nonzero status of each element of the result,under writemask.",
    "Compare Greater between int32 vector ymm2 and int32 vector ymm3/m256/m32bcst,and set vector mask k1 to reflect the zero/nonzero status of each element of the result,under writemask.",
    "Compare Greater between int32 elements in zmm2 and zmm3/m512/m32bcst,and set destination k1 according to the comparison results under writemask. k2.",
    "Compare packed signed byte integers in xmm2 and xmm3/m128 for greater than,and set vector mask k1 to reflect the zero/nonzero status of each element of the result,under writemask.",
    "Compare packed signed byte integers in ymm2 and ymm3/m256 for greater than,and set vector mask k1 to reflect the zero/nonzero status of each element of the result,under writemask.",
    "Compare packed signed byte integers in zmm2 and zmm3/m512 for greater than,and set vector mask k1 to reflect the zero/nonzero status of each element of the result,under writemask.",
    "Compare packed signed word integers in xmm2 and xmm3/m128 for greater than,and set vector mask k1 to reflect the zero/nonzero status of each element of the result,under writemask.",
    "Compare packed signed word integers in ymm2 and ymm3/m256 for greater than,and set vector mask k1 to reflect the zero/nonzero status of each element of the result,under writemask.",
    "Compare packed signed word integers in zmm2 and zmm3/m512 for greater than,and set vector mask k1 to reflect the zero/nonzero status of each element of the result,under writemask.",
    "Compare packed signed qwords in xmm2/m128 and xmm1 for greater than.",
    "Compare packed signed qwords in xmm2 and xmm3/m128 for greater than.",
    "Compare packed signed qwords in ymm2 and ymm3/m256 for greater than.",
    "Compare Greater between int64 vector xmm2 and int64 vector xmm3/m128/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.",
    "Compare Greater between int64 vector ymm2 and int64 vector ymm3/m256/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.",
    "Compare Greater between int64 vector zmm2 and int64 vector zmm3/m512/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.",
    "Perform a packed comparison of string data with implicit lengths, generating an index, and storing the result in ECX.",
    "Perform a packed comparison of string data with implicit lengths, generating an index, and storing the result in ECX.",
    "Perform a packed comparison of string data with implicit lengths, generating a mask, and storing the result in XMM0.",
    "Perform a packed comparison of string data with implicit lengths, generating a Mask, and storing the result in XMM0.",
    "Parallel deposit of bits from r32b using mask in r/m32, result is writ-ten to r32a.",
    "Parallel deposit of bits from r64b using mask in r/m64, result is writ-ten to r64a.",
    "Parallel extract of bits from r32b using mask in r/m32, result is writ-ten to r32a.",
    "Parallel extract of bits from r64b using mask in r/m64, result is writ-ten to r64a.",
    "Extract a byte integer value from xmm2 at the source byte offset specified by imm8 into AnyRegister or m8. The upper bits of r32 or r64 are zeroed.",
    "Extract a dword integer value from xmm2 at the source dword offset specified by imm8 into r/m32.",
    "Extract a qword integer value from xmm2 at the source qword offset specified by imm8 into r/m64.",
    "Extract a byte integer value from xmm2 at the source byte offset specified by imm8 into AnyRegister or m8. The upper bits of r64/r32 is filled with zeros.",
    "Extract a dword integer value from xmm2 at the source dword offset specified by imm8 into r32/m32.",
    "Extract a qword integer value from xmm2 at the source dword offset specified by imm8 into r64/m64.",
    "Extract a byte integer value from xmm2 at the source byte offset specified by imm8 into AnyRegister or m8. The upper bits of r64/r32 is filled with zeros.",
    "Extract a dword integer value from xmm2 at the source dword offset specified by imm8 into r32/m32.",
    "Extract a qword integer value from xmm2 at the source dword offset specified by imm8 into r64/m64.",
    "Extract the word specified by imm8 from mm and move it to AnyRegister, bits 15-0. The upper bits of r32 or r64 is zeroed.",
    "Extract the word specified by imm8 from xmm and move it to AnyRegister, bits 15-0. The upper bits of r32 or r64 is zeroed. 66 0F 3A 15",
    "Extract the word specified by imm8 from xmm and copy it to lowest 16 bits of AnyRegister or m16. Zero-extend the result in the destination, r32 or r64.",
    "Extract the word specified by imm8 from xmm1 and move it to AnyRegister, bits 15:0. Zero-extend the result. The upper bits of r64/r32 is filled with zeros.",
    "Extract a word integer value from xmm2 at the source word offset specified by imm8 into AnyRegister or m16. The upper bits of r64/r32 is filled with zeros.",
    "Extract the word specified by imm8 from xmm1 and move it to AnyRegister, bits 15:0. Zero-extend the result. The upper bits of r64/r32 is filled with zeros.",
    "Extract a word integer value from xmm2 at the source word offset specified by imm8 into AnyRegister or m16. The upper bits of r64/r32 is filled with zeros.",
    "Add 16-bit signed integers horizontally, pack saturated integers to mm1.",
    "Add 16-bit signed integers horizontally, pack saturated integers to xmm1.",
    "Add 16-bit signed integers horizontally, pack saturated integers to xmm1.",
    "Add 16-bit signed integers horizontally, pack saturated integers to ymm1.",
    "Add 16-bit integers horizontally, pack to mm1.",
    "Add 16-bit integers horizontally, pack to xmm1.",
    "Add 32-bit integers horizontally, pack to mm1.",
    "Add 32-bit integers horizontally, pack to xmm1.",
    "Add 16-bit integers horizontally, pack to xmm1.",
    "Add 32-bit integers horizontally, pack to xmm1.",
    "Add 16-bit signed integers horizontally, pack to ymm1.",
    "Add 32-bit signed integers horizontally, pack to ymm1.",
    "Find the minimum unsigned word in xmm2/m128 and place its value in the low word of xmm1 and its index in the second-lowest word of xmm1.",
    "Find the minimum unsigned word in xmm2/m128 and place its value in the low word of xmm1 and its index in the second-lowest word of xmm1.",
    "Subtract 16-bit signed integer horizontally, pack saturated integers to mm1.",
    "Subtract 16-bit signed integer horizontally, pack saturated integers to xmm1.",
    "Subtract 16-bit signed integer horizontally, pack saturated integers to xmm1.",
    "Subtract 16-bit signed integer horizontally, pack saturated integers to ymm1.",
    "Subtract 16-bit signed integers horizontally, pack to mm1.",
    "Subtract 16-bit signed integers horizontally, pack to xmm1.",
    "Subtract 32-bit signed integers horizontally, pack to mm1.",
    "Subtract 32-bit signed integers horizontally, pack to xmm1.",
    "Subtract 16-bit signed integers horizontally, pack to xmm1.",
    "Subtract 32-bit signed integers horizontally, pack to xmm1.",
    "Subtract 16-bit signed integers horizontally, pack to ymm1.",
    "Subtract 32-bit signed integers horizontally, pack to ymm1.",
    "Insert a byte integer value from r32/m8 into xmm1 at the destination element in xmm1 specified by imm8.",
    "Insert a dword integer value from r/m32 into the xmm1 at the destination element specified by imm8.",
    "Insert a qword integer value from r/m64 into the xmm1 at the destination element specified by imm8.",
    "Merge a byte integer value from r32/m8 and rest from xmm2 into xmm1 at the byte offset in imm8.",
    "Insert a dword integer value from r32/m32 and rest from xmm2 into xmm1 at the dword offset in imm8.",
    "Insert a qword integer value from r64/m64 and rest from xmm2 into xmm1 at the qword offset in imm8.",
    "Merge a byte integer value from r32/m8 and rest from xmm2 into xmm1 at the byte offset in imm8.",
    "Insert a dword integer value from r32/m32 and rest from xmm2 into xmm1 at the dword offset in imm8.",
    "Insert a qword integer value from r64/m64 and rest from xmm2 into xmm1 at the qword offset in imm8.",
    "Insert the low word from r32 or from m16 into mm at the word position specified by imm8.",
    "Move the low word of r32 or from m16 into xmm at the word position specified by imm8.",
    "Insert a word integer value from r32/m16 and rest from xmm2 into xmm1 at the word offset in imm8.",
    "Insert a word integer value from r32/m16 and rest from xmm2 into xmm1 at the word offset in imm8.",
    "Multiply signed and unsigned bytes, add horizontal pair of signed words, pack saturated signed-words to mm1.",
    "Multiply signed and unsigned bytes, add horizontal pair of signed words, pack saturated signed-words to xmm1.",
    "Multiply signed and unsigned bytes, add horizontal pair of signed words, pack saturated signed-words to xmm1.",
    "Multiply signed and unsigned bytes, add horizontal pair of signed words, pack saturated signed-words to ymm1.",
    "Multiply signed and unsigned bytes, add horizontal pair of signed words, pack saturated signed-words to xmm1 under writemask k1.",
    "Multiply signed and unsigned bytes, add horizontal pair of signed words, pack saturated signed-words to ymm1 under writemask k1.",
    "Multiply signed and unsigned bytes, add horizontal pair of signed words, pack saturated signed-words to zmm1 under writemask k1.",
    "Multiply the packed words in mm by the packed words in mm/m64, add adjacent doubleword results, and store in mm.",
    "Multiply the packed word integers in xmm1 by the packed word integers in xmm2/m128, add adjacent doubleword results, and store in xmm1.",
    "Multiply the packed word integers in xmm2 by the packed word integers in xmm3/m128, add adjacent doubleword results, and store in xmm1.",
    "Multiply the packed word integers in ymm2 by the packed word integers in ymm3/m256, add adjacent doubleword results, and store in ymm1.",
    "Multiply the packed word integers in xmm2 by the packed word integers in xmm3/m128, add adjacent doubleword results, and store in xmm1 under writemask k1.",
    "Multiply the packed word integers in ymm2 by the packed word integers in ymm3/m256, add adjacent doubleword results, and store in ymm1 under writemask k1.",
    "Multiply the packed word integers in zmm2 by the packed word integers in zmm3/m512, add adjacent doubleword results, and store in zmm1 under writemask k1.",
    "Compare signed word integers in mm2/m64 and mm1 and return maximum values.",
    "Compare packed signed byte integers in xmm1 and xmm2/m128 and store packed maximum values in xmm1.",
    "Compare packed signed word integers in xmm2/m128 and xmm1 and stores maximum packed values in xmm1.",
    "Compare packed signed dword integers in xmm1 and xmm2/m128 and store packed maximum values in xmm1.",
    "Compare packed signed byte integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1.",
    "Compare packed signed word integers in xmm3/m128 and xmm2 and store packed maximum values in xmm1.",
    "Compare packed signed dword integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1.",
    "Compare packed signed byte integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1.",
    "Compare packed signed word integers in ymm3/m256 and ymm2 and store packed maximum values in ymm1.",
    "Compare packed signed dword integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1.",
    "Compare packed signed byte integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1 under writemask k1.",
    "Compare packed signed byte integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1 under writemask k1.",
    "Compare packed signed byte integers in zmm2 and zmm3/m512 and store packed maximum values in zmm1 under writemask k1.",
    "Compare packed signed word integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1 under writemask k1.",
    "Compare packed signed word integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1 under writemask k1.",
    "Compare packed signed word integers in zmm2 and zmm3/m512 and store packed maximum values in zmm1 under writemask k1.",
    "Compare packed signed dword integers in xmm2 and xmm3/m128/m32bcst and store packed maximum values in xmm1 using writemask k1.PMAXSB/PMAXSW/PMAXSD/PMAXSQâ€”Maximum of Packed Signed Integers",
    "Compare unsigned byte integers in mm2/m64 and mm1 and returns maximum values.",
    "Compare packed unsigned byte integers in xmm1 and xmm2/m128 and store packed maximum values in xmm1.",
    "Compare packed unsigned word integers in xmm2/m128 and xmm1 and stores maximum packed values in xmm1.",
    "Compare packed unsigned byte integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1.",
    "Compare packed unsigned word integers in xmm3/m128 and xmm2 and store maximum packed values in xmm1.",
    "Compare packed unsigned byte integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1.",
    "Compare packed unsigned word integers in ymm3/m256 and ymm2 and store maximum packed values in ymm1.",
    "Compare packed unsigned byte integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1 under writemask k1.",
    "Compare packed unsigned byte integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1 under writemask k1.",
    "Compare packed unsigned byte integers in zmm2 and zmm3/m512 and store packed maximum values in zmm1 under writemask k1.",
    "Compare packed unsigned word integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1 under writemask k1.",
    "Compare packed unsigned word integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1 under writemask k1.",
    "Compare packed unsigned word integers in zmm2 and zmm3/m512 and store packed maximum values in zmm1 under writemask k1.",
    "Compare packed unsigned dword integers in xmm1 and xmm2/m128 and store packed maximum values in xmm1.",
    "Compare packed unsigned dword integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1.",
    "Compare packed unsigned dword integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1.",
    "Compare packed unsigned dword integers in xmm2 and xmm3/m128/m32bcst and store packed maximum values in xmm1 under writemask k1.",
    "Compare packed unsigned dword integers in ymm2 and ymm3/m256/m32bcst and store packed maximum values in ymm1 under writemask k1.",
    "Compare packed unsigned dword integers in zmm2 and zmm3/m512/m32bcst and store packed maximum values in zmm1 under writemask k1.",
    "Compare packed unsigned qword integers in xmm2 and xmm3/m128/m64bcst and store packed maximum values in xmm1 under writemask k1.",
    "Compare packed unsigned qword integers in ymm2 and ymm3/m256/m64bcst and store packed maximum values in ymm1 under writemask k1.",
    "Compare packed unsigned qword integers in zmm2 and zmm3/m512/m64bcst and store packed maximum values in zmm1 under writemask k1.",
    "Compare signed word integers in mm2/m64 and mm1 and return minimum values.",
    "Compare packed signed byte integers in xmm1 and xmm2/m128 and store packed minimum values in xmm1.",
    "Compare packed signed word integers in xmm2/m128 and xmm1 and store packed minimum values in xmm1.",
    "Compare packed signed byte integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1.",
    "Compare packed signed word integers in xmm3/m128 and xmm2 and return packed minimum values in xmm1.",
    "Compare packed signed byte integers in ymm2 and ymm3/m256 and store packed minimum values in ymm1.",
    "Compare packed signed word integers in ymm3/m256 and ymm2 and return packed minimum values in ymm1.",
    "Compare packed signed byte integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1 under writemask k1.",
    "Compare packed signed byte integers in ymm2 and ymm3/m256 and store packed minimum values in ymm1 under writemask k1.",
    "Compare packed signed byte integers in zmm2 and zmm3/m512 and store packed minimum values in zmm1 under writemask k1.",
    "Compare packed signed word integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1 under writemask k1.",
    "Compare packed signed word integers in ymm2 and ymm3/m256 and store packed minimum values in ymm1 under writemask k1.",
    "Compare packed signed word integers in zmm2 and zmm3/m512 and store packed minimum values in zmm1 under writemask k1.",
    "Compare packed signed dword integers in xmm1 and xmm2/m128 and store packed minimum values in xmm1.",
    "Compare packed signed dword integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1.",
    "Compare packed signed dword integers in ymm2 and ymm3/m128 and store packed minimum values in ymm1.",
    "Compare packed signed dword integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1 under writemask k1.",
    "Compare packed signed dword integers in ymm2 and ymm3/m256 and store packed minimum values in ymm1 under writemask k1.",
    "Compare packed signed dword integers in zmm2 and zmm3/m512/m32bcst and store packed minimum values in zmm1 under writemask k1.",
    "Compare packed signed qword integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1 under writemask k1.",
    "Compare packed signed qword integers in ymm2 and ymm3/m256 and store packed minimum values in ymm1 under writemask k1.",
    "Compare packed signed qword integers in zmm2 and zmm3/m512/m64bcst and store packed minimum values in zmm1 under writemask k1.",
    "Compare unsigned byte integers in mm2/m64 and mm1 and returns minimum values.",
    "Compare packed unsigned byte integers in xmm1 and xmm2/m128 and store packed minimum values in xmm1.",
    "Compare packed unsigned word integers in xmm2/m128 and xmm1 and store packed minimum values in xmm1.",
    "Compare packed unsigned byte integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1.",
    "Compare packed unsigned word integers in xmm3/m128 and xmm2 and return packed minimum values in xmm1.",
    "Compare packed unsigned byte integers in ymm2 and ymm3/m256 and store packed minimum values in ymm1.",
    "Compare packed unsigned word integers in ymm3/m256 and ymm2 and return packed minimum values in ymm1.",
    "Compare packed unsigned byte integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1 under writemask k1.",
    "Compare packed unsigned byte integers in ymm2 and ymm3/m256 and store packed minimum values in ymm1 under writemask k1.",
    "Compare packed unsigned byte integers in zmm2 and zmm3/m512 and store packed minimum values in zmm1 under writemask k1.",
    "Compare packed unsigned word integers in xmm3/m128 and xmm2 and return packed minimum values in xmm1 under writemask k1.",
    "Compare packed unsigned word integers in ymm3/m256 and ymm2 and return packed minimum values in ymm1 under writemask k1.",
    "Compare packed unsigned word integers in zmm3/m512 and zmm2 and return packed minimum values in zmm1 under writemask k1.",
    "Compare packed unsigned dword integers in xmm1 and xmm2/m128 and store packed minimum values in xmm1.",
    "Compare packed unsigned dword integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1.",
    "Compare packed unsigned dword integers in ymm2 and ymm3/m256 and store packed minimum values in ymm1.",
    "Compare packed unsigned dword integers in xmm2 and xmm3/m128/m32bcst and store packed minimum values in xmm1 under writemask k1.",
    "Compare packed unsigned dword integers in ymm2 and ymm3/m256/m32bcst and store packed minimum values in ymm1 under writemask k1.",
    "Compare packed unsigned dword integers in zmm2 and zmm3/m512/m32bcst and store packed minimum values in zmm1 under writemask k1.",
    "Compare packed unsigned qword integers in xmm2 and xmm3/m128/m64bcst and store packed minimum values in xmm1 under writemask k1.",
    "Compare packed unsigned qword integers in ymm2 and ymm3/m256/m64bcst and store packed minimum values in ymm1 under writemask k1.",
    "Compare packed unsigned qword integers in zmm2 and zmm3/m512/m64bcst and store packed minimum values in zmm1 under writemask k1.",
    "Move a byte mask of mm to AnyRegister. The upper bits of r32 or r64 are zeroed",
    "Move a byte mask of xmm to AnyRegister. The upper bits of r32 or r64 are zeroed",
    "Move a byte mask of xmm1 to AnyRegister. The upper bits of r32 or r64 are filled with zeros.",
    "Move a 32-bit mask of ymm1 to AnyRegister. The upper bits of r64 are filled with zeros.",
    "Sign extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 16-bit integers in xmm1.",
    "Sign extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 32-bit integers in xmm1.",
    "Sign extend 2 packed 8-bit integers in the low 2 bytes of xmm2/m16 to 2 packed 64-bit integers in xmm1.",
    "Sign extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 32-bit integers in xmm1.",
    "Sign extend 2 packed 16-bit integers in the low 4 bytes of xmm2/m32 to 2 packed 64-bit integers in xmm1.",
    "Sign extend 2 packed 32-bit integers in the low 8 bytes of xmm2/m64 to 2 packed 64-bit integers in xmm1.",
    "Sign extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 16-bit integers in xmm1.",
    "Sign extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 32-bit integers in xmm1.",
    "Sign extend 2 packed 8-bit integers in the low 2 bytes of xmm2/m16 to 2 packed 64-bit integers in xmm1.",
    "Sign extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 32-bit integers in xmm1.",
    "Sign extend 2 packed 16-bit integers in the low 4 bytes of xmm2/m32 to 2 packed 64-bit integers in xmm1.",
    "Sign extend 2 packed 32-bit integers in the low 8 bytes of xmm2/m64 to 2 packed 64-bit integers in xmm1.",
    "Sign extend 16 packed 8-bit integers in xmm2/m128 to 16 packed 16-bit integers in ymm1.",
    "Sign extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 32-bit integers in ymm1.",
    "Sign extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 64-bit integers in ymm1.",
    "Sign extend 8 packed 16-bit integers in the low 16 bytes of xmm2/m128 to 8 packed 32-bit integers in ymm1.",
    "Sign extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 64-bit integers in ymm1.",
    "Sign extend 4 packed 32-bit integers in the low 16 bytes of xmm2/m128 to 4 packed 64-bit integers in ymm1.",
    "Sign extend 8 packed 8-bit integers in xmm2/m64 to 8 packed 16-bit integers in zmm1.",
    "Sign extend 16 packed 8-bit integers in xmm2/m128 to 16 packed 16-bit integers in ymm1.",
    "Sign extend 32 packed 8-bit integers in ymm2/m256 to 32 packed 16-bit integers in zmm1.",
    "Sign extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 32-bit integers in xmm1 subject to writemask k1.PMOVSXâ€”Packed Move with Sign Extend",
    "Sign extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 32-bit integers in ymm1 subject to writemask k1.",
    "Sign extend 16 packed 8-bit integers in the low 16 bytes of xmm2/m128 to 16 packed 32-bit integers in zmm1 subject to writemask k1.",
    "Sign extend 2 packed 8-bit integers in the low 2 bytes of xmm2/m16 to 2 packed 64-bit integers in xmm1 subject to writemask k1.",
    "Sign extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 64-bit integers in ymm1 subject to writemask k1.",
    "Sign extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 64-bit integers in zmm1 subject to writemask k1.",
    "Sign extend 4 packed 16-bit integers in the low 8 bytes of ymm2/mem to 4 packed 32-bit integers in xmm1 subject to writemask k1.",
    "Sign extend 8 packed 16-bit integers in the low 16 bytes of ymm2/m128 to 8 packed 32-bit integers in ymm1 subject to writemask k1.",
    "Sign extend 16 packed 16-bit integers in the low 32 bytes of ymm2/m256 to 16 packed 32-bit integers in zmm1 subject to writemask k1.",
    "Sign extend 2 packed 16-bit integers in the low 4 bytes of xmm2/m32 to 2 packed 64-bit integers in xmm1 subject to writemask k1.",
    "Sign extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 64-bit integers in ymm1 subject to writemask k1.",
    "Sign extend 8 packed 16-bit integers in the low 16 bytes of xmm2/m128 to 8 packed 64-bit integers in zmm1 subject to writemask k1.",
    "Sign extend 2 packed 32-bit integers in the low 8 bytes of xmm2/m64 to 2 packed 64-bit integers in zmm1 using writemask k1.",
    "Sign extend 4 packed 32-bit integers in the low 16 bytes of xmm2/m128 to 4 packed 64-bit integers in zmm1 using writemask k1.",
    "Sign extend 8 packed 32-bit integers in the low 32 bytes of ymm2/m256 to 8 packed 64-bit integers in zmm1 using writemask k1.",
    "Zero extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 16-bit integers in xmm1.",
    "Zero extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 32-bit integers in xmm1.",
    "Zero extend 2 packed 8-bit integers in the low 2 bytes of xmm2/m16 to 2 packed 64-bit integers in xmm1.",
    "Zero extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 32-bit integers in xmm1.",
    "Zero extend 2 packed 16-bit integers in the low 4 bytes of xmm2/m32 to 2 packed 64-bit integers in xmm1.",
    "Zero extend 2 packed 32-bit integers in the low 8 bytes of xmm2/m64 to 2 packed 64-bit integers in xmm1.",
    "Zero extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 16-bit integers in xmm1.",
    "Zero extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 32-bit integers in xmm1.",
    "Zero extend 2 packed 8-bit integers in the low 2 bytes of xmm2/m16 to 2 packed 64-bit integers in xmm1.",
    "Zero extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 32-bit integers in xmm1.",
    "Zero extend 2 packed 16-bit integers in the low 4 bytes of xmm2/m32 to 2 packed 64-bit integers in xmm1.",
    "Zero extend 2 packed 32-bit integers in the low 8 bytes of xmm2/m64 to 2 packed 64-bit integers in xmm1.",
    "Zero extend 16 packed 8-bit integers in xmm2/m128 to 16 packed 16-bit integers in ymm1.",
    "Zero extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 32-bit integers in ymm1.",
    "Zero extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 64-bit integers in ymm1.",
    "Zero extend 8 packed 16-bit integers xmm2/m128 to 8 packed 32-bit integers in ymm1.",
    "Zero extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 64-bit integers in xmm1.",
    "Zero extend 4 packed 32-bit integers in xmm2/m128 to 4 packed 64-bit integers in ymm1.PMOVZXâ€”Packed Move with Zero Extend",
    "Zero extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 16-bit integers in xmm1.",
    "Zero extend 16 packed 8-bit integers in xmm2/m128 to 16 packed 16-bit integers in ymm1.",
    "Zero extend 32 packed 8-bit integers in ymm2/m256 to 32 packed 16-bit integers in zmm1.",
    "Zero extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 32-bit integers in xmm1 subject to writemask k1.",
    "Zero extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 32-bit integers in ymm1 subject to writemask k1.",
    "Zero extend 16 packed 8-bit integers in xmm2/m128 to 16 packed 32-bit integers in zmm1 subject to writemask k1.",
    "Zero extend 2 packed 8-bit integers in the low 2 bytes of xmm2/m16 to 2 packed 64-bit integers in xmm1 subject to writemask k1.",
    "Zero extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 64-bit integers in ymm1 subject to writemask k1.",
    "Zero extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 64-bit integers in zmm1 subject to writemask k1.",
    "Zero extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 32-bit integers in xmm1 subject to writemask k1.",
    "Zero extend 8 packed 16-bit integers in xmm2/m128 to 8 packed 32-bit integers in zmm1 subject to writemask k1.",
    "Zero extend 16 packed 16-bit integers in ymm2/m256 to 16 packed 32-bit integers in zmm1 subject to writemask k1.",
    "Zero extend 2 packed 16-bit integers in the low 4 bytes of xmm2/m32 to 2 packed 64-bit integers in xmm1 subject to writemask k1.",
    "Zero extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 64-bit integers in ymm1 subject to writemask k1.",
    "Zero extend 8 packed 16-bit integers in xmm2/m128 to 8 packed 64-bit integers in zmm1 subject to writemask k1.",
    "Multiply packed signed doubleword integers in xmm1 by packed signed doubleword integers in xmm2/m128, and store the quadword results in xmm1.",
    "Multiply packed signed doubleword integers in xmm2 by packed signed doubleword integers in xmm3/m128, and store the quadword results in xmm1.",
    "Multiply packed signed doubleword integers in ymm2 by packed signed doubleword integers in ymm3/m256, and store the quadword results in ymm1.",
    "Multiply packed signed doubleword integers in xmm2 by packed signed doubleword integers in xmm3/m128/m64bcst, and store the quadword results in xmm1 using writemask k1.",
    "Multiply packed signed doubleword integers in ymm2 by packed signed doubleword integers in ymm3/m256/m64bcst, and store the quadword results in ymm1 using writemask k1.",
    "Multiply packed signed doubleword integers in zmm2 by packed signed doubleword integers in zmm3/m512/m64bcst, and store the quadword results in zmm1 using writemask k1.",
    "Multiply 16-bit signed words, scale and round signed doublewords, pack high 16 bits to mm1.",
    "Multiply 16-bit signed words, scale and round signed doublewords, pack high 16 bits to xmm1.",
    "Multiply 16-bit signed words, scale and round signed doublewords, pack high 16 bits to xmm1.",
    "Multiply 16-bit signed words, scale and round signed doublewords, pack high 16 bits to ymm1.",
    "Multiply 16-bit signed words, scale and round signed doublewords, pack high 16 bits to xmm1 under writemask k1.",
    "Multiply 16-bit signed words, scale and round signed doublewords, pack high 16 bits to ymm1 under writemask k1.",
    "Multiply 16-bit signed words, scale and round signed doublewords, pack high 16 bits to zmm1 under writemask k1.",
    "Multiply the packed unsigned word integers in mm1 register and mm2/m64, and store the high 16 bits of the results in mm1.",
    "Multiply the packed unsigned word integers in xmm1 and xmm2/m128, and store the high 16 bits of the results in xmm1.",
    "Multiply the packed unsigned word integers in xmm2 and xmm3/m128, and store the high 16 bits of the results in xmm1.",
    "Multiply the packed unsigned word integers in ymm2 and ymm3/m256, and store the high 16 bits of the results in ymm1.",
    "Multiply the packed unsigned word integers in xmm2 and xmm3/m128, and store the high 16 bits of the results in xmm1 under writemask k1.",
    "Multiply the packed unsigned word integers in ymm2 and ymm3/m256, and store the high 16 bits of the results in ymm1 under writemask k1.",
    "Multiply the packed unsigned word integers in zmm2 and zmm3/m512, and store the high 16 bits of the results in zmm1 under writemask k1.",
    "Multiply the packed signed word integers in mm1 register and mm2/m64, and store the high 16 bits of the results in mm1.",
    "Multiply the packed signed word integers in xmm1 and xmm2/m128, and store the high 16 bits of the results in xmm1.",
    "Multiply the packed signed word integers in xmm2 and xmm3/m128, and store the high 16 bits of the results in xmm1.",
    "Multiply the packed signed word integers in ymm2 and ymm3/m256, and store the high 16 bits of the results in ymm1.",
    "Multiply the packed signed word integers in xmm2 and xmm3/m128, and store the high 16 bits of the results in xmm1 under writemask k1.",
    "Multiply the packed signed word integers in ymm2 and ymm3/m256, and store the high 16 bits of the results in ymm1 under writemask k1.",
    "Multiply the packed signed word integers in zmm2 and zmm3/m512, and store the high 16 bits of the results in zmm1 under writemask k1.",
    "Multiply the packed dword signed integers in xmm1 and xmm2/m128 and store the low 32 bits of each product in xmm1.",
    "Multiply the packed dword signed integers in xmm2 and xmm3/m128 and store the low 32 bits of each product in xmm1.",
    "Multiply the packed dword signed integers in ymm2 and ymm3/m256 and store the low 32 bits of each product in ymm1.",
    "Multiply the packed dword signed integers in xmm2 and xmm3/m128/m32bcst and store the low 32 bits of each product in xmm1 under writemask k1.",
    "Multiply the packed dword signed integers in ymm2 and ymm3/m256/m32bcst and store the low 32 bits of each product in ymm1 under writemask k1.",
    "Multiply the packed dword signed integers in zmm2 and zmm3/m512/m32bcst and store the low 32 bits of each product in zmm1 under writemask k1.",
    "Multiply the packed qword signed integers in xmm2 and xmm3/m128/m64bcst and store the low 64 bits of each product in xmm1 under writemask k1.",
    "Multiply the packed qword signed integers in ymm2 and ymm3/m256/m64bcst and store the low 64 bits of each product in ymm1 under writemask k1.",
    "Multiply the packed qword signed integers in zmm2 and zmm3/m512/m64bcst and store the low 64 bits of each product in zmm1 under writemask k1.",
    "Multiply the packed signed word integers in mm1 register and mm2/m64, and store the low 16 bits of the results in mm1.",
    "Multiply the packed signed word integers in xmm1 and xmm2/m128, and store the low 16 bits of the results in xmm1.",
    "Multiply the packed dword signed integers in xmm2 and xmm3/m128 and store the low 32 bits of each product in xmm1.",
    "Multiply the packed signed word integers in ymm2 and ymm3/m256, and store the low 16 bits of the results in ymm1.",
    "Multiply the packed signed word integers in xmm2 and xmm3/m128, and store the low 16 bits of the results in xmm1 under writemask k1.",
    "Multiply the packed signed word integers in ymm2 and ymm3/m256, and store the low 16 bits of the results in ymm1 under writemask k1.",
    "Multiply the packed signed word integers in zmm2 and zmm3/m512, and store the low 16 bits of the results in zmm1 under writemask k1.",
    "Multiply unsigned doubleword integer in mm1 by unsigned doubleword integer in mm2/m64, and store the quadword result in mm1.",
    "Multiply packed unsigned doubleword integers in xmm1 by packed unsigned doubleword integers in xmm2/m128, and store the quadword results in xmm1.",
    "Multiply packed unsigned doubleword integers in xmm2 by packed unsigned doubleword integers in xmm3/m128, and store the quadword results in xmm1.",
    "Multiply packed unsigned doubleword integers in ymm2 by packed unsigned doubleword integers in ymm3/m256, and store the quadword results in ymm1.",
    "Multiply packed unsigned doubleword integers in xmm2 by packed unsigned doubleword integers in xmm3/m128/m64bcst, and store the quadword results in xmm1 under writemask k1.",
    "Multiply packed unsigned doubleword integers in ymm2 by packed unsigned doubleword integers in ymm3/m256/m64bcst, and store the quadword results in ymm1 under writemask k1.",
    "Multiply packed unsigned doubleword integers in zmm2 by packed unsigned doubleword integers in zmm3/m512/m64bcst, and store the quadword results in zmm1 under writemask k1.",
    "Pop top of stack into m16; increment stack pointer.",
    "Pop top of stack into m32; increment stack pointer.",
    "Pop top of stack into m64; increment stack pointer. Cannot encode 32-bit operand size.",
    "Pop top of stack into r16; increment stack pointer.",
    "Pop top of stack into r32; increment stack pointer.",
    "Pop top of stack into r64; increment stack pointer. Cannot encode 32-bit operand size.",
    "Pop top of stack into DS; increment stack pointer.",
    "Pop top of stack into ES; increment stack pointer.",
    "Pop top of stack into SS; increment stack pointer.",
    "Pop top of stack into FS; increment stack pointer by 16 bits.",
    "Pop top of stack into FS; increment stack pointer by 32 bits.",
    "Pop top of stack into FS; increment stack pointer by 64 bits.",
    "Pop top of stack into GS; increment stack pointer by 16 bits.",
    "Pop top of stack into GS; increment stack pointer by 32 bits.",
    "Pop top of stack into GS; increment stack pointer by 64 bits.",
    "Pop DI, SI, BP, BX, DX, CX, and AX.",
    "Pop EDI, ESI, EBP, EBX, EDX, ECX, and EAX.",
    "POPCNT on r/m16",
    "POPCNT on r/m32",
    "POPCNT on r/m64",
    "Pop top of stack into lower 16 bits of EFLAGS.",
    "Pop top of stack into EFLAGS.",
    "Pop top of stack and zero-extend into RFLAGS.",
    "Bitwise OR of mm/m64 and mm.",
    "Bitwise OR of xmm2/m128 and xmm1.",
    "Bitwise OR of xmm2/m128 and xmm3.",
    "Bitwise OR of ymm2/m256 and ymm3.",
    "Bitwise OR of packed doubleword integers in xmm2 and xmm3/m128/m32bcst using writemask k1.",
    "Bitwise OR of packed doubleword integers in ymm2 and ymm3/m256/m32bcst using writemask k1.",
    "Bitwise OR of packed doubleword integers in zmm2 and zmm3/m512/m32bcst using writemask k1.",
    "Bitwise OR of packed quadword integers in xmm2 and xmm3/m128/m64bcst using writemask k1.",
    "Bitwise OR of packed quadword integers in ymm2 and ymm3/m256/m64bcst using writemask k1.",
    "Bitwise OR of packed quadword integers in zmm2 and zmm3/m512/m64bcst using writemask k1.",
    "Move data from m8 closer to the processor using T0 hint.",
    "Move data from m8 closer to the processor using T1 hint.",
    "Move data from m8 closer to the processor using T2 hint.",
    "Move data from m8 closer to the processor using NTA hint.",
    "Move data from m8 closer to the processor in anticipation of a write.",
    "Move data from m8 closer to the processor using T1 hint with intent to write.",
    "Computes the absolute differences of the packed unsigned byte integers from mm2 /m64 and mm1; differences are then summed to produce an unsigned word integer result.",
    "Computes the absolute differences of the packed unsigned byte integers from xmm2/m128 and xmm1; the 8 low differences and 8 high differences are then summed separately to produce two unsigned word integer results.",
    "Computes the absolute differences of the packed unsigned byte integers from xmm3/m128 and xmm2; the 8 low differences and 8 high differences are then summed separately to produce two unsigned word integer results.",
    "Computes the absolute differences of the packed unsigned byte integers from ymm3/m256 and ymm2; then each consecutive 8 differences are summed separately to produce four unsigned word integer results.",
    "Computes the absolute differences of the packed unsigned byte integers from xmm3/m128 and xmm2; then each consecutive 8 differences are summed separately to produce four unsigned word integer results.",
    "Computes the absolute differences of the packed unsigned byte integers from ymm3/m256 and ymm2; then each consecutive 8 differences are summed separately to produce four unsigned word integer results.",
    "Computes the absolute differences of the packed unsigned byte integers from zmm3/m512 and zmm2; then each consecutive 8 differences are summed separately to produce four unsigned word integer results.",
    "Shuffle bytes in mm1 according to contents of mm2/m64.",
    "Shuffle bytes in xmm1 according to contents of xmm2/m128.",
    "Shuffle bytes in xmm2 according to contents of xmm3/m128.",
    "Shuffle bytes in ymm2 according to contents of ymm3/m256.",
    "Shuffle bytes in xmm2 according to contents of xmm3/m128 under write mask k1.",
    "Shuffle bytes in ymm2 according to contents of ymm3/m256 under write mask k1.",
    "Shuffle bytes in zmm2 according to contents of zmm3/m512 under write mask k1.",
    "Shuffle the doublewords in xmm2/m128 based on the encoding in imm8 and store the result in xmm1.",
    "Shuffle the doublewords in xmm2/m128 based on the encoding in imm8 and store the result in xmm1.",
    "Shuffle the doublewords in ymm2/m256 based on the encoding in imm8 and store the result in ymm1.",
    "Shuffle the doublewords in xmm2/m128/m32bcst based on the encoding in imm8 and store the result in xmm1 using writemask k1.",
    "Shuffle the doublewords in ymm2/m256/m32bcst based on the encoding in imm8 and store the result in ymm1 using writemask k1.",
    "Shuffle the doublewords in zmm2/m512/m32bcst based on the encoding in imm8 and store the result in zmm1 using writemask k1.",
    "Shuffle the high words in xmm2/m128 based on the encoding in imm8 and store the result in xmm1.",
    "Shuffle the high words in xmm2/m128 based on the encoding in imm8 and store the result in xmm1.",
    "Shuffle the high words in ymm2/m256 based on the encoding in imm8 and store the result in ymm1.",
    "Shuffle the high words in xmm2/m128 based on the encoding in imm8 and store the result in xmm1 under write mask k1.",
    "Shuffle the high words in ymm2/m256 based on the encoding in imm8 and store the result in ymm1 under write mask k1.",
    "Shuffle the high words in zmm2/m512 based on the encoding in imm8 and store the result in zmm1 under write mask k1.",
    "Shuffle the low words in xmm2/m128 based on the encoding in imm8 and store the result in xmm1.",
    "Shuffle the low words in xmm2/m128 based on the encoding in imm8 and store the result in xmm1.",
    "Shuffle the low words in ymm2/m256 based on the encoding in imm8 and store the result in ymm1.",
    "Shuffle the low words in xmm2/m128 based on the encoding in imm8 and store the result in xmm1 under write mask k1.",
    "Shuffle the low words in ymm2/m256 based on the encoding in imm8 and store the result in ymm1 under write mask k1.",
    "Shuffle the low words in zmm2/m512 based on the encoding in imm8 and store the result in zmm1 under write mask k1.",
    "Shuffle the words in mm2/m64 based on the encoding in imm8 and store the result in mm1.",
    "Negate/zero/preserve packed byte integers in mm1 depending on the corresponding sign in mm2/m64.",
    "Negate/zero/preserve packed byte integers in xmm1 depending on the corresponding sign in xmm2/m128.",
    "Negate/zero/preserve packed word integers in mm1 depending on the corresponding sign in mm2/m128.",
    "Negate/zero/preserve packed word integers in xmm1 depending on the corresponding sign in xmm2/m128.",
    "Negate/zero/preserve packed doubleword integers in mm1 depending on the corresponding sign in mm2/m128.",
    "Negate/zero/preserve packed doubleword integers in xmm1 depending on the corresponding sign in xmm2/m128.",
    "Negate/zero/preserve packed byte integers in xmm2 depending on the corresponding sign in xmm3/m128.",
    "Negate/zero/preserve packed word integers in xmm2 depending on the corresponding sign in xmm3/m128.",
    "Negate/zero/preserve packed doubleword integers in xmm2 depending on the corresponding sign in xmm3/m128.",
    "Negate packed byte integers in ymm2 if the corresponding sign in ymm3/m256 is less than zero.",
    "Negate packed 16-bit integers in ymm2 if the corresponding sign in ymm3/m256 is less than zero.",
    "Negate packed doubleword integers in ymm2 if the corresponding sign in ymm3/m256 is less than zero.",
    "Shift xmm1 left by imm8 bytes while shifting in 0s.",
    "Shift xmm2 left by imm8 bytes while shifting in 0s and store result in xmm1.",
    "Shift ymm2 left by imm8 bytes while shifting in 0s and store result in ymm1.",
    "Shift xmm2/m128 left by imm8 bytes while shifting in 0s and store result in xmm1.",
    "Shift ymm2/m256 left by imm8 bytes while shifting in 0s and store result in ymm1.",
    "Shift zmm2/m512 left by imm8 bytes while shifting in 0s and store result in zmm1.",
    "Shift words in mm left mm/m64 while shifting in 0s.",
    "Shift words in xmm1 left by xmm2/m128 while shifting in 0s.",
    "Shift words in mm left by imm8 while shifting in 0s.",
    "Shift words in xmm1 left by imm8 while shifting in 0s.",
    "Shift doublewords in mm left by mm/m64 while shifting in 0s.",
    "Shift doublewords in xmm1 left by xmm2/m128 while shifting in 0s.",
    "Shift doublewords in mm left by imm8 while shifting in 0s.",
    "Shift doublewords in xmm1 left by imm8 while shifting in 0s.",
    "Shift quadword in mm left by mm/m64 while shifting in 0s.",
    "Shift quadwords in xmm1 left by xmm2/m128 while shifting in 0s.",
    "Shift quadword in mm left by imm8 while shifting in 0s.",
    "Shift quadwords in xmm1 left by imm8 while shifting in 0s.",
    "Shift words in xmm2 left by amount specified in xmm3/m128 while shifting in 0s.",
    "Shift words in xmm2 left by imm8 while shifting in 0s.",
    "Shift doublewords in xmm2 left by amount specified in xmm3/m128 while shifting in 0s.",
    "Shift doublewords in xmm2 left by imm8 while shifting in 0s.",
    "Shift quadwords in xmm2 left by amount specified in xmm3/m128 while shifting in 0s.",
    "Shift quadwords in xmm2 left by imm8 while shifting in 0s.",
    "Shift words in ymm2 left by amount specified in xmm3/m128 while shifting in 0s.",
    "Shift words in ymm2 left by imm8 while shifting in 0s.PSLLW/PSLLD/PSLLQâ€”Shift Packed Data Left Logical",
    "Shift doublewords in ymm2 left by amount specified in xmm3/m128 while shifting in 0s.",
    "Shift doublewords in ymm2 left by imm8 while shifting in 0s.",
    "Shift quadwords in ymm2 left by amount specified in xmm3/m128 while shifting in 0s.",
    "Shift quadwords in ymm2 left by imm8 while shifting in 0s.",
    "Shift words in xmm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.",
    "Shift words in ymm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.",
    "Shift words in zmm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.",
    "Shift words in xmm2/m128 left by imm8 while shifting in 0s using writemask k1.",
    "Shift words in ymm2/m256 left by imm8 while shifting in 0s using writemask k1.",
    "Shift words in zmm2/m512 left by imm8 while shifting in 0 using writemask k1.",
    "Shift doublewords in xmm2 left by amount specified in xmm3/m128 while shifting in 0s under writemask k1.",
    "Shift doublewords in ymm2 left by amount specified in xmm3/m128 while shifting in 0s under writemask k1.",
    "Shift doublewords in zmm2 left by amount specified in xmm3/m128 while shifting in 0s under writemask k1.",
    "Shift doublewords in xmm2/m128/m32bcst left by imm8 while shifting in 0s using writemask k1.",
    "Shift doublewords in ymm2/m256/m32bcst left by imm8 while shifting in 0s using writemask k1.",
    "Shift doublewords in zmm2/m512/m32bcst left by imm8 while shifting in 0s using writemask k1.",
    "Shift quadwords in xmm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.",
    "Shift quadwords in ymm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.",
    "Shift quadwords in zmm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.PSLLW/PSLLD/PSLLQâ€”Shift Packed Data Left Logical",
    "Shift words in mm right by mm/m64 while shifting in sign bits.",
    "Shift words in xmm1 right by xmm2/m128 while shifting in sign bits.",
    "Shift words in mm right by imm8 while shifting in sign bits",
    "Shift words in xmm1 right by imm8 while shifting in sign bits",
    "Shift doublewords in mm right by mm/m64 while shifting in sign bits.",
    "Shift doubleword in xmm1 right by xmm2 /m128 while shifting in sign bits.",
    "Shift doublewords in mm right by imm8 while shifting in sign bits.",
    "Shift doublewords in xmm1 right by imm8 while shifting in sign bits.",
    "Shift words in xmm2 right by amount specified in xmm3/m128 while shifting in sign bits.",
    "Shift words in xmm2 right by imm8 while shifting in sign bits.",
    "Shift doublewords in xmm2 right by amount specified in xmm3/m128 while shifting in sign bits.",
    "Shift doublewords in xmm2 right by imm8 while shifting in sign bits.",
    "Shift words in ymm2 right by amount specified in xmm3/m128 while shifting in sign bits.",
    "Shift words in ymm2 right by imm8 while shifting in sign bits.",
    "Shift doublewords in ymm2 right by amount specified in xmm3/m128 while shifting in sign bits.",
    "Shift doublewords in ymm2 right by imm8 while shifting in sign bits.",
    "Shift words in xmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.",
    "Shift words in ymm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.",
    "Shift words in zmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.",
    "Shift words in xmm2/m128 right by imm8 while shifting in sign bits using writemask k1.",
    "Shift words in ymm2/m256 right by imm8 while shifting in sign bits using writemask k1.",
    "Shift words in zmm2/m512 right by imm8 while shifting in sign bits using writemask k1.",
    "Shift doublewords in xmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.",
    "Shift doublewords in ymm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.",
    "Shift doublewords in zmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.",
    "Shift doublewords in xmm2/m128/m32bcst right by imm8 while shifting in sign bits using writemask k1.",
    "Shift doublewords in ymm2/m256/m32bcst right by imm8 while shifting in sign bits using writemask k1.",
    "Shift doublewords in zmm2/m512/m32bcst right by imm8 while shifting in sign bits using writemask k1.",
    "Shift quadwords in xmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.",
    "Shift quadwords in ymm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.",
    "Shift quadwords in zmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.",
    "Shift quadwords in xmm2/m128/m64bcst right by imm8 while shifting in sign bits using writemask k1.",
    "Shift quadwords in ymm2/m256/m64bcst right by imm8 while shifting in sign bits using writemask k1.",
    "Shift quadwords in zmm2/m512/m64bcst right by imm8 while shifting in sign bits using writemask k1.",
    "Shift xmm1 right by imm8 while shifting in 0s.",
    "Shift xmm2 right by imm8 bytes while shifting in 0s.",
    "Shift ymm1 right by imm8 bytes while shifting in 0s.",
    "Shift xmm2/m128 right by imm8 bytes while shifting in 0s and store result in xmm1.",
    "Shift ymm2/m256 right by imm8 bytes while shifting in 0s and store result in ymm1.",
    "Shift zmm2/m512 right by imm8 bytes while shifting in 0s and store result in zmm1.",
    "Shift words in mm right by amount specified in mm/m64 while shifting in 0s.",
    "Shift words in xmm1 right by amount specified in xmm2/m128 while shifting in 0s.",
    "Shift words in mm right by imm8 while shifting in 0s.",
    "Shift words in xmm1 right by imm8 while shifting in 0s.",
    "Shift doublewords in mm right by amount specified in mm/m64 while shifting in 0s.",
    "Shift doublewords in xmm1 right by amount specified in xmm2/m128 while shifting in 0s.",
    "Shift doublewords in mm right by imm8 while shifting in 0s.",
    "Shift doublewords in xmm1 right by imm8 while shifting in 0s.",
    "Shift mm right by amount specified in mm/m64 while shifting in 0s.",
    "Shift quadwords in xmm1 right by amount specified in xmm2/m128 while shifting in 0s.",
    "Shift mm right by imm8 while shifting in 0s.",
    "Shift quadwords in xmm1 right by imm8 while shifting in 0s.",
    "Shift words in xmm2 right by amount specified in xmm3/m128 while shifting in 0s.",
    "Shift words in xmm2 right by imm8 while shifting in 0s.",
    "Shift doublewords in xmm2 right by amount specified in xmm3/m128 while shifting in 0s.",
    "Shift doublewords in xmm2 right by imm8 while shifting in 0s.",
    "Shift quadwords in xmm2 right by amount specified in xmm3/m128 while shifting in 0s.",
    "Shift quadwords in xmm2 right by imm8 while shifting in 0s.",
    "Shift words in ymm2 right by amount specified in xmm3/m128 while shifting in 0s.",
    "Shift words in ymm2 right by imm8 while shifting in 0s.PSRLW/PSRLD/PSRLQâ€”Shift Packed Data Right Logical",
    "Shift doublewords in ymm2 right by amount specified in xmm3/m128 while shifting in 0s.",
    "Shift doublewords in ymm2 right by imm8 while shifting in 0s.",
    "Shift quadwords in ymm2 right by amount specified in xmm3/m128 while shifting in 0s.",
    "Shift quadwords in ymm2 right by imm8 while shifting in 0s.",
    "Shift words in xmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.",
    "Shift words in ymm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.",
    "Shift words in zmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.",
    "Shift words in xmm2/m128 right by imm8 while shifting in 0s using writemask k1.",
    "Shift words in ymm2/m256 right by imm8 while shifting in 0s using writemask k1.",
    "Shift words in zmm2/m512 right by imm8 while shifting in 0s using writemask k1.",
    "Shift doublewords in xmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.",
    "Shift doublewords in ymm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.",
    "Shift doublewords in zmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.",
    "Shift doublewords in xmm2/m128/m32bcst right by imm8 while shifting in 0s using writemask k1.",
    "Shift doublewords in ymm2/m256/m32bcst right by imm8 while shifting in 0s using writemask k1.",
    "Shift doublewords in zmm2/m512/m32bcst right by imm8 while shifting in 0s using writemask k1.",
    "Shift quadwords in xmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.",
    "Shift quadwords in ymm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.",
    "Shift quadwords in zmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.PSRLW/PSRLD/PSRLQâ€”Shift Packed Data Right Logical",
    "Subtract packed byte integers in mm/m64 from packed byte integers in mm.",
    "Subtract packed byte integers in xmm2/m128 from packed byte integers in xmm1.",
    "Subtract packed word integers in mm/m64 from packed word integers in mm.",
    "Subtract packed word integers in xmm2/m128 from packed word integers in xmm1.",
    "Subtract packed doubleword integers in mm/m64 from packed doubleword integers in mm.",
    "Subtract packed doubleword integers in xmm2/mem128 from packed doubleword integers in xmm1.",
    "Subtract packed byte integers in xmm3/m128 from xmm2.",
    "Subtract packed word integers in xmm3/m128 from xmm2.",
    "Subtract packed doubleword integers in xmm3/m128 from xmm2.",
    "Subtract packed byte integers in ymm3/m256 from ymm2.",
    "Subtract packed word integers in ymm3/m256 from ymm2.",
    "Subtract packed doubleword integers in ymm3/m256 from ymm2.",
    "Subtract packed byte integers in xmm3/m128 from xmm2 and store in xmm1 using writemask k1.",
    "Subtract packed byte integers in ymm3/m256 from ymm2 and store in ymm1 using writemask k1.",
    "Subtract packed byte integers in zmm3/m512 from zmm2 and store in zmm1 using writemask k1.",
    "Subtract packed word integers in xmm3/m128 from xmm2 and store in xmm1 using writemask k1.",
    "Subtract packed word integers in ymm3/m256 from ymm2 and store in ymm1 using writemask k1.",
    "Subtract packed word integers in zmm3/m512 from zmm2 and store in zmm1 using writemask k1.PSUBB/PSUBW/PSUBDâ€”Subtract Packed Integers",
    "Subtract quadword integer in mm1 from mm2 /m64.",
    "Subtract packed quadword integers in xmm1 from xmm2/m128.",
    "Subtract packed quadword integers in xmm3/m128 from xmm2.",
    "Subtract packed quadword integers in ymm3/m256 from ymm2.",
    "Subtract packed quadword integers in xmm3/m128/m64bcst from xmm2 and store in xmm1 using writemask k1.",
    "Subtract packed quadword integers in ymm3/m256/m64bcst from ymm2 and store in ymm1 using writemask k1.",
    "Subtract packed quadword integers in zmm3/m512/m64bcst from zmm2 and store in zmm1 using writemask k1.",
    "Subtract signed packed bytes in mm/m64 from signed packed bytes in mm and saturate results.",
    "Subtract packed signed byte integers in xmm2/m128 from packed signed byte integers in xmm1 and saturate results.",
    "Subtract signed packed words in mm/m64 from signed packed words in mm and saturate results.",
    "Subtract packed signed word integers in xmm2/m128 from packed signed word integers in xmm1 and saturate results.",
    "Subtract packed signed byte integers in xmm3/m128 from packed signed byte integers in xmm2 and saturate results.",
    "Subtract packed signed word integers in xmm3/m128 from packed signed word integers in xmm2 and saturate results.",
    "Subtract packed signed byte integers in ymm3/m256 from packed signed byte integers in ymm2 and saturate results.",
    "Subtract packed signed word integers in ymm3/m256 from packed signed word integers in ymm2 and saturate results.",
    "Subtract packed signed byte integers in xmm3/m128 from packed signed byte integers in xmm2 and saturate results and store in xmm1 using writemask k1.",
    "Subtract packed signed byte integers in ymm3/m256 from packed signed byte integers in ymm2 and saturate results and store in ymm1 using writemask k1.",
    "Subtract packed signed byte integers in zmm3/m512 from packed signed byte integers in zmm2 and saturate results and store in zmm1 using writemask k1.",
    "Subtract packed signed word integers in xmm3/m128 from packed signed word integers in xmm2 and saturate results and store in xmm1 using writemask k1.",
    "Subtract packed signed word integers in ymm3/m256 from packed signed word integers in ymm2 and saturate results and store in ymm1 using writemask k1.PSUBSB/PSUBSWâ€”Subtract Packed Signed Integers with Signed Saturation",
    "Subtract unsigned packed bytes in mm/m64 from unsigned packed bytes in mm and saturate result.",
    "Subtract packed unsigned byte integers in xmm2/m128 from packed unsigned byte integers in xmm1 and saturate result.",
    "Subtract unsigned packed words in mm/m64 from unsigned packed words in mm and saturate result.",
    "Subtract packed unsigned word integers in xmm2/m128 from packed unsigned word integers in xmm1 and saturate result.",
    "Subtract packed unsigned byte integers in xmm3/m128 from packed unsigned byte integers in xmm2 and saturate result.",
    "Subtract packed unsigned word integers in xmm3/m128 from packed unsigned word integers in xmm2 and saturate result.",
    "Subtract packed unsigned byte integers in ymm3/m256 from packed unsigned byte integers in ymm2 and saturate result.",
    "Subtract packed unsigned word integers in ymm3/m256 from packed unsigned word integers in ymm2 and saturate result.",
    "Subtract packed unsigned byte integers in xmm3/m128 from packed unsigned byte integers in xmm2, saturate results and store in xmm1 using writemask k1.",
    "Subtract packed unsigned byte integers in ymm3/m256 from packed unsigned byte integers in ymm2, saturate results and store in ymm1 using writemask k1.",
    "Subtract packed unsigned byte integers in zmm3/m512 from packed unsigned byte integers in zmm2, saturate results and store in zmm1 using writemask k1.",
    "Subtract packed unsigned word integers in xmm3/m128 from packed unsigned word integers in xmm2 and saturate results and store in xmm1 using writemask k1.",
    "Subtract packed unsigned word integers in ymm3/m256 from packed unsigned word integers in ymm2, saturate results and store in ymm1 using writemask k1.PSUBUSB/PSUBUSWâ€”Subtract Packed Unsigned Integers with Unsigned Saturation",
    "Set ZF if xmm2/m128 AND xmm1 result is all 0s. Set CF if xmm2/m128 AND NOT xmm1 result is all 0s.",
    "Set ZF and CF depending on bitwise AND and ANDN of sources.",
    "Set ZF and CF depending on bitwise AND and ANDN of sources.",
    "Reads the data from r64/m64 to encod into a PTW packet if dependencies are met (see details below).",
    "Reads the data from r32/m32 to encode into a PTW packet if dependencies are met (see details below).",
    "Unpack and interleave high-order bytes from mm and mm/m64 into mm.",
    "Unpack and interleave high-order bytes from xmm1 and xmm2/m128 into xmm1.",
    "Unpack and interleave high-order words from mm and mm/m64 into mm.",
    "Unpack and interleave high-order words from xmm1 and xmm2/m128 into xmm1.",
    "Unpack and interleave high-order doublewords from mm and mm/m64 into mm.",
    "Unpack and interleave high-order doublewords from xmm1 and xmm2/m128 into xmm1.",
    "Unpack and interleave high-order quadwords from xmm1 and xmm2/m128 into xmm1.",
    "Interleave high-order bytes from xmm2 and xmm3/m128 into xmm1.",
    "Interleave high-order words from xmm2 and xmm3/m128 into xmm1.",
    "Interleave high-order doublewords from xmm2 and xmm3/m128 into xmm1.",
    "Interleave high-order quadword from xmm2 and xmm3/m128 into xmm1 register.",
    "Interleave high-order bytes from ymm2 and ymm3/m256 into ymm1 register.",
    "Interleave high-order words from ymm2 and ymm3/m256 into ymm1 register.",
    "Interleave high-order doublewords from ymm2 and ymm3/m256 into ymm1 register.",
    "Interleave high-order quadword from ymm2 and ymm3/m256 into ymm1 register.",
    "Interleave high-order bytes from xmm2 and xmm3/m128 into xmm1 register using k1 write mask.",
    "Interleave high-order words from xmm2 and xmm3/m128 into xmm1 register using k1 write mask.",
    "Interleave high-order doublewords from xmm2 and xmm3/m128/m32bcst into xmm1 register using k1 write mask.",
    "Interleave high-order quadword from xmm2 and xmm3/m128/m64bcst into xmm1 register using k1 write mask.PUNPCKHBW/PUNPCKHWD/PUNPCKHDQ/PUNPCKHQDQâ€” Unpack High Data",
    "Interleave low-order bytes from mm and mm/m32 into mm.",
    "Interleave low-order bytes from xmm1 and xmm2/m128 into xmm1.",
    "Interleave low-order words from mm and mm/m32 into mm.",
    "Interleave low-order words from xmm1 and xmm2/m128 into xmm1.",
    "Interleave low-order doublewords from mm and mm/m32 into mm.",
    "Interleave low-order doublewords from xmm1 and xmm2/m128 into xmm1.",
    "Interleave low-order quadword from xmm1 and xmm2/m128 into xmm1 register.",
    "Interleave low-order bytes from xmm2 and xmm3/m128 into xmm1.",
    "Interleave low-order words from xmm2 and xmm3/m128 into xmm1.",
    "Interleave low-order doublewords from xmm2 and xmm3/m128 into xmm1.",
    "Interleave low-order quadword from xmm2 and xmm3/m128 into xmm1 register.",
    "Interleave low-order bytes from ymm2 and ymm3/m256 into ymm1 register.",
    "Interleave low-order words from ymm2 and ymm3/m256 into ymm1 register.",
    "Interleave low-order doublewords from ymm2 and ymm3/m256 into ymm1 register.",
    "Interleave low-order quadword from ymm2 and ymm3/m256 into ymm1 register.",
    "Interleave low-order bytes from xmm2 and xmm3/m128 into xmm1 register subject to write mask k1.",
    "Interleave low-order words from xmm2 and xmm3/m128 into xmm1 register subject to write mask k1.",
    "Interleave low-order doublewords from xmm2 and xmm3/m128/m32bcst into xmm1 register subject to write mask k1.",
    "Interleave low-order quadword from zmm2 and zmm3/m512/m64bcst into zmm1 register subject to write mask k1.PUNPCKLBW/PUNPCKLWD/PUNPCKLDQ/PUNPCKLQDQâ€”Unpack Low Data",
    "Push r/m16.",
    "Push r/m32.",
    "Push r/m64.",
    "Push r16.",
    "Push r32.",
    "Push r64.",
    "Push imm8.",
    "Push imm16.",
    "Push imm32.",
    "Push CS.",
    "Push SS.",
    "Push DS.",
    "Push ES.",
    "Push FS.",
    "Push GS.",
    "Push AX, CX, DX, BX, original SP, BP, SI, and DI.",
    "Push EAX, ECX, EDX, EBX, original ESP, EBP, ESI, and EDI.",
    "Push lower 16 bits of EFLAGS.",
    "Push EFLAGS.",
    "Push RFLAGS.",
    "Bitwise XOR of mm/m64 and mm.",
    "Bitwise XOR of xmm2/m128 and xmm1.",
    "Bitwise XOR of xmm3/m128 and xmm2.",
    "Bitwise XOR of ymm3/m256 and ymm2.",
    "Bitwise XOR of packed doubleword integers in xmm2 and xmm3/m128 using writemask k1.",
    "Bitwise XOR of packed doubleword integers in ymm2 and ymm3/m256 using writemask k1.",
    "Bitwise XOR of packed doubleword integers in zmm2 and zmm3/m512/m32bcst using writemask k1.",
    "Bitwise XOR of packed quadword integers in xmm2 and xmm3/m128 using writemask k1.",
    "Bitwise XOR of packed quadword integers in ymm2 and ymm3/m256 using writemask k1.",
    "Bitwise XOR of packed quadword integers in zmm2 and zmm3/m512/m64bcst using writemask k1.",
    "Rotate 9 bits (CF, r/m8) left once.",
    "Rotate 9 bits (CF, r/m8) left once.",
    "Rotate 9 bits (CF, r/m8) left CL times.",
    "Rotate 9 bits (CF, r/m8) left CL times.",
    "Rotate 9 bits (CF, r/m8) left imm8 times.",
    "Rotate 9 bits (CF, r/m8) left imm8 times.",
    "Rotate 17 bits (CF, r/m16) left once.",
    "Rotate 17 bits (CF, r/m16) left CL times.",
    "Rotate 17 bits (CF, r/m16) left imm8 times.",
    "Rotate 33 bits (CF, r/m32) left once.",
    "Rotate 65 bits (CF, r/m64) left once. Uses a 6 bit count.",
    "Rotate 33 bits (CF, r/m32) left CL times.",
    "Rotate 65 bits (CF, r/m64) left CL times. Uses a 6 bit count.",
    "Rotate 33 bits (CF, r/m32) left imm8 times.",
    "Rotate 65 bits (CF, r/m64) left imm8 times. Uses a 6 bit count.",
    "Rotate 9 bits (CF, r/m8) right once.",
    "Rotate 9 bits (CF, r/m8) right once.",
    "Rotate 9 bits (CF, r/m8) right CL times.",
    "Rotate 9 bits (CF, r/m8) right CL times.",
    "Rotate 9 bits (CF, r/m8) right imm8 times.",
    "Rotate 9 bits (CF, r/m8) right imm8 times.",
    "Rotate 17 bits (CF, r/m16) right once.",
    "Rotate 17 bits (CF, r/m16) right CL times.",
    "Rotate 17 bits (CF, r/m16) right imm8 times.",
    "Rotate 33 bits (CF, r/m32) right once. Uses a 6 bit count.",
    "Rotate 65 bits (CF, r/m64) right once. Uses a 6 bit count.",
    "Rotate 33 bits (CF, r/m32) right CL times.",
    "Rotate 65 bits (CF, r/m64) right CL times. Uses a 6 bit count.",
    "Rotate 33 bits (CF, r/m32) right imm8 times.",
    "Rotate 65 bits (CF, r/m64) right imm8 times. Uses a 6 bit count.",
    "Rotate 8 bits r/m8 left once.",
    "Rotate 8 bits r/m8 left once",
    "Rotate 8 bits r/m8 left CL times.",
    "Rotate 8 bits r/m8 left CL times.",
    "Rotate 8 bits r/m8 left imm8 times.RCL/RCR/ROL/RORâ€”Rotate",
    "Rotate 8 bits r/m8 left imm8 times.",
    "Rotate 16 bits r/m16 left once.",
    "Rotate 16 bits r/m16 left CL times.",
    "Rotate 16 bits r/m16 left imm8 times.",
    "Rotate 32 bits r/m32 left once.",
    "Rotate 64 bits r/m64 left once. Uses a 6 bit count.",
    "Rotate 32 bits r/m32 left CL times.",
    "Rotate 64 bits r/m64 left CL times. Uses a 6 bit count.",
    "Rotate 32 bits r/m32 left imm8 times.",
    "Rotate 64 bits r/m64 left imm8 times. Uses a 6 bit count.",
    "Rotate 8 bits r/m8 right once.",
    "Rotate 8 bits r/m8 right once.",
    "Rotate 8 bits r/m8 right CL times.",
    "Rotate 8 bits r/m8 right CL times.",
    "Rotate 8 bits r/m16 right imm8 times.",
    "Rotate 8 bits r/m16 right imm8 times.",
    "Rotate 16 bits r/m16 right once.",
    "Rotate 16 bits r/m16 right CL times.",
    "Rotate 16 bits r/m16 right imm8 times.",
    "Rotate 32 bits r/m32 right once.",
    "Rotate 64 bits r/m64 right once. Uses a 6 bit count.",
    "Rotate 32 bits r/m32 right CL times.",
    "Rotate 64 bits r/m64 right CL times. Uses a 6 bit count.",
    "Rotate 32 bits r/m32 right imm8 times.",
    "Rotate 64 bits r/m64 right imm8 times. Uses a 6 bit count.",
    "Computes the approximate reciprocals of the packed single-precision floating-point values in xmm2/m128 and stores the results in xmm1.",
    "Computes the approximate reciprocals of packed single-precision values in xmm2/mem and stores the results in xmm1.",
    "Computes the approximate reciprocals of packed single-precision values in ymm2/mem and stores the results in ymm1.",
    "Computes the approximate reciprocal of the scalar single-precision floating-point value in xmm2/m32 and stores the result in xmm1.",
    "Computes the approximate reciprocal of the scalar single-precision floating-point value in xmm3/m32 and stores the result in xmm1. Also, upper single precision floating-point values (bits[127:32]) from xmm2 are copied to xmm1[127:32].",
    "Load the 32-bit destination register with the FS base address.",
    "Load the 64-bit destination register with the FS base address.",
    "Load the 32-bit destination register with the GS base address.",
    "Load the 64-bit destination register with the GS base address.",
    "Read MSR specified by ECX into EDX:EAX.",
    "Read IA32_TSC_AUX into r32.",
    "Read IA32_TSC_AUX into r64.",
    "Reads PKRU into EAX.",
    "Read performance-monitoring counter specified by ECX into EDX:EAX.",
    "Read a 16-bit random number and store in the destination register.",
    "Read a 32-bit random number and store in the destination register.",
    "Read a 64-bit random number and store in the destination register.",
    "Read a 16-bit NIST SP800-90B & C compliant random value and store in the destination register.",
    "Read a 32-bit NIST SP800-90B & C compliant random value and store in the destination register.",
    "Read a 64-bit NIST SP800-90B & C compliant random value and store in the destination register.",
    "Read time-stamp counter into EDX:EAX.",
    "Read 64-bit time-stamp counter and IA32_TSC_AUX value into EDX:EAX and ECX.",
    "Near return to calling procedure.",
    "Far return to calling procedure.",
    "Near return to calling procedure and pop imm16 bytes from stack.",
    "Far return to calling procedure and pop imm16 bytes from stack.",
    "Rotate 32-bit r/m32 right imm8 times without affecting arithmetic flags.",
    "Rotate 64-bit r/m64 right imm8 times without affecting arithmetic flags.",
    "Round packed double precision floating-point values in xmm2/m128 and place the result in xmm1. The rounding mode is determined by imm8.",
    "Round packed double-precision floating-point values in xmm2/m128 and place the result in xmm1. The rounding mode is determined by imm8.",
    "Round packed double-precision floating-point values in ymm2/m256 and place the result in ymm1. The rounding mode is determined by imm8.",
    "Round packed single precision floating-point values in xmm2/m128 and place the result in xmm1. The rounding mode is determined by imm8.",
    "Round packed single-precision floating-point values in xmm2/m128 and place the result in xmm1. The rounding mode is determined by imm8.",
    "Round packed single-precision floating-point values in ymm2/m256 and place the result in ymm1. The rounding mode is determined by imm8.",
    "Round the low packed double precision floating-point value in xmm2/m64 and place the result in xmm1. The rounding mode is determined by imm8.",
    "Round the low packed double precision floating-point value in xmm3/m64 and place the result in xmm1. The rounding mode is determined by imm8. Upper packed double precision floating-point value (bits[127:64]) from xmm2 is copied to xmm1[127:64].",
    "Round the low packed single precision floating-point value in xmm2/m32 and place the result in xmm1. The rounding mode is determined by imm8.",
    "Round the low packed single precision floating-point value in xmm3/m32 and place the result in xmm1. The rounding mode is determined by imm8. Also, upper packed single precision floating-point values (bits[127:32]) from xmm2 are copied to xmm1[127:32].",
    "Resume operation of interrupted program.",
    "Computes the approximate reciprocals of the square roots of the packed single-precision floating-point values in xmm2/m128 and stores the results in xmm1.",
    "Computes the approximate reciprocals of the square roots of packed single-precision values in xmm2/mem and stores the results in xmm1.",
    "Computes the approximate reciprocals of the square roots of packed single-precision values in ymm2/mem and stores the results in ymm1.",
    "Computes the approximate reciprocal of the square root of the low single-precision floating-point value in xmm2/m32 and stores the results in xmm1.",
    "Computes the approximate reciprocal of the square root of the low single precision floating-point value in xmm3/m32 and stores the results in xmm1. Also, upper single precision floating-point values (bits[127:32]) from xmm2 are copied to xmm1[127:32].",
    "Loads SF, ZF, AF, PF, and CF from AH into EFLAGS register.",
    "Multiply r/m8 by 2, once.",
    "Multiply r/m8 by 2, once.",
    "Multiply r/m8 by 2, CL times.",
    "Multiply r/m8 by 2, CL times.",
    "Multiply r/m8 by 2, imm8 times.",
    "Multiply r/m8 by 2, imm8 times.",
    "Multiply r/m16 by 2, once.",
    "Multiply r/m16 by 2, CL times.",
    "Multiply r/m16 by 2, imm8 times.",
    "Multiply r/m32 by 2, once.",
    "Multiply r/m64 by 2, once.",
    "Multiply r/m32 by 2, CL times.",
    "Multiply r/m64 by 2, CL times.",
    "Multiply r/m32 by 2, imm8 times.",
    "Multiply r/m64 by 2, imm8 times.",
    "Signed divide r/m8 by 2, once.",
    "Signed divide r/m8 by 2, once.",
    "Signed divide r/m8 by 2, CL times.",
    "Signed divide r/m8 by 2, CL times.",
    "Signed divide r/m8 by 2, imm8 time.",
    "Signed divide r/m8 by 2, imm8 times.",
    "Signed divide r/m16 by 2, once.",
    "Signed divide r/m16 by 2, CL times.",
    "Signed divide r/m16 by 2, imm8 times.",
    "Signed divide r/m32 by 2, once.",
    "Signed divide r/m64 by 2, once.",
    "Signed divide r/m32 by 2, CL times.",
    "Signed divide r/m64 by 2, CL times.",
    "Signed divide r/m32 by 2, imm8 times.",
    "Signed divide r/m64 by 2, imm8 times",
    "Multiply r/m8 by 2, once.",
    "Multiply r/m8 by 2, once.",
    "Multiply r/m8 by 2, CL times.",
    "Multiply r/m8 by 2, CL times.",
    "Multiply r/m8 by 2, imm8 times.",
    "Multiply r/m8 by 2, imm8 times.",
    "Multiply r/m16 by 2, once.",
    "Multiply r/m16 by 2, CL times.",
    "Multiply r/m16 by 2, imm8 times.",
    "Multiply r/m32 by 2, once.SAL/SAR/SHL/SHRâ€”Shift",
    "Multiply r/m64 by 2, once.",
    "Multiply r/m32 by 2, CL times.",
    "Multiply r/m64 by 2, CL times.",
    "Multiply r/m32 by 2, imm8 times.",
    "Multiply r/m64 by 2, imm8 times.",
    "Unsigned divide r/m8 by 2, once.",
    "Unsigned divide r/m8 by 2, once.",
    "Unsigned divide r/m8 by 2, CL times.",
    "Unsigned divide r/m8 by 2, CL times.",
    "Unsigned divide r/m8 by 2, imm8 times.",
    "Unsigned divide r/m8 by 2, imm8 times.",
    "Unsigned divide r/m16 by 2, once.",
    "Unsigned divide r/m16 by 2, CL times",
    "Unsigned divide r/m16 by 2, imm8 times.",
    "Unsigned divide r/m32 by 2, once.",
    "Unsigned divide r/m64 by 2, once.",
    "Unsigned divide r/m32 by 2, CL times.",
    "Unsigned divide r/m64 by 2, CL times.",
    "Unsigned divide r/m32 by 2, imm8 times.",
    "Unsigned divide r/m64 by 2, imm8 times.",
    "Shift r/m32 arithmetically right with count specified in r32b.",
    "Shift r/m32 logically left with count specified in r32b.",
    "Shift r/m32 logically right with count specified in r32b.",
    "Shift r/m64 arithmetically right with count specified in r64b.",
    "Shift r/m64 logically left with count specified in r64b.",
    "Shift r/m64 logically right with count specified in r64b.",
    "Subtract with borrow imm8 from AL.",
    "Subtract with borrow imm16 from AX.",
    "Subtract with borrow imm32 from EAX.",
    "Subtract with borrow sign-extended imm.32 to 64-bits from RAX.",
    "Subtract with borrow imm8 from r/m8.",
    "Subtract with borrow imm8 from r/m8.",
    "Subtract with borrow imm16 from r/m16.",
    "Subtract with borrow imm32 from r/m32.",
    "Subtract with borrow sign-extended imm32 to 64-bits from r/m64.",
    "Subtract with borrow sign-extended imm8 from r/m16.",
    "Subtract with borrow sign-extended imm8 from r/m32.",
    "Subtract with borrow sign-extended imm8 from r/m64.",
    "Subtract with borrow r8 from r/m8.",
    "Subtract with borrow r8 from r/m8.",
    "Subtract with borrow r16 from r/m16.",
    "Subtract with borrow r32 from r/m32.",
    "Subtract with borrow r64 from r/m64.",
    "Subtract with borrow r/m8 from r8.",
    "Subtract with borrow r/m8 from r8.",
    "Subtract with borrow r/m16 from r16.",
    "Subtract with borrow r/m32 from r32.",
    "Subtract with borrow r/m64 from r64.",
    "Compare AL with byte at ES:(E)DI or RDI, then set status flags.",
    "Compare AX with word at ES:(E)DI or RDI, then set status flags.",
    "Compare EAX with doubleword at ES(E)DI or RDI then set status flags.",
    "Compare RAX with quadword at RDI or EDI then set status flags.",
    "Compare AL with byte at ES:(E)DI or RDI then set status flags.",
    "Compare AX with word at ES:(E)DI or RDI then set status flags.",
    "Compare EAX with doubleword at ES:(E)DI or RDI then set status flags.",
    "Compare RAX with quadword at RDI or EDI then set status flags.",
    "Set byte if above (CF=0 and ZF=0).",
    "Set byte if above (CF=0 and ZF=0).",
    "Set byte if above or equal (CF=0).",
    "Set byte if above or equal (CF=0).",
    "Set byte if below (CF=1).",
    "Set byte if below (CF=1).",
    "Set byte if below or equal (CF=1 or ZF=1).",
    "Set byte if below or equal (CF=1 or ZF=1).",
    "Set byte if carry (CF=1).",
    "Set byte if carry (CF=1).",
    "Set byte if equal (ZF=1).",
    "Set byte if equal (ZF=1).",
    "Set byte if greater (ZF=0 and SF=OF).",
    "Set byte if greater (ZF=0 and SF=OF).",
    "Set byte if greater or equal (SF=OF).",
    "Set byte if greater or equal (SF=OF).",
    "Set byte if less (SFâ‰  OF).",
    "Set byte if less (SFâ‰  OF).",
    "Set byte if less or equal (ZF=1 or SFâ‰  OF).",
    "Set byte if less or equal (ZF=1 or SFâ‰  OF).",
    "Set byte if not above (CF=1 or ZF=1).",
    "Set byte if not above (CF=1 or ZF=1).",
    "Set byte if not above or equal (CF=1).",
    "Set byte if not above or equal (CF=1).",
    "Set byte if not below (CF=0).",
    "Set byte if not below (CF=0).",
    "Set byte if not below or equal (CF=0 and ZF=0).",
    "Set byte if not below or equal (CF=0 and ZF=0).",
    "Set byte if not carry (CF=0).",
    "Set byte if not carry (CF=0).",
    "Set byte if not equal (ZF=0).",
    "Set byte if not equal (ZF=0).",
    "Set byte if not greater (ZF=1 or SFâ‰  OF)",
    "Set byte if not greater (ZF=1 or SFâ‰  OF).",
    "Set byte if not greater or equal (SFâ‰  OF).",
    "Set byte if not greater or equal (SFâ‰  OF).",
    "Set byte if not less (SF=OF).",
    "Set byte if not less (SF=OF).",
    "Set byte if not less or equal (ZF=0 and SF=OF).SETccâ€”Set Byte on Condition",
    "Serializes store operations.",
    "Store GDTR to m.",
    "Performs an intermediate calculation for the next four SHA1 message dwords using previous message dwords from xmm1 and xmm2/m128, storing the result in xmm1.",
    "Performs the final calculation for the next four SHA1 message dwords using intermediate results from xmm1 and the previous message dwords from xmm2/m128, storing the result in xmm1.",
    "Calculates SHA1 state variable E after four rounds of operation from the current SHA1 state variable A in xmm1. The calculated value of the SHA1 state variable E is added to the scheduled dwords in xmm2/m128, and stored with some of the scheduled dwords in xmm1.",
    "Performs four rounds of SHA1 operation operating on SHA1 state (A,B,C,D) from xmm1, with a pre-computed sum of the next 4 round message dwords and state variable E from xmm2/m128. The immediate byte controls logic functions and round constants.",
    "Performs an intermediate calculation for the next four SHA256 message dwords using previous message dwords from xmm1 and xmm2/m128, storing the result in xmm1.",
    "Performs the final calculation for the next four SHA256 message dwords using previous message dwords from xmm1 and xmm2/m128, storing the result in xmm1.",
    "Perform 2 rounds of SHA256 operation using an initial SHA256 state (C,D,G,H) from xmm1, an initial SHA256 state (A,B,E,F) from xmm2/m128, and a pre-computed sum of the next 2 round mes-sage dwords and the corresponding round constants from the implicit operand XMM0, storing the updated SHA256 state (A,B,E,F) result in xmm1.",
    "Shift r/m16 to left imm8 places while shifting bits from r16 in from the right.",
    "Shift r/m16 to left CL places while shifting bits from r16 in from the right.",
    "Shift r/m32 to left imm8 places while shifting bits from r32 in from the right.",
    "Shift r/m64 to left imm8 places while shifting bits from r64 in from the right.",
    "Shift r/m32 to left CL places while shifting bits from r32 in from the right.",
    "Shift r/m64 to left CL places while shifting bits from r64 in from the right.",
    "Shift r/m16 to right imm8 places while shifting bits from r16 in from the left.",
    "Shift r/m16 to right CL places while shifting bits from r16 in from the left.",
    "Shift r/m32 to right imm8 places while shifting bits from r32 in from the left.",
    "Shift r/m64 to right imm8 places while shifting bits from r64 in from the left.",
    "Shift r/m32 to right CL places while shifting bits from r32 in from the left.",
    "Shift r/m64 to right CL places while shifting bits from r64 in from the left.",
    "Shuffle two pairs of double-precision floating-point values from xmm1 and xmm2/m128 using imm8 to select from each pair, interleaved result is stored in xmm1.",
    "Shuffle two pairs of double-precision floating-point values from xmm2 and xmm3/m128 using imm8 to select from each pair, interleaved result is stored in xmm1.",
    "Shuffle four pairs of double-precision floating-point values from ymm2 and ymm3/m256 using imm8 to select from each pair, interleaved result is stored in xmm1.",
    "Shuffle two paris of double-precision floating-point values from xmm2 and xmm3/m128/m64bcst using imm8 to select from each pair. store interleaved results in xmm1 subject to writemask k1.",
    "Shuffle four paris of double-precision floating-point values from ymm2 and ymm3/m256/m64bcst using imm8 to select from each pair. store interleaved results in ymm1 subject to writemask k1.",
    "Shuffle eight paris of double-precision floating-point values from zmm2 and zmm3/m512/m64bcst using imm8 to select from each pair. store interleaved results in zmm1 subject to writemask k1.",
    "Select from quadruplet of single-precision floating-point values in xmm1 and xmm2/m128 using imm8, interleaved result pairs are stored in xmm1.",
    "Select from quadruplet of single-precision floating-point values in xmm1 and xmm2/m128 using imm8, interleaved result pairs are stored in xmm1.",
    "Select from quadruplet of single-precision floating-point values in ymm2 and ymm3/m256 using imm8, interleaved result pairs are stored in ymm1.",
    "Select from quadruplet of single-precision floating-point values in xmm1 and xmm2/m128 using imm8, interleaved result pairs are stored in xmm1, subject to writemask k1.",
    "Select from quadruplet of single-precision floating-point values in ymm2 and ymm3/m256 using imm8, interleaved result pairs are stored in ymm1, subject to writemask k1.",
    "Select from quadruplet of single-precision floating-point values in zmm2 and zmm3/m512 using imm8, interleaved result pairs are stored in zmm1, subject to writemask k1.",
    "Store IDTR to m.",
    "Stores segment selector from LDTR in r/m16.",
    "Stores segment selector from LDTR in r64/m16.",
    "Store machine status word to r/m16.",
    "Store machine status word in low-order 16 bits of r32/m16; high-order 16 bits of r32 are undefined.",
    "Store machine status word in low-order 16 bits of r64/m16; high-order 16 bits of r32 are undefined.",
    "Computes Square Roots of the packed double-precision floating-point values in xmm2/m128 and stores the result in xmm1.",
    "Computes Square Roots of the packed double-precision floating-point values in xmm2/m128 and stores the result in xmm1.",
    "Computes Square Roots of the packed double-precision floating-point values in ymm2/m256 and stores the result in ymm1.",
    "Computes Square Roots of the packed double-precision floating-point values in xmm2/m128/m64bcst and stores the result in xmm1 subject to writemask k1.",
    "Computes Square Roots of the packed double-precision floating-point values in ymm2/m256/m64bcst and stores the result in ymm1 subject to writemask k1.",
    "Computes Square Roots of the packed double-precision floating-point values in zmm2/m512/m64bcst and stores the result in zmm1 subject to writemask k1.",
    "Computes Square Roots of the packed single-precision floating-point values in xmm2/m128 and stores the result in xmm1.",
    "Computes Square Roots of the packed single-precision floating-point values in xmm2/m128 and stores the result in xmm1.",
    "Computes Square Roots of the packed single-precision floating-point values in ymm2/m256 and stores the result in ymm1.",
    "Computes Square Roots of the packed single-precision floating-point values in xmm2/m128/m32bcst and stores the result in xmm1 subject to writemask k1.",
    "Computes Square Roots of the packed single-precision floating-point values in ymm2/m256/m32bcst and stores the result in ymm1 subject to writemask k1.",
    "Computes Square Roots of the packed single-precision floating-point values in zmm2/m512/m32bcst and stores the result in zmm1 subject to writemask k1.",
    "Computes square root of the low double-precision floating-point value in xmm2/m64 and stores the results in xmm1.",
    "Computes square root of the low double-precision floating-point value in xmm3/m64 and stores the results in xmm1. Also, upper double-precision floating-point value (bits[127:64]) from xmm2 is copied to xmm1[127:64].",
    "Computes square root of the low double-precision floating-point value in xmm3/m64 and stores the results in xmm1 under writemask k1. Also, upper double-precision floating-point value (bits[127:64]) from xmm2 is copied to xmm1[127:64].",
    "Computes square root of the low single-precision floating-point value in xmm2/m32 and stores the results in xmm1.",
    "Computes square root of the low single-precision floating-point value in xmm3/m32 and stores the results in xmm1. Also, upper single-precision floating-point values (bits[127:32]) from xmm2 are copied to xmm1[127:32].",
    "Computes square root of the low single-precision floating-point value in xmm3/m32 and stores the results in xmm1 under writemask k1. Also, upper single-precision floating-point values (bits[127:32]) from xmm2 are copied to xmm1[127:32].",
    "Set the AC flag in the EFLAGS register.",
    "Set CF flag.",
    "Set DF flag.",
    "Set interrupt flag; external, maskable interrupts enabled at the end of the next instruction.",
    "Store contents of MXCSR register to m32.",
    "Store contents of MXCSR register to m32.",
    "For legacy mode, store AL at address ES:(E)DI; For 64-bit mode store AL at address RDI or EDI.",
    "For legacy mode, store AX at address ES:(E)DI; For 64-bit mode store AX at address RDI or EDI.",
    "For legacy mode, store EAX at address ES:(E)DI; For 64-bit mode store EAX at address RDI or EDI.",
    "Store RAX at address RDI or EDI.",
    "For legacy mode, store AL at address ES:(E)DI; For 64-bit mode store AL at address RDI or EDI.",
    "For legacy mode, store AX at address ES:(E)DI; For 64-bit mode store AX at address RDI or EDI.",
    "For legacy mode, store EAX at address ES:(E)DI; For 64-bit mode store EAX at address RDI or EDI.",
    "Store RAX at address RDI or EDI.",
    "Stores segment selector from TR in r/m16.",
    "Subtract imm8 from AL.",
    "Subtract imm16 from AX.",
    "Subtract imm32 from EAX.",
    "Subtract imm32 sign-extended to 64-bits from RAX.",
    "Subtract imm8 from r/m8.",
    "Subtract imm8 from r/m8.",
    "Subtract imm16 from r/m16.",
    "Subtract imm32 from r/m32.",
    "Subtract imm32 sign-extended to 64-bits from r/m64.",
    "Subtract sign-extended imm8 from r/m16.",
    "Subtract sign-extended imm8 from r/m32.",
    "Subtract sign-extended imm8 from r/m64.",
    "Subtract r8 from r/m8.",
    "Subtract r8 from r/m8.",
    "Subtract r16 from r/m16.",
    "Subtract r32 from r/m32.",
    "Subtract r64 from r/m64.",
    "Subtract r/m8 from r8.",
    "Subtract r/m8 from r8.",
    "Subtract r/m16 from r16.",
    "Subtract r/m32 from r32.",
    "Subtract r/m64 from r64.",
    "Subtract packed double-precision floating-point values in xmm2/mem from xmm1 and store result in xmm1.",
    "Subtract packed double-precision floating-point values in xmm3/mem from xmm2 and store result in xmm1.",
    "Subtract packed double-precision floating-point values in ymm3/mem from ymm2 and store result in ymm1.",
    "Subtract packed double-precision floating-point values from xmm3/m128/m64bcst to xmm2 and store result in xmm1 with writemask k1.",
    "Subtract packed double-precision floating-point values from ymm3/m256/m64bcst to ymm2 and store result in ymm1 with writemask k1.",
    "Subtract packed double-precision floating-point values from zmm3/m512/m64bcst to zmm2 and store result in zmm1 with writemask k1.",
    "Subtract packed single-precision floating-point values in xmm2/mem from xmm1 and store result in xmm1.",
    "Subtract packed single-precision floating-point values in xmm3/mem from xmm2 and stores result in xmm1.",
    "Subtract packed single-precision floating-point values in ymm3/mem from ymm2 and stores result in ymm1.",
    "Subtract packed single-precision floating-point values from xmm3/m128/m32bcst to xmm2 and stores result in xmm1 with writemask k1.",
    "Subtract packed single-precision floating-point values from ymm3/m256/m32bcst to ymm2 and stores result in ymm1 with writemask k1.",
    "Subtract packed single-precision floating-point values in zmm3/m512/m32bcst from zmm2 and stores result in zmm1 with writemask k1.",
    "Subtract the low double-precision floating-point value in xmm2/m64 from xmm1 and store the result in xmm1.",
    "Subtract the low double-precision floating-point value in xmm3/m64 from xmm2 and store the result in xmm1.",
    "Subtract the low double-precision floating-point value in xmm3/m64 from xmm2 and store the result in xmm1 under writemask k1.",
    "Subtract the low single-precision floating-point value in xmm2/m32 from xmm1 and store the result in xmm1.",
    "Subtract the low single-precision floating-point value in xmm3/m32 from xmm2 and store the result in xmm1.",
    "Subtract the low single-precision floating-point value in xmm3/m32 from xmm2 and store the result in xmm1 under writemask k1.",
    "Exchanges the current GS base register value with the value contained in MSR address C0000102H.",
    "Fast call to privilege level 0 system procedures.",
    "Fast call to privilege level 0 system procedures.",
    "Fast return to privilege level 3 user code.",
    "Fast return to 64-bit mode privilege level 3 user code.",
    "Return to compatibility mode from fast system call",
    "Return to 64-bit mode from fast system call",
    "AND imm8 with AL; set SF, ZF, PF according to result.",
    "AND imm16 with AX; set SF, ZF, PF according to result.",
    "AND imm32 with EAX; set SF, ZF, PF according to result.",
    "AND imm32 sign-extended to 64-bits with RAX; set SF, ZF, PF according to result.",
    "AND imm8 with r/m8; set SF, ZF, PF according to result.",
    "AND imm8 with r/m8; set SF, ZF, PF according to result.",
    "AND imm16 with r/m16; set SF, ZF, PF according to result.",
    "AND imm32 with r/m32; set SF, ZF, PF according to result.",
    "AND imm32 sign-extended to 64-bits with r/m64; set SF, ZF, PF according to result.",
    "AND r8 with r/m8; set SF, ZF, PF according to result.",
    "AND r8 with r/m8; set SF, ZF, PF according to result.",
    "AND r16 with r/m16; set SF, ZF, PF according to result.",
    "AND r32 with r/m32; set SF, ZF, PF according to result.",
    "AND r64 with r/m64; set SF, ZF, PF according to result.",
    "Count the number of trailing zero bits in r/m16, return result in r16.",
    "Count the number of trailing zero bits in r/m32, return result in r32.",
    "Count the number of trailing zero bits in r/m64, return result in r64.",
    "Compare low double-precision floating-point values in xmm1 and xmm2/mem64 and set the EFLAGS flags accordingly.",
    "Compare low double-precision floating-point values in xmm1 and xmm2/mem64 and set the EFLAGS flags accordingly.",
    "Compare low double-precision floating-point values in xmm1 and xmm2/m64 and set the EFLAGS flags accordingly.",
    "Compare low single-precision floating-point values in xmm1 and xmm2/mem32 and set the EFLAGS flags accordingly.",
    "Compare low single-precision floating-point values in xmm1 and xmm2/mem32 and set the EFLAGS flags accordingly.",
    "Compare low single-precision floating-point values in xmm1 and xmm2/mem32 and set the EFLAGS flags accordingly.",
    "Raise invalid opcode exception.",
    "Raise invalid opcode exception.",
    "Raise invalid opcode exception.",
    "Unpacks and Interleaves double-precision floating-point values from high quadwords of xmm1 and xmm2/m128.",
    "Unpacks and Interleaves double-precision floating-point values from high quadwords of xmm2 and xmm3/m128.",
    "Unpacks and Interleaves double-precision floating-point values from high quadwords of ymm2 and ymm3/m256.",
    "Unpacks and Interleaves double precision floating-point values from high quadwords of xmm2 and xmm3/m128/m64bcst subject to writemask k1.",
    "Unpacks and Interleaves double precision floating-point values from high quadwords of ymm2 and ymm3/m256/m64bcst subject to writemask k1.",
    "Unpacks and Interleaves double-precision floating-point values from high quadwords of zmm2 and zmm3/m512/m64bcst subject to writemask k1.",
    "Unpacks and Interleaves single-precision floating-point values from high quadwords of xmm1 and xmm2/m128.",
    "Unpacks and Interleaves single-precision floating-point values from high quadwords of xmm2 and xmm3/m128.",
    "Unpacks and Interleaves single-precision floating-point values from high quadwords of ymm2 and ymm3/m256.",
    "Unpacks and Interleaves single-precision floating-point values from high quadwords of xmm2 and xmm3/m128/m32bcst and write result to xmm1 subject to writemask k1.",
    "Unpacks and Interleaves single-precision floating-point values from high quadwords of ymm2 and ymm3/m256/m32bcst and write result to ymm1 subject to writemask k1.",
    "Unpacks and Interleaves single-precision floating-point values from high quadwords of zmm2 and zmm3/m512/m32bcst and write result to zmm1 subject to writemask k1.",
    "Unpacks and Interleaves double-precision floating-point values from low quadwords of xmm1 and xmm2/m128.",
    "Unpacks and Interleaves double-precision floating-point values from low quadwords of xmm2 and xmm3/m128.",
    "Unpacks and Interleaves double-precision floating-point values from low quadwords of ymm2 and ymm3/m256.",
    "Unpacks and Interleaves double precision floating-point values from low quadwords of xmm2 and xmm3/m128/m64bcst subject to write mask k1.",
    "Unpacks and Interleaves double precision floating-point values from low quadwords of ymm2 and ymm3/m256/m64bcst subject to write mask k1.",
    "Unpacks and Interleaves double-precision floating-point values from low quadwords of zmm2 and zmm3/m512/m64bcst subject to write mask k1.",
    "Unpacks and Interleaves single-precision floating-point values from low quadwords of xmm1 and xmm2/m128.",
    "Unpacks and Interleaves single-precision floating-point values from low quadwords of xmm2 and xmm3/m128.",
    "Unpacks and Interleaves single-precision floating-point values from low quadwords of ymm2 and ymm3/m256.",
    "Unpacks and Interleaves single-precision floating-point values from low quadwords of xmm2 and xmm3/mem and write result to xmm1 subject to write mask k1.",
    "Unpacks and Interleaves single-precision floating-point values from low quadwords of ymm2 and ymm3/mem and write result to ymm1 subject to write mask k1.",
    "Unpacks and Interleaves single-precision floating-point values from low quadwords of zmm2 and zmm3/m512/m32bcst and write result to zmm1 subject to write mask k1.",
    "Shift right and merge vectors xmm2 and xmm3/m128/m32bcst with double-word granularity using imm8 as number of elements to shift, and store the final result in xmm1, under writemask.",
    "Shift right and merge vectors xmm2 and xmm3/m128/m64bcst with quad-word granularity using imm8 as number of elements to shift, and store the final result in xmm1, under writemask.",
    "Shift right and merge vectors ymm2 and ymm3/m256/m32bcst with double-word granularity using imm8 as number of elements to shift, and store the final result in ymm1, under writemask.",
    "Shift right and merge vectors ymm2 and ymm3/m256/m64bcst with quad-word granularity using imm8 as number of elements to shift, and store the final result in ymm1, under writemask.",
    "Shift right and merge vectors zmm2 and zmm3/m512/m32bcst with double-word granularity using imm8 as number of elements to shift, and store the final result in zmm1, under writemask.",
    "Shift right and merge vectors zmm2 and zmm3/m512/m64bcst with quad-word granularity using imm8 as number of elements to shift, and store the final result in zmm1, under writemask.",
    "Blend double-precision vector xmm2 and double-precision vector xmm3/m128/m64bcst and store the result in xmm1, under control mask.",
    "Blend double-precision vector ymm2 and double-precision vector ymm3/m256/m64bcst and store the result in ymm1, under control mask.",
    "Blend double-precision vector zmm2 and double-precision vector zmm3/m512/m64bcst and store the result in zmm1, under control mask.",
    "Blend single-precision vector xmm2 and single-precision vector xmm3/m128/m32bcst and store the result in xmm1, under control mask.",
    "Blend single-precision vector ymm2 and single-precision vector ymm3/m256/m32bcst and store the result in ymm1, under control mask.",
    "Blend single-precision vector zmm2 and single-precision vector zmm3/m512/m32bcst using k1 as select control and store the result in zmm1.",
    "Broadcast single-precision floating-point element in mem to four locations in xmm1.",
    "Broadcast single-precision floating-point element in mem to eight locations in ymm1.",
    "Broadcast double-precision floating-point element in mem to four locations in ymm1.",
    "Broadcast 128 bits of floating-point data in mem to low and high 128-bits in ymm1.",
    "Broadcast the low single-precision floating-point element in the source operand to four locations in xmm1.",
    "Broadcast low single-precision floating-point element in the source operand to eight locations in ymm1.",
    "Broadcast low double-precision floating-point element in the source operand to four locations in ymm1.",
    "Broadcast low double-precision floating-point element in xmm2/m64 to four locations in ymm1 using writemask k1.",
    "Broadcast low double-precision floating-point element in xmm2/m64 to eight locations in zmm1 using writemask k1.",
    "Broadcast two single-precision floating-point elements in xmm2/m64 to locations in ymm1 using writemask k1.",
    "Broadcast two single-precision floating-point elements in xmm2/m64 to locations in zmm1 using writemask k1.",
    "Broadcast low single-precision floating-point element in xmm2/m32 to all locations in xmm1 using writemask k1.",
    "Broadcast low single-precision floating-point element in xmm2/m32 to all locations in ymm1 using writemask k1.",
    "Broadcast low single-precision floating-point element in xmm2/m32 to all locations in zmm1 using writemask k1.",
    "Broadcast 128 bits of 4 single-precision floating-point data in mem to locations in ymm1 using writemask k1.",
    "Broadcast 128 bits of 4 single-precision floating-point data in mem to locations in zmm1 using writemask k1.",
    "Broadcast 128 bits of 2 double-precision floating-point data in mem to locations in ymm1 using writemask k1.VBROADCASTâ€”Load with Broadcast Floating-Point Data",
    "Compress packed double-precision floating-point values from xmm2 to xmm1/m128 using writemask k1.",
    "Compress packed double-precision floating-point values from ymm2 to ymm1/m256 using writemask k1.",
    "Compress packed double-precision floating-point values from zmm2 using control mask k1 to zmm1/m512.",
    "Compress packed single-precision floating-point values from xmm2 to xmm1/m128 using writemask k1.",
    "Compress packed single-precision floating-point values from ymm2 to ymm1/m256 using writemask k1.",
    "Compress packed single-precision floating-point values from zmm2 using control mask k1 to zmm1/m512.",
    "Convert two packed double-precision floating-point values from xmm2/m128/m64bcst to two packed quadword integers in xmm1 with writemask k1.",
    "Convert four packed double-precision floating-point values from ymm2/m256/m64bcst to four packed quadword integers in ymm1 with writemask k1.",
    "Convert eight packed double-precision floating-point values from zmm2/m512/m64bcst to eight packed quadword integers in zmm1 with writemask k1.",
    "Convert two packed double-precision floating-point values in xmm2/m128/m64bcst to two unsigned doubleword integers in xmm1 subject to writemask k1.",
    "Convert four packed double-precision floating-point values in ymm2/m256/m64bcst to four unsigned doubleword integers in xmm1 subject to writemask k1.",
    "Convert eight packed double-precision floating-point values in zmm2/m512/m64bcst to eight unsigned doubleword integers in ymm1 subject to writemask k1.",
    "Convert two packed double-precision floating-point values from xmm2/mem to two packed unsigned quadword integers in xmm1 with writemask k1.",
    "Convert fourth packed double-precision floating-point values from ymm2/mem to four packed unsigned quadword integers in ymm1 with writemask k1.",
    "Convert eight packed double-precision floating-point values from zmm2/mem to eight packed unsigned quadword integers in zmm1 with writemask k1.",
    "Convert four packed half precision (16-bit) floating-point values in xmm2/m64 to packed single-precision floating-point value in xmm1.",
    "Convert eight packed half precision (16-bit) floating-point values in xmm2/m128 to packed single-precision floating-point value in ymm1.",
    "Convert four packed half precision (16-bit) floating-point values in xmm2/m64 to packed single-precision floating-point values in xmm1.",
    "Convert eight packed half precision (16-bit) floating-point values in xmm2/m128 to packed single-precision floating-point values in ymm1.",
    "Convert sixteen packed half precision (16-bit) floating-point values in ymm2/m256 to packed single-precision floating-point values in zmm1.",
    "Convert four packed single-precision floating-point values in xmm2 to packed half-precision (16-bit) floating-point values in xmm1/m64. Imm8 provides rounding controls.",
    "Convert eight packed single-precision floating-point values in ymm2 to packed half-precision (16-bit) floating-point values in xmm1/m128. Imm8 provides rounding controls.",
    "Convert four packed single-precision floating-point values in xmm2 to packed half-precision (16-bit) floating-point values in xmm1/m64. Imm8 provides rounding controls.",
    "Convert eight packed single-precision floating-point values in ymm2 to packed half-precision (16-bit) floating-point values in xmm1/m128. Imm8 provides rounding controls.",
    "Convert sixteen packed single-precision floating-point values in zmm2 to packed half-precision (16-bit) floating-point values in ymm1/m256. Imm8 provides rounding controls.",
    "Convert two packed single precision floating-point values from xmm2/m64/m32bcst to two packed signed quadword values in xmm1 subject to writemask k1.",
    "Convert four packed single precision floating-point values from xmm2/m128/m32bcst to four packed signed quadword values in ymm1 subject to writemask k1.",
    "Convert eight packed single precision floating-point values from ymm2/m256/m32bcst to eight packed signed quadword values in zmm1 subject to writemask k1.",
    "Convert four packed single precision floating-point values from xmm2/m128/m32bcst to four packed unsigned doubleword values in xmm1 subject to writemask k1.",
    "Convert eight packed single precision floating-point values from ymm2/m256/m32bcst to eight packed unsigned doubleword values in ymm1 subject to writemask k1.",
    "Convert sixteen packed single-precision floating-point values from zmm2/m512/m32bcst to sixteen packed unsigned doubleword values in zmm1 subject to writemask k1.",
    "Convert two packed single precision floating-point values from zmm2/m64/m32bcst to two packed unsigned quadword values in zmm1 subject to writemask k1.",
    "Convert four packed single precision floating-point values from xmm2/m128/m32bcst to four packed unsigned quadword values in ymm1 subject to writemask k1.",
    "Convert eight packed single precision floating-point values from ymm2/m256/m32bcst to eight packed unsigned quadword values in zmm1 subject to writemask k1.",
    "Convert two packed quadword integers from xmm2/m128/m64bcst to packed double-precision floating-point values in xmm1 with writemask k1.",
    "Convert four packed quadword integers from ymm2/m256/m64bcst to packed double-precision floating-point values in ymm1 with writemask k1.",
    "Convert eight packed quadword integers from zmm2/m512/m64bcst to eight packed double-precision floating-point values in zmm1 with writemask k1.",
    "Convert two packed quadword integers from xmm2/mem to packed single-precision floating-point values in xmm1 with writemask k1.",
    "Convert four packed quadword integers from ymm2/mem to packed single-precision floating-point values in xmm1 with writemask k1.",
    "Convert eight packed quadword integers from zmm2/mem to eight packed single-precision floating-point values in ymm1 with writemask k1.",
    "Convert one double-precision floating-point value from xmm1/m64 to one unsigned doubleword integer r32.",
    "Convert one double-precision floating-point value from xmm1/m64 to one unsigned quadword integer zeroextended into r64.",
    "Convert one single-precision floating-point value from xmm1/m32 to one unsigned doubleword integer in r32.",
    "Convert one single-precision floating-point value from xmm1/m32 to one unsigned quadword integer in r64.",
    "Convert two packed double-precision floating-point values from zmm2/m128/m64bcst to two packed quadword integers in zmm1 using truncation with writemask k1.",
    "Convert four packed double-precision floating-point values from ymm2/m256/m64bcst to four packed quadword integers in ymm1 using truncation with writemask k1.",
    "Convert eight packed double-precision floating-point values from zmm2/m512 to eight packed quadword integers in zmm1 using truncation with writemask k1.",
    "Convert two packed double-precision floating-point values in xmm2/m128/m64bcst to two unsigned doubleword integers in xmm1 using truncation subject to writemask k1.",
    "Convert four packed double-precision floating-point values in ymm2/m256/m64bcst to four unsigned doubleword integers in xmm1 using truncation subject to writemask k1.",
    "Convert eight packed double-precision floating-point values in zmm2/m512/m64bcst to eight unsigned doubleword integers in ymm1 using truncation subject to writemask k1.",
    "Convert two packed double-precision floating-point values from xmm2/m128/m64bcst to two packed unsigned quadword integers in xmm1 using truncation with writemask k1.",
    "Convert four packed double-precision floating-point values from ymm2/m256/m64bcst to four packed unsigned quadword integers in ymm1 using truncation with writemask k1.",
    "Convert eight packed double-precision floating-point values from zmm2/mem to eight packed unsigned quadword integers in zmm1 using truncation with writemask k1.",
    "Convert two packed single precision floating-point values from xmm2/m64/m32bcst to two packed signed quadword values in xmm1 using truncation subject to writemask k1.",
    "Convert four packed single precision floating-point values from xmm2/m128/m32bcst to four packed signed quadword values in ymm1 using truncation subject to writemask k1.",
    "Convert eight packed single precision floating-point values from ymm2/m256/m32bcst to eight packed signed quadword values in zmm1 using truncation subject to writemask k1.",
    "Convert four packed single precision floating-point values from xmm2/m128/m32bcst to four packed unsigned doubleword values in xmm1 using truncation subject to writemask k1.",
    "Convert eight packed single precision floating-point values from ymm2/m256/m32bcst to eight packed unsigned doubleword values in ymm1 using truncation subject to writemask k1.",
    "Convert sixteen packed single-precision floating-point values from zmm2/m512/m32bcst to sixteen packed unsigned doubleword values in zmm1 using truncation subject to writemask k1.",
    "Convert two packed single precision floating-point values from xmm2/m64/m32bcst to two packed unsigned quadword values in xmm1 using truncation subject to writemask k1.",
    "Convert four packed single precision floating-point values from xmm2/m128/m32bcst to four packed unsigned quadword values in ymm1 using truncation subject to writemask k1.",
    "Convert eight packed single precision floating-point values from ymm2/m256/m32bcst to eight packed unsigned quadword values in zmm1 using truncation subject to writemask k1.",
    "Convert one double-precision floating-point value from xmm1/m64 to one unsigned doubleword integer r32 using truncation.",
    "Convert one double-precision floating-point value from xmm1/m64 to one unsigned quadword integer zeroextended into r64 using truncation.",
    "Convert one single-precision floating-point value from xmm1/m32 to one unsigned doubleword integer in r32 using truncation.",
    "Convert one single-precision floating-point value from xmm1/m32 to one unsigned quadword integer in r64 using truncation.",
    "Convert two packed unsigned doubleword integers from ymm2/m64/m32bcst to packed double-precision floating-point values in zmm1 with writemask k1.",
    "Convert four packed unsigned doubleword integers from xmm2/m128/m32bcst to packed double-precision floating-point values in zmm1 with writemask k1.",
    "Convert eight packed unsigned doubleword integers from ymm2/m256/m32bcst to eight packed double-precision floating-point values in zmm1 with writemask k1.",
    "Convert four packed unsigned doubleword integers from xmm2/m128/m32bcst to packed single-precision floating-point values in xmm1 with writemask k1.",
    "Convert eight packed unsigned doubleword integers from ymm2/m256/m32bcst to packed single-precision floating-point values in zmm1 with writemask k1.",
    "Convert sixteen packed unsigned doubleword integers from zmm2/m512/m32bcst to sixteen packed single-precision floating-point values in zmm1 with writemask k1.",
    "Convert two packed unsigned quadword integers from xmm2/m128/m64bcst to two packed double-precision floating-point values in xmm1 with writemask k1.",
    "Convert four packed unsigned quadword integers from ymm2/m256/m64bcst to packed double-precision floating-point values in ymm1 with writemask k1.",
    "Convert eight packed unsigned quadword integers from zmm2/m512/m64bcst to eight packed double-precision floating-point values in zmm1 with writemask k1.",
    "Convert two packed unsigned quadword integers from xmm2/m128/m64bcst to packed single-precision floating-point values in zmm1 with writemask k1.",
    "Convert four packed unsigned quadword integers from ymm2/m256/m64bcst to packed single-precision floating-point values in xmm1 with writemask k1.",
    "Convert eight packed unsigned quadword integers from zmm2/m512/m64bcst to eight packed single-precision floating-point values in zmm1 with writemask k1.",
    "Convert one unsigned doubleword integer from r/m32 to one double-precision floating-point value in xmm1.",
    "Convert one unsigned quadword integer from r/m64 to one double-precision floating-point value in xmm1.",
    "Convert one signed doubleword integer from r/m32 to one single-precision floating-point value in xmm1.",
    "Convert one signed quadword integer from r/m64 to one single-precision floating-point value in xmm1.",
    "Compute packed SAD word results of unsigned bytes in dword block from xmm2 with unsigned bytes of dword blocks transformed from xmm3/m128 using the shuffle controls in imm8. Results are written to xmm1 under the writemask k1.",
    "Compute packed SAD word results of unsigned bytes in dword block from ymm2 with unsigned bytes of dword blocks transformed from ymm3/m256 using the shuffle controls in imm8. Results are written to ymm1 under the writemask k1.",
    "Compute packed SAD word results of unsigned bytes in dword block from zmm2 with unsigned bytes of dword blocks transformed from zmm3/m512 using the shuffle controls in imm8. Results are written to zmm1 under the writemask k1.",
    "Set ZF=1 if segment specified with r/m16 can be read.",
    "Set ZF=1 if segment specified with r/m16 can be written.",
    "Computes approximations to the exponential 2^x (with less than 2^-23 of maximum relative error) of the packed double-precision floating-point values from zmm2/m512/m64bcst and stores the floating-point result in zmm1with writemask k1.",
    "Computes approximations to the exponential 2^x (with less than 2^-23 of maximum relative error) of the packed single-precision floating-point values from zmm2/m512/m32bcst and stores the floating-point result in zmm1with writemask k1.",
    "Expand packed double-precision floating-point values from xmm2/m128 to xmm1 using writemask k1.",
    "Expand packed double-precision floating-point values from ymm2/m256 to ymm1 using writemask k1.",
    "Expand packed double-precision floating-point values from zmm2/m512 to zmm1 using writemask k1.",
    "Expand packed single-precision floating-point values from xmm2/m128 to xmm1 using writemask k1.",
    "Expand packed single-precision floating-point values from ymm2/m256 to ymm1 using writemask k1.",
    "Expand packed single-precision floating-point values from zmm2/m512 to zmm1 using writemask k1.",
    "Extract 128 bits of packed floating-point values from ymm2 and store results in xmm1/m128. EVEX.256.66.0F3A.W0 19 /r ib VEXTRACTF32X4 xmm1/m128 {k1}{z}, ymm2, imm8 C V/V AVX512VL AVX512F Extract 128 bits of packed single-precision floating-point values from ymm2 and store results in xmm1/m128 subject to writemask k1.",
    "Extract 128 bits of packed single-precision floating-point values from zmm2 and store results in xmm1/m128 subject to writemask k1. EVEX.256.66.0F3A.W1 19 /r ib VEXTRACTF64X2 xmm1/m128 {k1}{z}, ymm2, imm8 B V/V AVX512VL AVX512DQ Extract 128 bits of packed double-precision floating-point values from ymm2 and store results in xmm1/m128 subject to writemask k1. EVEX.512.66.0F3A.W1 19 /r ib VEXTRACTF64X2 xmm1/m128 {k1}{z}, zmm2, imm8 B V/V AVX512DQ Extract 128 bits of packed double-precision floating-point values from zmm2 and store results in xmm1/m128 subject to writemask k1. EVEX.512.66.0F3A.W0 1B /r ib VEXTRACTF32X8 ymm1/m256 {k1}{z}, zmm2, imm8 D V/V AVX512DQ Extract 256 bits of packed single-precision floating-point values from zmm2 and store results in ymm1/m256 subject to writemask k1.",
    "Extract 256 bits of packed double-precision floating-point values from zmm2 and store results in ymm1/m256 subject to writemask k1.",
    "Extract 128 bits of integer data from ymm2 and store results in xmm1/m128. EVEX.256.66.0F3A.W0 39 /r ib VEXTRACTI32X4 xmm1/m128 {k1}{z}, ymm2, imm8 C V/V AVX512VL AVX512F Extract 128 bits of double-word integer values from ymm2 and store results in xmm1/m128 subject to writemask k1.",
    "Extract 128 bits of double-word integer values from zmm2 and store results in xmm1/m128 subject to writemask k1. EVEX.256.66.0F3A.W1 39 /r ib VEXTRACTI64X2 xmm1/m128 {k1}{z}, ymm2, imm8 B V/V AVX512VL AVX512DQ Extract 128 bits of quad-word integer values from ymm2 and store results in xmm1/m128 subject to writemask k1. EVEX.512.66.0F3A.W1 39 /r ib VEXTRACTI64X2 xmm1/m128 {k1}{z}, zmm2, imm8 B V/V AVX512DQ Extract 128 bits of quad-word integer values from zmm2 and store results in xmm1/m128 subject to writemask k1. EVEX.512.66.0F3A.W0 3B /r ib VEXTRACTI32X8 ymm1/m256 {k1}{z}, zmm2, imm8 D V/V AVX512DQ Extract 256 bits of double-word integer values from zmm2 and store results in ymm1/m256 subject to writemask k1.",
    "Extract 256 bits of quad-word integer values from zmm2 and store results in ymm1/m256 subject to writemask k1.",
    "Fix up special numbers in float64 vector xmm1, float64 vector xmm2 and int64 vector xmm3/m128/m64bcst and store the result in xmm1, under writemask.",
    "Fix up special numbers in float64 vector ymm1, float64 vector ymm2 and int64 vector ymm3/m256/m64bcst and store the result in ymm1, under writemask.",
    "Fix up elements of float64 vector in zmm2 using int64 vector table in zmm3/m512/m64bcst, combine with preserved elements from zmm1, and store the result in zmm1.",
    "Fix up special numbers in float32 vector xmm1, float32 vector xmm2 and int32 vector xmm3/m128/m32bcst and store the result in xmm1, under writemask.",
    "Fix up special numbers in float32 vector ymm1, float32 vector ymm2 and int32 vector ymm3/m256/m32bcst and store the result in ymm1, under writemask.",
    "Fix up elements of float32 vector in zmm2 using int32 vector table in zmm3/m512/m32bcst, combine with preserved elements from zmm1, and store the result in zmm1.",
    "Fix up a float64 number in the low quadword element of xmm2 using scalar int32 table in xmm3/m64 and store the result in xmm1.",
    "Fix up a float32 number in the low doubleword element in xmm2 using scalar int32 table in xmm3/m32 and store the result in xmm1.",
    "Multiply packed double-precision floating-point values from xmm1 and xmm3/mem, add to xmm2 and put result in xmm1.",
    "Multiply packed double-precision floating-point values from xmm1 and xmm2, add to xmm3/mem and put result in xmm1.",
    "Multiply packed double-precision floating-point values from xmm2 and xmm3/mem, add to xmm1 and put result in xmm1.",
    "Multiply packed double-precision floating-point values from ymm1 and ymm3/mem, add to ymm2 and put result in ymm1.",
    "Multiply packed double-precision floating-point values from ymm1 and ymm2, add to ymm3/mem and put result in ymm1.",
    "Multiply packed double-precision floating-point values from ymm2 and ymm3/mem, add to ymm1 and put result in ymm1.",
    "Multiply packed double-precision floating-point values from xmm1 and xmm3/m128/m64bcst, add to xmm2 and put result in xmm1.",
    "Multiply packed double-precision floating-point values from xmm1 and xmm2, add to xmm3/m128/m64bcst and put result in xmm1.",
    "Multiply packed double-precision floating-point values from xmm2 and xmm3/m128/m64bcst, add to xmm1 and put result in xmm1.",
    "Multiply packed double-precision floating-point values from ymm1 and ymm3/m256/m64bcst, add to ymm2 and put result in ymm1.",
    "Multiply packed double-precision floating-point values from ymm1 and ymm2, add to ymm3/m256/m64bcst and put result in ymm1.",
    "Multiply packed double-precision floating-point values from ymm2 and ymm3/m256/m64bcst, add to ymm1 and put result in ymm1.",
    "Multiply packed double-precision floating-point values from zmm1 and zmm3/m512/m64bcst, add to zmm2 and put result in zmm1.",
    "Multiply packed double-precision floating-point values from zmm1 and zmm2, add to zmm3/m512/m64bcst and put result in zmm1.",
    "Multiply packed double-precision floating-point values from zmm2 and zmm3/m512/m64bcst, add to zmm1 and put result in zmm1.VFMADD132PD/VFMADD213PD/VFMADD231PDâ€”Fused Multiply-Add of Packed Double-Precision Floating-Point Values",
    "Multiply packed single-precision floating-point values from xmm1 and xmm3/mem, add to xmm2 and put result in xmm1.",
    "Multiply packed single-precision floating-point values from xmm1 and xmm2, add to xmm3/mem and put result in xmm1.",
    "Multiply packed single-precision floating-point values from xmm2 and xmm3/mem, add to xmm1 and put result in xmm1.",
    "Multiply packed single-precision floating-point values from ymm1 and ymm3/mem, add to ymm2 and put result in ymm1.",
    "Multiply packed single-precision floating-point values from ymm1 and ymm2, add to ymm3/mem and put result in ymm1.",
    "Multiply packed single-precision floating-point values from ymm2 and ymm3/mem, add to ymm1 and put result in ymm1.",
    "Multiply packed single-precision floating-point values from xmm1 and xmm3/m128/m32bcst, add to xmm2 and put result in xmm1.",
    "Multiply packed single-precision floating-point values from xmm1 and xmm2, add to xmm3/m128/m32bcst and put result in xmm1.",
    "Multiply packed single-precision floating-point values from xmm2 and xmm3/m128/m32bcst, add to xmm1 and put result in xmm1.",
    "Multiply packed single-precision floating-point values from ymm1 and ymm3/m256/m32bcst, add to ymm2 and put result in ymm1.",
    "Multiply packed single-precision floating-point values from ymm1 and ymm2, add to ymm3/m256/m32bcst and put result in ymm1.",
    "Multiply packed single-precision floating-point values from ymm2 and ymm3/m256/m32bcst, add to ymm1 and put result in ymm1.",
    "Multiply packed single-precision floating-point values from zmm1 and zmm3/m512/m32bcst, add to zmm2 and put result in zmm1.",
    "Multiply packed single-precision floating-point values from zmm1 and zmm2, add to zmm3/m512/m32bcst and put result in zmm1.",
    "Multiply packed single-precision floating-point values from zmm2 and zmm3/m512/m32bcst, add to zmm1 and put result in zmm1.VFMADD132PS/VFMADD213PS/VFMADD231PSâ€”Fused Multiply-Add of Packed Single-Precision Floating-Point Values",
    "Multiply scalar double-precision floating-point value from xmm1 and xmm3/m64, add to xmm2 and put result in xmm1.",
    "Multiply scalar double-precision floating-point value from xmm1 and xmm2, add to xmm3/m64 and put result in xmm1.",
    "Multiply scalar double-precision floating-point value from xmm2 and xmm3/m64, add to xmm1 and put result in xmm1.",
    "Multiply scalar double-precision floating-point value from xmm1 and xmm3/m64, add to xmm2 and put result in xmm1.",
    "Multiply scalar double-precision floating-point value from xmm1 and xmm2, add to xmm3/m64 and put result in xmm1.",
    "Multiply scalar double-precision floating-point value from xmm2 and xmm3/m64, add to xmm1 and put result in xmm1.",
    "Multiply scalar single-precision floating-point value from xmm1 and xmm3/m32, add to xmm2 and put result in xmm1.",
    "Multiply scalar single-precision floating-point value from xmm1 and xmm2, add to xmm3/m32 and put result in xmm1.",
    "Multiply scalar single-precision floating-point value from xmm2 and xmm3/m32, add to xmm1 and put result in xmm1.",
    "Multiply scalar single-precision floating-point value from xmm1 and xmm3/m32, add to xmm2 and put result in xmm1.",
    "Multiply scalar single-precision floating-point value from xmm1 and xmm2, add to xmm3/m32 and put result in xmm1.",
    "Multiply scalar single-precision floating-point value from xmm2 and xmm3/m32, add to xmm1 and put result in xmm1.",
    "Multiply packed double-precision floating-point values from xmm1 and xmm3/mem,add/subtract elements in xmm2 and put result in xmm1.",
    "Multiply packed double-precision floating-point values from xmm1 and xmm2,add/subtract elements in xmm3/mem and put result in xmm1.",
    "Multiply packed double-precision floating-point values from xmm2 and xmm3/mem,add/subtract elements in xmm1 and put result in xmm1.",
    "Multiply packed double-precision floating-point values from ymm1 and ymm3/mem,add/subtract elements in ymm2 and put result in ymm1.",
    "Multiply packed double-precision floating-point values from ymm1 and ymm2,add/subtract elements in ymm3/mem and put result in ymm1.",
    "Multiply packed double-precision floating-point values from ymm2 and ymm3/mem,add/subtract elements in ymm1 and put result in ymm1.",
    "Multiply packed double-precision floating-point values from xmm1 and xmm2,add/subtract elements in xmm3/m128/m64bcst and put result in xmm1 subject to writemask k1.",
    "Multiply packed double-precision floating-point values from xmm2 and xmm3/m128/m64bcst,add/subtract elements in xmm1 and put result in xmm1 subject to writemask k1.",
    "Multiply packed double-precision floating-point values from xmm1 and xmm3/m128/m64bcst,add/subtract elements in xmm2 and put result in xmm1 subject to writemask k1.",
    "Multiply packed double-precision floating-point values from ymm1 and ymm2,add/subtract elements in ymm3/m256/m64bcst and put result in ymm1 subject to writemask k1.",
    "Multiply packed double-precision floating-point values from ymm2 and ymm3/m256/m64bcst,add/subtract elements in ymm1 and put result in ymm1 subject to writemask k1.",
    "Multiply packed double-precision floating-point values from ymm1 and ymm3/m256/m64bcst,add/subtract elements in ymm2 and put result in ymm1 subject to writemask k1.",
    "Multiply packed double-precision floating-point values from zmm1and zmm2,add/subtract elements in zmm3/m512/m64bcst and put result in zmm1 subject to writemask k1.",
    "Multiply packed double-precision floating-point values from zmm2 and zmm3/m512/m64bcst,add/subtract elements in zmm1 and put result in zmm1 subject to writemask k1.",
    "Multiply packed double-precision floating-point values from zmm1 and zmm3/m512/m64bcst,add/subtract elements in zmm2 and put result in zmm1 subject to writemask k1.",
    "Multiply packed single-precision floating-point values from xmm1 and xmm3/mem, add/subtract elements in xmm2 and put result in xmm1.",
    "Multiply packed single-precision floating-point values from xmm1 and xmm2, add/subtract elements in xmm3/mem and put result in xmm1.",
    "Multiply packed single-precision floating-point values from xmm2 and xmm3/mem, add/subtract elements in xmm1 and put result in xmm1.",
    "Multiply packed single-precision floating-point values from ymm1 and ymm3/mem, add/subtract elements in ymm2 and put result in ymm1.",
    "Multiply packed single-precision floating-point values from ymm1 and ymm2, add/subtract elements in ymm3/mem and put result in ymm1.",
    "Multiply packed single-precision floating-point values from ymm2 and ymm3/mem, add/subtract elements in ymm1 and put result in ymm1.",
    "Multiply packed single-precision floating-point values from xmm1 and xmm2, add/subtract elements in xmm3/m128/m32bcst and put result in xmm1 subject to writemask k1.",
    "Multiply packed single-precision floating-point values from xmm2 and xmm3/m128/m32bcst, add/subtract elements in xmm1 and put result in xmm1 subject to writemask k1.",
    "Multiply packed single-precision floating-point values from xmm1 and xmm3/m128/m32bcst, add/subtract elements in zmm2 and put result in xmm1 subject to writemask k1.",
    "Multiply packed single-precision floating-point values from ymm1 and ymm2, add/subtract elements in ymm3/m256/m32bcst and put result in ymm1 subject to writemask k1.",
    "Multiply packed single-precision floating-point values from ymm2 and ymm3/m256/m32bcst, add/subtract elements in ymm1 and put result in ymm1 subject to writemask k1.",
    "Multiply packed single-precision floating-point values from ymm1 and ymm3/m256/m32bcst, add/subtract elements in ymm2 and put result in ymm1 subject to writemask k1.",
    "Multiply packed single-precision floating-point values from zmm1 and zmm2, add/subtract elements in zmm3/m512/m32bcst and put result in zmm1 subject to writemask k1.",
    "Multiply packed single-precision floating-point values from zmm2 and zmm3/m512/m32bcst, add/subtract elements in zmm1 and put result in zmm1 subject to writemask k1.",
    "Multiply packed single-precision floating-point values from zmm1 and zmm3/m512/m32bcst, add/subtract elements in zmm2 and put result in zmm1 subject to writemask k1.VFMADDSUB132PS/VFMADDSUB213PS/VFMADDSUB231PSâ€”Fused Multiply-Alternating Add/Subtract of Packed Single-Precision",
    "Multiply packed double-precision floating-point values from xmm1 and xmm3/mem, subtract xmm2 and put result in xmm1.",
    "Multiply packed double-precision floating-point values from xmm1 and xmm2, subtract xmm3/mem and put result in xmm1.",
    "Multiply packed double-precision floating-point values from xmm2 and xmm3/mem, subtract xmm1 and put result in xmm1.",
    "Multiply packed double-precision floating-point values from ymm1 and ymm3/mem, subtract ymm2 and put result in ymm1.",
    "Multiply packed double-precision floating-point values from ymm1 and ymm2, subtract ymm3/mem and put result in ymm1.",
    "Multiply packed double-precision floating-point values from ymm2 and ymm3/mem, subtract ymm1 and put result in ymm1.S",
    "Multiply packed double-precision floating-point values from xmm1 and xmm3/m128/m64bcst, subtract xmm2 and put result in xmm1 subject to writemask k1.",
    "Multiply packed double-precision floating-point values from xmm1 and xmm2, subtract xmm3/m128/m64bcst and put result in xmm1 subject to writemask k1.",
    "Multiply packed double-precision floating-point values from xmm2 and xmm3/m128/m64bcst, subtract xmm1 and put result in xmm1 subject to writemask k1.",
    "Multiply packed double-precision floating-point values from ymm1 and ymm3/m256/m64bcst, subtract ymm2 and put result in ymm1 subject to writemask k1.",
    "Multiply packed double-precision floating-point values from ymm1 and ymm2, subtract ymm3/m256/m64bcst and put result in ymm1 subject to writemask k1.",
    "Multiply packed double-precision floating-point values from ymm2 and ymm3/m256/m64bcst, subtract ymm1 and put result in ymm1 subject to writemask k1.",
    "Multiply packed double-precision floating-point values from zmm1 and zmm3/m512/m64bcst, subtract zmm2 and put result in zmm1 subject to writemask k1.",
    "Multiply packed double-precision floating-point values from zmm1 and zmm2, subtract zmm3/m512/m64bcst and put result in zmm1 subject to writemask k1.",
    "Multiply packed double-precision floating-point values from zmm2 and zmm3/m512/m64bcst, subtract zmm1 and put result in zmm1 subject to writemask k1.VFMSUB132PD/VFMSUB213PD/VFMSUB231PDâ€”Fused Multiply-Subtract of Packed Double-Precision Floating-Point Values",
    "Multiply packed single-precision floating-point values from xmm1 and xmm3/mem, subtract xmm2 and put result in xmm1.",
    "Multiply packed single-precision floating-point values from xmm1 and xmm2, subtract xmm3/mem and put result in xmm1.",
    "Multiply packed single-precision floating-point values from xmm2 and xmm3/mem, subtract xmm1 and put result in xmm1.",
    "Multiply packed single-precision floating-point values from ymm1 and ymm3/mem, subtract ymm2 and put result in ymm1.",
    "Multiply packed single-precision floating-point values from ymm1 and ymm2, subtract ymm3/mem and put result in ymm1.",
    "Multiply packed single-precision floating-point values from ymm2 and ymm3/mem, subtract ymm1 and put result in ymm1.",
    "Multiply packed single-precision floating-point values from xmm1 and xmm3/m128/m32bcst, subtract xmm2 and put result in xmm1.",
    "Multiply packed single-precision floating-point values from xmm1 and xmm2, subtract xmm3/m128/m32bcst and put result in xmm1.",
    "Multiply packed single-precision floating-point values from xmm2 and xmm3/m128/m32bcst, subtract xmm1 and put result in xmm1.",
    "Multiply packed single-precision floating-point values from ymm1 and ymm3/m256/m32bcst, subtract ymm2 and put result in ymm1.",
    "Multiply packed single-precision floating-point values from ymm1 and ymm2, subtract ymm3/m256/m32bcst and put result in ymm1.",
    "Multiply packed single-precision floating-point values from ymm2 and ymm3/m256/m32bcst, subtract ymm1 and put result in ymm1.",
    "Multiply packed single-precision floating-point values from zmm1 and zmm3/m512/m32bcst, subtract zmm2 and put result in zmm1.",
    "Multiply packed single-precision floating-point values from zmm1 and zmm2, subtract zmm3/m512/m32bcst and put result in zmm1.",
    "Multiply packed single-precision floating-point values from zmm2 and zmm3/m512/m32bcst, subtract zmm1 and put result in zmm1.VFMSUB132PS/VFMSUB213PS/VFMSUB231PSâ€”Fused Multiply-Subtract of Packed Single-Precision Floating-Point Values",
    "Multiply scalar double-precision floating-point value from xmm1 and xmm3/m64, subtract xmm2 and put result in xmm1.",
    "Multiply scalar double-precision floating-point value from xmm1 and xmm2, subtract xmm3/m64 and put result in xmm1.",
    "Multiply scalar double-precision floating-point value from xmm2 and xmm3/m64, subtract xmm1 and put result in xmm1.",
    "Multiply scalar double-precision floating-point value from xmm1 and xmm3/m64, subtract xmm2 and put result in xmm1.",
    "Multiply scalar double-precision floating-point value from xmm1 and xmm2, subtract xmm3/m64 and put result in xmm1.",
    "Multiply scalar double-precision floating-point value from xmm2 and xmm3/m64, subtract xmm1 and put result in xmm1.",
    "Multiply scalar single-precision floating-point value from xmm1 and xmm3/m32, subtract xmm2 and put result in xmm1.",
    "Multiply scalar single-precision floating-point value from xmm1 and xmm2, subtract xmm3/m32 and put result in xmm1.",
    "Multiply scalar single-precision floating-point value from xmm2 and xmm3/m32, subtract xmm1 and put result in xmm1.",
    "Multiply scalar single-precision floating-point value from xmm1 and xmm3/m32, subtract xmm2 and put result in xmm1.",
    "Multiply scalar single-precision floating-point value from xmm1 and xmm2, subtract xmm3/m32 and put result in xmm1.",
    "Multiply scalar single-precision floating-point value from xmm2 and xmm3/m32, subtract xmm1 and put result in xmm1.",
    "Multiply packed double-precision floating-point values from xmm1 and xmm3/mem,subtract/add elements in xmm2 and put result in xmm1.",
    "Multiply packed double-precision floating-point values from xmm1 and xmm2,subtract/add elements in xmm3/mem and put result in xmm1.",
    "Multiply packed double-precision floating-point values from xmm2 and xmm3/mem,subtract/add elements in xmm1 and put result in xmm1.",
    "Multiply packed double-precision floating-point values from ymm1 and ymm3/mem,subtract/add elements in ymm2 and put result in ymm1.",
    "Multiply packed double-precision floating-point values from ymm1 and ymm2,subtract/add elements in ymm3/mem and put result in ymm1.",
    "Multiply packed double-precision floating-point values from ymm2 and ymm3/mem,subtract/add elements in ymm1 and put result in ymm1.",
    "Multiply packed double-precision floating-point values from xmm1 and xmm3/m128/m64bcst,subtract/add elements in xmm2 and put result in xmm1 subject to writemask k1.",
    "Multiply packed double-precision floating-point values from xmm1 and xmm2,subtract/add elements in xmm3/m128/m64bcst and put result in xmm1 subject to writemask k1.",
    "Multiply packed double-precision floating-point values from xmm2 and xmm3/m128/m64bcst,subtract/add elements in xmm1 and put result in xmm1 subject to writemask k1.",
    "Multiply packed double-precision floating-point values from ymm1 and ymm3/m256/m64bcst,subtract/add elements in ymm2 and put result in ymm1 subject to writemask k1.",
    "Multiply packed double-precision floating-point values from ymm1 and ymm2,subtract/add elements in ymm3/m256/m64bcst and put result in ymm1 subject to writemask k1.",
    "Multiply packed double-precision floating-point values from ymm2 and ymm3/m256/m64bcst,subtract/add elements in ymm1 and put result in ymm1 subject to writemask k1.",
    "Multiply packed double-precision floating-point values from zmm1 and zmm3/m512/m64bcst,subtract/add elements in zmm2 and put result in zmm1 subject to writemask k1.",
    "Multiply packed double-precision floating-point values from zmm1 and zmm2,subtract/add elements in zmm3/m512/m64bcst and put result in zmm1 subject to writemask k1.",
    "Multiply packed double-precision floating-point values from zmm2 and zmm3/m512/m64bcst,subtract/add elements in zmm1 and put result in zmm1 subject to writemask k1.",
    "Multiply packed single-precision floating-point values from xmm1 and xmm3/mem, subtract/add elements in xmm2 and put result in xmm1.",
    "Multiply packed single-precision floating-point values from xmm1 and xmm2, subtract/add elements in xmm3/mem and put result in xmm1.",
    "Multiply packed single-precision floating-point values from xmm2 and xmm3/mem, subtract/add elements in xmm1 and put result in xmm1.",
    "Multiply packed single-precision floating-point values from ymm1 and ymm3/mem, subtract/add elements in ymm2 and put result in ymm1.",
    "Multiply packed single-precision floating-point values from ymm1 and ymm2, subtract/add elements in ymm3/mem and put result in ymm1.",
    "Multiply packed single-precision floating-point values from ymm2 and ymm3/mem, subtract/add elements in ymm1 and put result in ymm1.",
    "Multiply packed single-precision floating-point values from xmm1 and xmm3/m128/m32bcst, subtract/add elements in xmm2 and put result in xmm1 subject to writemask k1.",
    "Multiply packed single-precision floating-point values from xmm1 and xmm2, subtract/add elements in xmm3/m128/m32bcst and put result in xmm1 subject to writemask k1.",
    "Multiply packed single-precision floating-point values from xmm2 and xmm3/m128/m32bcst, subtract/add elements in xmm1 and put result in xmm1 subject to writemask k1.",
    "Multiply packed single-precision floating-point values from ymm1 and ymm3/m256/m32bcst, subtract/add elements in ymm2 and put result in ymm1 subject to writemask k1.",
    "Multiply packed single-precision floating-point values from ymm1 and ymm2, subtract/add elements in ymm3/m256/m32bcst and put result in ymm1 subject to writemask k1.",
    "Multiply packed single-precision floating-point values from ymm2 and ymm3/m256/m32bcst, subtract/add elements in ymm1 and put result in ymm1 subject to writemask k1.",
    "Multiply packed single-precision floating-point values from zmm1 and zmm3/m512/m32bcst, subtract/add elements in zmm2 and put result in zmm1 subject to writemask k1.",
    "Multiply packed single-precision floating-point values from zmm1 and zmm2, subtract/add elements in zmm3/m512/m32bcst and put result in zmm1 subject to writemask k1.",
    "Multiply packed single-precision floating-point values from zmm2 and zmm3/m512/m32bcst, subtract/add elements in zmm1 and put result in zmm1 subject to writemask k1.VFMSUBADD132PS/VFMSUBADD213PS/VFMSUBADD231PSâ€”Fused Multiply-Alternating Subtract/Add of Packed Single-Precision",
    "Multiply packed double-precision floating-point values from xmm1 and xmm3/mem, negate the multiplication result and add to xmm2 and put result in xmm1.",
    "Multiply packed double-precision floating-point values from xmm1 and xmm2, negate the multiplication result and add to xmm3/mem and put result in xmm1.",
    "Multiply packed double-precision floating-point values from xmm2 and xmm3/mem, negate the multiplication result and add to xmm1 and put result in xmm1.",
    "Multiply packed double-precision floating-point values from ymm1 and ymm3/mem, negate the multiplication result and add to ymm2 and put result in ymm1.",
    "Multiply packed double-precision floating-point values from ymm1 and ymm2, negate the multiplication result and add to ymm3/mem and put result in ymm1.",
    "Multiply packed double-precision floating-point values from ymm2 and ymm3/mem, negate the multiplication result and add to ymm1 and put result in ymm1.",
    "Multiply packed double-precision floating-point values from xmm1 and xmm3/m128/m64bcst, negate the multiplication result and add to xmm2 and put result in xmm1.",
    "Multiply packed double-precision floating-point values from xmm1 and xmm2, negate the multiplication result and add to xmm3/m128/m64bcst and put result in xmm1.",
    "Multiply packed double-precision floating-point values from xmm2 and xmm3/m128/m64bcst, negate the multiplication result and add to xmm1 and put result in xmm1.",
    "Multiply packed double-precision floating-point values from ymm1 and ymm3/m256/m64bcst, negate the multiplication result and add to ymm2 and put result in ymm1.",
    "Multiply packed double-precision floating-point values from ymm1 and ymm2, negate the multiplication result and add to ymm3/m256/m64bcst and put result in ymm1.",
    "Multiply packed double-precision floating-point values from ymm2 and ymm3/m256/m64bcst, negate the multiplication result and add to ymm1 and put result in ymm1.",
    "Multiply packed double-precision floating-point values from zmm1 and zmm3/m512/m64bcst, negate the multiplication result and add to zmm2 and put result in zmm1.",
    "Multiply packed double-precision floating-point values from zmm1 and zmm2, negate the multiplication result and add to zmm3/m512/m64bcst and put result in zmm1.",
    "Multiply packed double-precision floating-point values from zmm2 and zmm3/m512/m64bcst, negate the multiplication result and add to zmm1 and put result in zmm1.VFNMADD132PD/VFNMADD213PD/VFNMADD231PDâ€”Fused Negative Multiply-Add of Packed Double-Precision Floating-Point Values",
    "Multiply packed single-precision floating-point values from xmm1 and xmm3/mem, negate the multiplication result and add to xmm2 and put result in xmm1.",
    "Multiply packed single-precision floating-point values from xmm1 and xmm2, negate the multiplication result and add to xmm3/mem and put result in xmm1.",
    "Multiply packed single-precision floating-point values from xmm2 and xmm3/mem, negate the multiplication result and add to xmm1 and put result in xmm1.",
    "Multiply packed single-precision floating-point values from ymm1 and ymm3/mem, negate the multiplication result and add to ymm2 and put result in ymm1.",
    "Multiply packed single-precision floating-point values from ymm1 and ymm2, negate the multiplication result and add to ymm3/mem and put result in ymm1.",
    "Multiply packed single-precision floating-point values from ymm2 and ymm3/mem, negate the multiplication result and add to ymm1 and put result in ymm1.",
    "Multiply packed single-precision floating-point values from xmm1 and xmm3/m128/m32bcst, negate the multiplication result and add to xmm2 and put result in xmm1.",
    "Multiply packed single-precision floating-point values from xmm1 and xmm2, negate the multiplication result and add to xmm3/m128/m32bcst and put result in xmm1.",
    "Multiply packed single-precision floating-point values from xmm2 and xmm3/m128/m32bcst, negate the multiplication result and add to xmm1 and put result in xmm1.",
    "Multiply packed single-precision floating-point values from ymm1 and ymm3/m256/m32bcst, negate the multiplication result and add to ymm2 and put result in ymm1.",
    "Multiply packed single-precision floating-point values from ymm1 and ymm2, negate the multiplication result and add to ymm3/m256/m32bcst and put result in ymm1.",
    "Multiply packed single-precision floating-point values from ymm2 and ymm3/m256/m32bcst, negate the multiplication result and add to ymm1 and put result in ymm1.",
    "Multiply packed single-precision floating-point values from zmm1 and zmm3/m512/m32bcst, negate the multiplication result and add to zmm2 and put result in zmm1.",
    "Multiply packed single-precision floating-point values from zmm1 and zmm2, negate the multiplication result and add to zmm3/m512/m32bcst and put result in zmm1.",
    "Multiply packed single-precision floating-point values from zmm2 and zmm3/m512/m32bcst, negate the multiplication result and add to zmm1 and put result in zmm1.VFNMADD132PS/VFNMADD213PS/VFNMADD231PSâ€”Fused Negative Multiply-Add of Packed Single-Precision Floating-Point Values",
    "Multiply scalar double-precision floating-point value from xmm1 and xmm3/mem, negate the multiplication result and add to xmm2 and put result in xmm1.",
    "Multiply scalar double-precision floating-point value from xmm1 and xmm2, negate the multiplication result and add to xmm3/mem and put result in xmm1.",
    "Multiply scalar double-precision floating-point value from xmm2 and xmm3/mem, negate the multiplication result and add to xmm1 and put result in xmm1.",
    "Multiply scalar double-precision floating-point value from xmm1 and xmm3/m64, negate the multiplication result and add to xmm2 and put result in xmm1.",
    "Multiply scalar double-precision floating-point value from xmm1 and xmm2, negate the multiplication result and add to xmm3/m64 and put result in xmm1.",
    "Multiply scalar double-precision floating-point value from xmm2 and xmm3/m64, negate the multiplication result and add to xmm1 and put result in xmm1.",
    "Multiply scalar single-precision floating-point value from xmm1 and xmm3/m32, negate the multiplication result and add to xmm2 and put result in xmm1.",
    "Multiply scalar single-precision floating-point value from xmm1 and xmm2, negate the multiplication result and add to xmm3/m32 and put result in xmm1.",
    "Multiply scalar single-precision floating-point value from xmm2 and xmm3/m32, negate the multiplication result and add to xmm1 and put result in xmm1.",
    "Multiply scalar single-precision floating-point value from xmm1 and xmm3/m32, negate the multiplication result and add to xmm2 and put result in xmm1.",
    "Multiply scalar single-precision floating-point value from xmm1 and xmm2, negate the multiplication result and add to xmm3/m32 and put result in xmm1.",
    "Multiply scalar single-precision floating-point value from xmm2 and xmm3/m32, negate the multiplication result and add to xmm1 and put result in xmm1.",
    "Multiply packed double-precision floating-point values from xmm1 and xmm3/mem, negate the multiplication result and subtract xmm2 and put result in xmm1.",
    "Multiply packed double-precision floating-point values from xmm1 and xmm2, negate the multiplication result and subtract xmm3/mem and put result in xmm1.",
    "Multiply packed double-precision floating-point values from xmm2 and xmm3/mem, negate the multiplication result and subtract xmm1 and put result in xmm1.",
    "Multiply packed double-precision floating-point values from ymm1 and ymm3/mem, negate the multiplication result and subtract ymm2 and put result in ymm1.",
    "Multiply packed double-precision floating-point values from ymm1 and ymm2, negate the multiplication result and subtract ymm3/mem and put result in ymm1.",
    "Multiply packed double-precision floating-point values from ymm2 and ymm3/mem, negate the multiplication result and subtract ymm1 and put result in ymm1.",
    "Multiply packed double-precision floating-point values from xmm1 and xmm3/m128/m64bcst, negate the multiplication result and subtract xmm2 and put result in xmm1.",
    "Multiply packed double-precision floating-point values from xmm1 and xmm2, negate the multiplication result and subtract xmm3/m128/m64bcst and put result in xmm1.",
    "Multiply packed double-precision floating-point values from xmm2 and xmm3/m128/m64bcst, negate the multiplication result and subtract xmm1 and put result in xmm1.",
    "Multiply packed double-precision floating-point values from ymm1 and ymm3/m256/m64bcst, negate the multiplication result and subtract ymm2 and put result in ymm1.",
    "Multiply packed double-precision floating-point values from ymm1 and ymm2, negate the multiplication result and subtract ymm3/m256/m64bcst and put result in ymm1.",
    "Multiply packed double-precision floating-point values from ymm2 and ymm3/m256/m64bcst, negate the multiplication result and subtract ymm1 and put result in ymm1.",
    "Multiply packed double-precision floating-point values from zmm1 and zmm3/m512/m64bcst, negate the multiplication result and subtract zmm2 and put result in zmm1.",
    "Multiply packed double-precision floating-point values from zmm1 and zmm2, negate the multiplication result and subtract zmm3/m512/m64bcst and put result in zmm1.",
    "Multiply packed double-precision floating-point values from zmm2 and zmm3/m512/m64bcst, negate the multiplication result and subtract zmm1 and put result in zmm1.VFNMSUB132PD/VFNMSUB213PD/VFNMSUB231PDâ€”Fused Negative Multiply-Subtract of Packed Double-Precision Floating-Point",
    "Multiply packed single-precision floating-point values from xmm1 and xmm3/mem, negate the multiplication result and subtract xmm2 and put result in xmm1.",
    "Multiply packed single-precision floating-point values from xmm1 and xmm2, negate the multiplication result and subtract xmm3/mem and put result in xmm1.",
    "Multiply packed single-precision floating-point values from xmm2 and xmm3/mem, negate the multiplication result and subtract xmm1 and put result in xmm1.",
    "Multiply packed single-precision floating-point values from ymm1 and ymm3/mem, negate the multiplication result and subtract ymm2 and put result in ymm1.",
    "Multiply packed single-precision floating-point values from ymm1 and ymm2, negate the multiplication result and subtract ymm3/mem and put result in ymm1.",
    "Multiply packed single-precision floating-point values from ymm2 and ymm3/mem, negate the multiplication result and subtract ymm1 and put result in ymm1.",
    "Multiply packed single-precision floating-point values from xmm1 and xmm3/m128/m32bcst, negate the multiplication result and subtract xmm2 and put result in xmm1.",
    "Multiply packed single-precision floating-point values from xmm1 and xmm2, negate the multiplication result and subtract xmm3/m128/m32bcst and put result in xmm1.",
    "Multiply packed single-precision floating-point values from xmm2 and xmm3/m128/m32bcst, negate the multiplication result subtract add to xmm1 and put result in xmm1.",
    "Multiply packed single-precision floating-point values from ymm1 and ymm3/m256/m32bcst, negate the multiplication result and subtract ymm2 and put result in ymm1.",
    "Multiply packed single-precision floating-point values from ymm1 and ymm2, negate the multiplication result and subtract ymm3/m256/m32bcst and put result in ymm1.",
    "Multiply packed single-precision floating-point values from ymm2 and ymm3/m256/m32bcst, negate the multiplication result subtract add to ymm1 and put result in ymm1.",
    "Multiply packed single-precision floating-point values from zmm1 and zmm3/m512/m32bcst, negate the multiplication result and subtract zmm2 and put result in zmm1.",
    "Multiply packed single-precision floating-point values from zmm1 and zmm2, negate the multiplication result and subtract zmm3/m512/m32bcst and put result in zmm1.",
    "Multiply packed single-precision floating-point values from zmm2 and zmm3/m512/m32bcst, negate the multiplication result subtract add to zmm1 and put result in zmm1.VFNMSUB132PS/VFNMSUB213PS/VFNMSUB231PSâ€”Fused Negative Multiply-Subtract of Packed Single-Precision Floating-Point Val-",
    "Multiply scalar double-precision floating-point value from xmm1 and xmm3/mem, negate the multiplication result and subtract xmm2 and put result in xmm1.",
    "Multiply scalar double-precision floating-point value from xmm1 and xmm2, negate the multiplication result and subtract xmm3/mem and put result in xmm1.",
    "Multiply scalar double-precision floating-point value from xmm2 and xmm3/mem, negate the multiplication result and subtract xmm1 and put result in xmm1.",
    "Multiply scalar double-precision floating-point value from xmm1 and xmm3/m64, negate the multiplication result and subtract xmm2 and put result in xmm1.",
    "Multiply scalar double-precision floating-point value from xmm1 and xmm2, negate the multiplication result and subtract xmm3/m64 and put result in xmm1.",
    "Multiply scalar double-precision floating-point value from xmm2 and xmm3/m64, negate the multiplication result and subtract xmm1 and put result in xmm1.",
    "Multiply scalar single-precision floating-point value from xmm1 and xmm3/m32, negate the multiplication result and subtract xmm2 and put result in xmm1.",
    "Multiply scalar single-precision floating-point value from xmm1 and xmm2, negate the multiplication result and subtract xmm3/m32 and put result in xmm1.",
    "Multiply scalar single-precision floating-point value from xmm2 and xmm3/m32, negate the multiplication result and subtract xmm1 and put result in xmm1.",
    "Multiply scalar single-precision floating-point value from xmm1 and xmm3/m32, negate the multiplication result and subtract xmm2 and put result in xmm1.",
    "Multiply scalar single-precision floating-point value from xmm1 and xmm2, negate the multiplication result and subtract xmm3/m32 and put result in xmm1.",
    "Multiply scalar single-precision floating-point value from xmm2 and xmm3/m32, negate the multiplication result and subtract xmm1 and put result in xmm1.",
    "Tests the input for the following categories: NaN, +0, -0, +Infinity, -Infinity, denormal, finite negative. The immediate field provides a mask bit for each of these category tests. The masked test results are OR-ed together to form a mask result.",
    "Tests the input for the following categories: NaN, +0, -0, +Infinity, -Infinity, denormal, finite negative. The immediate field provides a mask bit for each of these category tests. The masked test results are OR-ed together to form a mask result.",
    "Tests the input for the following categories: NaN, +0, -0, +Infinity, -Infinity, denormal, finite negative. The immediate field provides a mask bit for each of these category tests. The masked test results are OR-ed together to form a mask result.",
    "Tests the input for the following categories: NaN, +0, -0, +Infinity, -Infinity, denormal, finite negative. The immediate field provides a mask bit for each of these category tests. The masked test results are OR-ed together to form a mask result.",
    "Tests the input for the following categories: NaN, +0, -0, +Infinity, -Infinity, denormal, finite negative. The immediate field provides a mask bit for each of these category tests. The masked test results are OR-ed together to form a mask result.",
    "Tests the input for the following categories: NaN, +0, -0, +Infinity, -Infinity, denormal, finite negative. The immediate field provides a mask bit for each of these category tests. The masked test results are OR-ed together to form a mask result.",
    "Tests the input for the following categories: NaN, +0, -0, +Infinity, -Infinity, denormal, finite negative. The immediate field provides a mask bit for each of these category tests. The masked test results are OR-ed together to form a mask result.",
    "Tests the input for the following categories: NaN, +0, -0, +Infinity, -Infinity, denormal, finite negative. The immediate field provides a mask bit for each of these category tests. The masked test results are OR-ed together to form a mask result.",
    "Using dword indices specified in vm32x, gather double-pre-cision FP values from memory conditioned on mask speci-fied by xmm2. Conditionally gathered elements are merged into xmm1.",
    "Using qword indices specified in vm64x, gather double-pre-cision FP values from memory conditioned on mask speci-fied by xmm2. Conditionally gathered elements are merged into xmm1.",
    "Using dword indices specified in vm32x, gather double-pre-cision FP values from memory conditioned on mask speci-fied by ymm2. Conditionally gathered elements are merged into ymm1.",
    "Using qword indices specified in vm64y, gather double-pre-cision FP values from memory conditioned on mask speci-fied by ymm2. Conditionally gathered elements are merged into ymm1.",
    "Using signed dword indices, gather single-precision floating-point values from memory using k1 as completion mask.",
    "Using signed dword indices, gather single-precision floating-point values from memory using k1 as completion mask.",
    "Using signed dword indices, gather single-precision floating-point values from memory using k1 as completion mask.",
    "Using signed dword indices, gather float64 vector into float64 vector xmm1 using k1 as completion mask.",
    "Using signed dword indices, gather float64 vector into float64 vector ymm1 using k1 as completion mask.",
    "Using signed dword indices, gather float64 vector into float64 vector zmm1 using k1 as completion mask.",
    "Using dword indices specified in vm32x, gather single-preci-sion FP values from memory conditioned on mask specified by xmm2. Conditionally gathered elements are merged into xmm1.",
    "Using qword indices specified in vm64x, gather single-preci-sion FP values from memory conditioned on mask specified by xmm2. Conditionally gathered elements are merged into xmm1.",
    "Using dword indices specified in vm32y, gather single-preci-sion FP values from memory conditioned on mask specified by ymm2. Conditionally gathered elements are merged into ymm1.",
    "Using qword indices specified in vm64y, gather single-preci-sion FP values from memory conditioned on mask specified by xmm2. Conditionally gathered elements are merged into xmm1.",
    "Using signed dword indices, prefetch sparse byte memory locations containing single-precision data using opmask k1 and T0 hint.",
    "Using signed qword indices, prefetch sparse byte memory locations containing single-precision data using opmask k1 and T0 hint.",
    "Using signed dword indices, prefetch sparse byte memory locations containing double-precision data using opmask k1 and T0 hint.",
    "Using signed qword indices, prefetch sparse byte memory locations containing double-precision data using opmask k1 and T0 hint.",
    "Using signed dword indices, prefetch sparse byte memory locations containing single-precision data using opmask k1 and T1 hint.",
    "Using signed qword indices, prefetch sparse byte memory locations containing single-precision data using opmask k1 and T1 hint.",
    "Using signed dword indices, prefetch sparse byte memory locations containing double-precision data using opmask k1 and T1 hint.",
    "Using signed qword indices, prefetch sparse byte memory locations containing double-precision data using opmask k1 and T1 hint.",
    "Using signed qword indices, gather single-precision floating-point values from memory using k1 as completion mask.",
    "Using signed qword indices, gather single-precision floating-point values from memory using k1 as completion mask.",
    "Using signed qword indices, gather single-precision floating-point values from memory using k1 as completion mask.",
    "Using signed qword indices, gather float64 vector into float64 vector xmm1 using k1 as completion mask.",
    "Using signed qword indices, gather float64 vector into float64 vector ymm1 using k1 as completion mask.",
    "Using signed qword indices, gather float64 vector into float64 vector zmm1 using k1 as completion mask.",
    "Convert the exponent of packed double-precision floating-point values in the source operand to DP FP results representing unbiased integer exponents and stores the results in the destination register.",
    "Convert the exponent of packed double-precision floating-point values in the source operand to DP FP results representing unbiased integer exponents and stores the results in the destination register.",
    "Convert the exponent of packed double-precision floating-point values in the source operand to DP FP results representing unbiased integer exponents and stores the results in the destination under writemask k1.",
    "Convert the exponent of packed single-precision floating-point values in the source operand to SP FP results representing unbiased integer exponents and stores the results in the destination register.",
    "Convert the exponent of packed single-precision floating-point values in the source operand to SP FP results representing unbiased integer exponents and stores the results in the destination register.",
    "Convert the exponent of packed single-precision floating-point values in the source operand to SP FP results representing unbiased integer exponents and stores the results in the destination register.",
    "Convert the biased exponent (bits 62:52) of the low double-precision floating-point value in xmm3/m64 to a DP FP value representing unbiased integer exponent. Stores the result to the low 64-bit of xmm1 under the writemask k1 and merge with the other elements of xmm2.",
    "Convert the biased exponent (bits 30:23) of the low single-precision floating-point value in xmm3/m32 to a SP FP value representing unbiased integer exponent. Stores the result to xmm1 under the writemask k1 and merge with the other elements of xmm2.",
    "Get Normalized Mantissa from float64 vector xmm2/m128/m64bcst and store the result in xmm1, using imm8 for sign control and mantissa interval normalization, under writemask.",
    "Get Normalized Mantissa from float64 vector ymm2/m256/m64bcst and store the result in ymm1, using imm8 for sign control and mantissa interval normalization, under writemask.",
    "Get Normalized Mantissa from float64 vector zmm2/m512/m64bcst and store the result in zmm1, using imm8 for sign control and mantissa interval normalization, under writemask.",
    "Get normalized mantissa from float32 vector xmm2/m128/m32bcst and store the result in xmm1, using imm8 for sign control and mantissa interval normalization, under writemask.",
    "Get normalized mantissa from float32 vector ymm2/m256/m32bcst and store the result in ymm1, using imm8 for sign control and mantissa interval normalization, under writemask.",
    "Get normalized mantissa from float32 vector zmm2/m512/m32bcst and store the result in zmm1, using imm8 for sign control and mantissa interval normalization, under writemask.",
    "Extract the normalized mantissa of the low float64 element in xmm3/m64 using imm8 for sign control and mantissa interval normalization. Store the mantissa to xmm1 under the writemask k1 and merge with the other elements of xmm2.",
    "Extract the normalized mantissa from the low float32 element of xmm3/m32 using imm8 for sign control and mantissa interval normalization, store the mantissa to xmm1 under the writemask k1 and merge with the other elements of xmm2.",
    "Insert 128 bits of packed floating-point values from xmm3/m128 and the remaining values from ymm2 into ymm1. EVEX.NDS.256.66.0F3A.W0 18 /r ib VINSERTF32X4 ymm1 {k1}{z}, ymm2, xmm3/m128, imm8 C V/V AVX512VL AVX512F Insert 128 bits of packed single-precision floating-point values from xmm3/m128 and the remaining values from ymm2 into ymm1 under writemask k1. EVEX.NDS.512.66.0F3A.W0 18 /r ib VINSERTF32X4 zmm1 {k1}{z}, zmm2, xmm3/m128, imm8 C V/V AVX512F Insert 128 bits of packed single-precision floating-point values from xmm3/m128 and the remaining values from zmm2 into zmm1 under writemask k1. EVEX.NDS.256.66.0F3A.W1 18 /r ib VINSERTF64X2 ymm1 {k1}{z}, ymm2, xmm3/m128, imm8 B V/V AVX512VL AVX512DQ Insert 128 bits of packed double-precision floating-point values from xmm3/m128 and the remaining values from ymm2 into ymm1 under writemask k1. EVEX.NDS.512.66.0F3A.W1 18 /r ib VINSERTF64X2 zmm1 {k1}{z}, zmm2, xmm3/m128, imm8 B V/V AVX512DQ Insert 128 bits of packed double-precision floating-point values from xmm3/m128 and the remaining values from zmm2 into zmm1 under writemask k1. EVEX.NDS.512.66.0F3A.W0 1A /r ib VINSERTF32X8 zmm1 {k1}{z}, zmm2, ymm3/m256, imm8 D V/V AVX512DQ Insert 256 bits of packed single-precision floating-point values from ymm3/m256 and the remaining values from zmm2 into zmm1 under writemask k1. EVEX.NDS.512.66.0F3A.W1 1A /r ib VINSERTF64X4 zmm1 {k1}{z}, zmm2, ymm3/m256, imm8 C V/V AVX512F Insert 256 bits of packed double-precision floating-point values from ymm3/m256 and the remaining values from zmm2 into zmm1 under writemask k1.",
    "Insert 128 bits of integer data from xmm3/m128 and the remaining values from ymm2 into ymm1. EVEX.NDS.256.66.0F3A.W0 38 /r ib VINSERTI32X4 ymm1 {k1}{z}, ymm2, xmm3/m128, imm8 C V/V AVX512VL AVX512F Insert 128 bits of packed doubleword integer values from xmm3/m128 and the remaining values from ymm2 into ymm1 under writemask k1. EVEX.NDS.512.66.0F3A.W0 38 /r ib VINSERTI32X4 zmm1 {k1}{z}, zmm2, xmm3/m128, imm8 C V/V AVX512F Insert 128 bits of packed doubleword integer values from xmm3/m128 and the remaining values from zmm2 into zmm1 under writemask k1. EVEX.NDS.256.66.0F3A.W1 38 /r ib VINSERTI64X2 ymm1 {k1}{z}, ymm2, xmm3/m128, imm8 B V/V AVX512VL AVX512DQ Insert 128 bits of packed quadword integer values from xmm3/m128 and the remaining values from ymm2 into ymm1 under writemask k1. EVEX.NDS.512.66.0F3A.W1 38 /r ib VINSERTI64X2 zmm1 {k1}{z}, zmm2, xmm3/m128, imm8 B V/V AVX512DQ Insert 128 bits of packed quadword integer values from xmm3/m128 and the remaining values from zmm2 into zmm1 under writemask k1. EVEX.NDS.512.66.0F3A.W0 3A /r ib VINSERTI32X8 zmm1 {k1}{z}, zmm2, ymm3/m256, imm8 D V/V AVX512DQ Insert 256 bits of packed doubleword integer values from ymm3/m256 and the remaining values from zmm2 into zmm1 under writemask k1. EVEX.NDS.512.66.0F3A.W1 3A /r ib VINSERTI64X4 zmm1 {k1}{z}, zmm2, ymm3/m256, imm8 C V/V AVX512F Insert 256 bits of packed quadword integer values from ymm3/m256 and the remaining values from zmm2 into zmm1 under writemask k1.",
    "Conditionally load packed single-precision values from m128 using mask in xmm2 and store in xmm1.",
    "Conditionally load packed single-precision values from m256 using mask in ymm2 and store in ymm1.",
    "Conditionally load packed double-precision values from m128 using mask in xmm2 and store in xmm1.",
    "Conditionally load packed double-precision values from m256 using mask in ymm2 and store in ymm1.",
    "Conditionally store packed single-precision values from xmm2 using mask in xmm1.",
    "Conditionally store packed single-precision values from ymm2 using mask in ymm1.",
    "Conditionally store packed double-precision values from xmm2 using mask in xmm1.",
    "Conditionally store packed double-precision values from ymm2 using mask in ymm1.",
    "Select dwords from xmm2 and xmm3/m128 from mask specified in imm8 and store the values into xmm1.",
    "Select dwords from ymm2 and ymm3/m256 from mask specified in imm8 and store the values into ymm1.",
    "Blend byte integer vector xmm2 and byte vector xmm3/m128 and store the result in xmm1, under control mask.",
    "Blend byte integer vector ymm2 and byte vector ymm3/m256 and store the result in ymm1, under control mask.",
    "Blend byte integer vector zmm2 and byte vector zmm3/m512 and store the result in zmm1, under control mask.",
    "Blend word integer vector xmm2 and word vector xmm3/m128 and store the result in xmm1, under control mask.",
    "Blend word integer vector ymm2 and word vector ymm3/m256 and store the result in ymm1, under control mask.",
    "Blend word integer vector zmm2 and word vector zmm3/m512 and store the result in zmm1, under control mask.",
    "Blend doubleword integer vector xmm2 and doubleword vector xmm3/m128/m32bcst and store the result in xmm1, under control mask.",
    "Blend doubleword integer vector ymm2 and doubleword vector ymm3/m256/m32bcst and store the result in ymm1, under control mask.",
    "Blend doubleword integer vector zmm2 and doubleword vector zmm3/m512/m32bcst and store the result in zmm1, under control mask.",
    "Blend quadword integer vector xmm2 and quadword vector xmm3/m128/m64bcst and store the result in xmm1, under control mask.",
    "Blend quadword integer vector ymm2 and quadword vector ymm3/m256/m64bcst and store the result in ymm1, under control mask.",
    "Blend quadword integer vector zmm2 and quadword vector zmm3/m512/m64bcst and store the result in zmm1, under control mask.",
    "Broadcast a byte integer in the source operand to sixteen locations in xmm1.",
    "Broadcast a byte integer in the source operand to thirty-two locations in ymm1.",
    "Broadcast a byte integer in the source operand to locations in xmm1 subject to writemask k1.",
    "Broadcast a byte integer in the source operand to locations in ymm1 subject to writemask k1.",
    "Broadcast a byte integer in the source operand to 64 locations in zmm1 subject to writemask k1.",
    "Broadcast a word integer in the source operand to eight locations in xmm1.",
    "Broadcast a word integer in the source operand to sixteen locations in ymm1.",
    "Broadcast a word integer in the source operand to locations in xmm1 subject to writemask k1.",
    "Broadcast a word integer in the source operand to locations in ymm1 subject to writemask k1.",
    "Broadcast a word integer in the source operand to 32 locations in zmm1 subject to writemask k1.",
    "Broadcast a dword integer in the source operand to four locations in xmm1.",
    "Broadcast a dword integer in the source operand to eight locations in ymm1.",
    "Broadcast a dword integer in the source operand to locations in xmm1 subject to writemask k1.",
    "Broadcast a dword integer in the source operand to locations in ymm1 subject to writemask k1.",
    "Broadcast a dword integer in the source operand to locations in zmm1 subject to writemask k1.",
    "Broadcast a qword element in source operand to two locations in xmm1.",
    "Broadcast a qword element in source operand to four locations in ymm1.",
    "Broadcast a qword element in source operand to locations in xmm1 subject to writemask k1.",
    "Broadcast a qword element in source operand to locations in ymm1 subject to writemask k1.",
    "Broadcast a qword element in source operand to locations in zmm1 subject to writemask k1.",
    "Broadcast two dword elements in source operand to locations in xmm1 subject to writemask k1.",
    "Broadcast two dword elements in source operand to locations in ymm1 subject to writemask k1.",
    "Broadcast two dword elements in source operand to locations in zmm1 subject to writemask k1.",
    "Broadcast 128 bits of integer data in mem to low and high 128-bits in ymm1.",
    "Broadcast 128 bits of 4 doubleword integer data in mem to locations in ymm1 using writemask k1.",
    "Broadcast 128 bits of 4 doubleword integer data in mem to locations in zmm1 using writemask k1.",
    "Broadcast 128 bits of 2 quadword integer data in mem to locations in ymm1 using writemask k1.",
    "Broadcast 128 bits of 2 quadword integer data in mem to locations in zmm1 using writemask k1.",
    "Broadcast 256 bits of 8 doubleword integer data in mem to locations in zmm1 using writemask k1.",
    "Broadcast 256 bits of 4 quadword integer data in mem to locations in zmm1 using writemask k1.",
    "Broadcast an 8-bit value from a GPR to all bytes in the 128-bit destination subject to writemask k1.",
    "Broadcast an 8-bit value from a GPR to all bytes in the 256-bit destination subject to writemask k1.",
    "Broadcast an 8-bit value from a GPR to all bytes in the 512-bit destination subject to writemask k1.",
    "Broadcast a 16-bit value from a GPR to all words in the 128-bit destination subject to writemask k1.",
    "Broadcast a 16-bit value from a GPR to all words in the 256-bit destination subject to writemask k1.",
    "Broadcast a 16-bit value from a GPR to all words in the 512-bit destination subject to writemask k1.",
    "Broadcast a 32-bit value from a GPR to all double-words in the 128-bit destination subject to writemask k1.",
    "Broadcast a 32-bit value from a GPR to all double-words in the 256-bit destination subject to writemask k1.",
    "Broadcast a 32-bit value from a GPR to all double-words in the 512-bit destination subject to writemask k1.",
    "Broadcast a 64-bit value from a GPR to all quad-words in the 128-bit destination subject to writemask k1.",
    "Broadcast a 64-bit value from a GPR to all quad-words in the 256-bit destination subject to writemask k1.",
    "Broadcast a 64-bit value from a GPR to all quad-words in the 512-bit destination subject to writemask k1.",
    "Broadcast low byte value in k1 to two locations in xmm1.",
    "Broadcast low byte value in k1 to four locations in ymm1.",
    "Broadcast low byte value in k1 to eight locations in zmm1.",
    "Broadcast low word value in k1 to four locations in xmm1.",
    "Broadcast low word value in k1 to eight locations in ymm1.",
    "Broadcast low word value in k1 to sixteen locations in zmm1.",
    "Compare packed signed byte values in xmm3/m128 and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.",
    "Compare packed signed byte values in ymm3/m256 and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.",
    "Compare packed signed byte values in zmm3/m512 and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.",
    "Compare packed unsigned byte values in xmm3/m128 and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.",
    "Compare packed unsigned byte values in ymm3/m256 and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.",
    "Compare packed unsigned byte values in zmm3/m512 and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.",
    "Compare packed signed doubleword integer values in xmm3/m128/m32bcst and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.",
    "Compare packed signed doubleword integer values in ymm3/m256/m32bcst and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.",
    "Compare packed signed doubleword integer values in zmm2 and zmm3/m512/m32bcst using bits 2:0 of imm8 as a comparison predicate. The comparison results are written to the destination k1 under writemask k2.",
    "Compare packed unsigned doubleword integer values in xmm3/m128/m32bcst and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.",
    "Compare packed unsigned doubleword integer values in ymm3/m256/m32bcst and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.",
    "Compare packed unsigned doubleword integer values in zmm2 and zmm3/m512/m32bcst using bits 2:0 of imm8 as a comparison predicate. The comparison results are written to the destination k1 under writemask k2.",
    "Compare packed signed quadword integer values in xmm3/m128/m64bcst and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.",
    "Compare packed signed quadword integer values in ymm3/m256/m64bcst and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.",
    "Compare packed signed quadword integer values in zmm3/m512/m64bcst and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.",
    "Compare packed unsigned quadword integer values in xmm3/m128/m64bcst and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.",
    "Compare packed unsigned quadword integer values in ymm3/m256/m64bcst and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.",
    "Compare packed unsigned quadword integer values in zmm3/m512/m64bcst and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.",
    "Compare packed signed word integers in xmm3/m128 and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.",
    "Compare packed signed word integers in ymm3/m256 and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.",
    "Compare packed signed word integers in zmm3/m512 and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.",
    "Compare packed unsigned word integers in xmm3/m128 and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.",
    "Compare packed unsigned word integers in ymm3/m256 and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.",
    "Compare packed unsigned word integers in zmm3/m512 and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.",
    "Compress packed doubleword integer values from xmm2 to xmm1/m128 using controlmask k1.",
    "Compress packed doubleword integer values from ymm2 to ymm1/m256 using controlmask k1.",
    "Compress packed doubleword integer values from zmm2 to zmm1/m512 using controlmask k1.",
    "Compress packed quadword integer values from xmm2 to xmm1/m128 using controlmask k1.",
    "Compress packed quadword integer values from ymm2 to ymm1/m256 using controlmask k1.",
    "Compress packed quadword integer values from zmm2 to zmm1/m512 using controlmask k1.",
    "Detect duplicate double-word values in xmm2/m128/m32bcst using writemask k1.",
    "Detect duplicate double-word values in ymm2/m256/m32bcst using writemask k1.",
    "Detect duplicate double-word values in zmm2/m512/m32bcst using writemask k1.",
    "Detect duplicate quad-word values in xmm2/m128/m64bcst using writemask k1.",
    "Detect duplicate quad-word values in ymm2/m256/m64bcst using writemask k1.",
    "Detect duplicate quad-word values in zmm2/m512/m64bcst using writemask k1.",
    "Permute 128-bit floating-point fields in ymm2 and ymm3/mem using controls from imm8 and store result in ymm1.",
    "Permute 128-bit integer data in ymm2 and ymm3/mem using controls from imm8 and store result in ymm1.",
    "Permute doublewords in ymm3/m256 using indices in ymm2 and store the result in ymm1.",
    "Permute doublewords in ymm3/m256/m32bcst using indexes in ymm2 and store the result in ymm1 using writemask k1.",
    "Permute doublewords in zmm3/m512/m32bcst using indices in zmm2 and store the result in zmm1 using writemask k1.",
    "Permute word integers in xmm3/m128 using indexes in xmm2 and store the result in xmm1 using writemask k1.",
    "Permute word integers in ymm3/m256 using indexes in ymm2 and store the result in ymm1 using writemask k1.",
    "Permute word integers in zmm3/m512 using indexes in zmm2 and store the result in zmm1 using writemask k1.",
    "Permute word integers from two tables in xmm3/m128 and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.",
    "Permute word integers from two tables in ymm3/m256 and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.",
    "Permute word integers from two tables in zmm3/m512 and zmm2 using indexes in zmm1 and store the result in zmm1 using writemask k1.",
    "Permute double-words from two tables in xmm3/m128/m32bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.",
    "Permute double-words from two tables in ymm3/m256/m32bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.",
    "Permute double-words from two tables in zmm3/m512/m32bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.",
    "Permute quad-words from two tables in xmm3/m128/m64bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.",
    "Permute quad-words from two tables in ymm3/m256/m64bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.",
    "Permute quad-words from two tables in zmm3/m512/m64bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.",
    "Permute single-precision FP values from two tables in xmm3/m128/m32bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.",
    "Permute single-precision FP values from two tables in ymm3/m256/m32bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.",
    "Permute single-precision FP values from two tables in zmm3/m512/m32bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.",
    "Permute double-precision FP values from two tables in xmm3/m128/m64bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.",
    "Permute double-precision FP values from two tables in ymm3/m256/m64bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.",
    "Permute double-precision FP values from two tables in zmm3/m512/m64bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.",
    "Permute double-precision floating-point values in xmm2 using controls from xmm3/m128 and store result in xmm1.",
    "Permute double-precision floating-point values in ymm2 using controls from ymm3/m256 and store result in ymm1.",
    "Permute double-precision floating-point values in xmm2 using control from xmm3/m128/m64bcst and store the result in xmm1 using writemask k1.",
    "Permute double-precision floating-point values in ymm2 using control from ymm3/m256/m64bcst and store the result in ymm1 using writemask k1.",
    "Permute double-precision floating-point values in zmm2 using control from zmm3/m512/m64bcst and store the result in zmm1 using writemask k1.",
    "Permute double-precision floating-point values in xmm2/m128 using controls from imm8.",
    "Permute double-precision floating-point values in ymm2/m256 using controls from imm8.",
    "Permute double-precision floating-point values in xmm2/m128/m64bcst using controls from imm8 and store the result in xmm1 using writemask k1.",
    "Permute double-precision floating-point values in ymm2/m256/m64bcst using controls from imm8 and store the result in ymm1 using writemask k1.",
    "Permute double-precision floating-point values in zmm2/m512/m64bcst using controls from imm8 and store the result in zmm1 using writemask k1.",
    "Permute single-precision floating-point values in xmm2 using controls from xmm3/m128 and store result in xmm1.",
    "Permute single-precision floating-point values in xmm2/m128 using controls from imm8 and store result in xmm1.",
    "Permute single-precision floating-point values in ymm2 using controls from ymm3/m256 and store result in ymm1.",
    "Permute single-precision floating-point values in ymm2/m256 using controls from imm8 and store result in ymm1.",
    "Permute single-precision floating-point values xmm2 using control from xmm3/m128/m32bcst and store the result in xmm1 using writemask k1.",
    "Permute single-precision floating-point values ymm2 using control from ymm3/m256/m32bcst and store the result in ymm1 using writemask k1.",
    "Permute single-precision floating-point values zmm2 using control from zmm3/m512/m32bcst and store the result in zmm1 using writemask k1.",
    "Permute single-precision floating-point values xmm2/m128/m32bcst using controls from imm8 and store the result in xmm1 using writemask k1.",
    "Permute single-precision floating-point values ymm2/m256/m32bcst using controls from imm8 and store the result in ymm1 using writemask k1.",
    "Permute single-precision floating-point values zmm2/m512/m32bcst using controls from imm8 and store the result in zmm1 using writemask k1.",
    "Permute double-precision floating-point elements in ymm2/m256 using indices in imm8 and store the result in ymm1.",
    "Permute double-precision floating-point elements in ymm2/m256/m64bcst using indexes in imm8 and store the result in ymm1 subject to writemask k1.",
    "Permute double-precision floating-point elements in zmm2/m512/m64bcst using indices in imm8 and store the result in zmm1 subject to writemask k1.",
    "Permute double-precision floating-point elements in ymm3/m256/m64bcst using indexes in ymm2 and store the result in ymm1 subject to writemask k1.",
    "Permute double-precision floating-point elements in zmm3/m512/m64bcst using indices in zmm2 and store the result in zmm1 subject to writemask k1.",
    "Permute single-precision floating-point elements in ymm3/m256 using indices in ymm2 and store the result in ymm1.",
    "Permute single-precision floating-point elements in ymm3/m256/m32bcst using indexes in ymm2 and store the result in ymm1 subject to write mask k1.",
    "Permute single-precision floating-point values in zmm3/m512/m32bcst using indices in zmm2 and store the result in zmm1 subject to write mask k1.",
    "Permute qwords in ymm2/m256 using indices in imm8 and store the result in ymm1.",
    "Permute qwords in ymm2/m256/m64bcst using indexes in imm8 and store the result in ymm1.",
    "Permute qwords in zmm2/m512/m64bcst using indices in imm8 and store the result in zmm1.",
    "Permute qwords in ymm3/m256/m64bcst using indexes in ymm2 and store the result in ymm1.",
    "Permute qwords in zmm3/m512/m64bcst using indices in zmm2 and store the result in zmm1.",
    "Permute word integers from two tables in xmm3/m128 and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.",
    "Permute word integers from two tables in ymm3/m256 and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.",
    "Permute word integers from two tables in zmm3/m512 and zmm1 using indexes in zmm2 and store the result in zmm1 using writemask k1.",
    "Permute double-words from two tables in xmm3/m128/m32bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.",
    "Permute double-words from two tables in ymm3/m256/m32bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.",
    "Permute double-words from two tables in zmm3/m512/m32bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.",
    "Permute quad-words from two tables in xmm3/m128/m64bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.",
    "Permute quad-words from two tables in ymm3/m256/m64bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.",
    "Permute quad-words from two tables in zmm3/m512/m64bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.",
    "Permute single-precision FP values from two tables in xmm3/m128/m32bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.",
    "Permute single-precision FP values from two tables in ymm3/m256/m32bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.",
    "Permute single-precision FP values from two tables in zmm3/m512/m32bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.",
    "Permute double-precision FP values from two tables in xmm3/m128/m64bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.",
    "Permute double-precision FP values from two tables in ymm3/m256/m64bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.",
    "Permute double-precision FP values from two tables in zmm3/m512/m64bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.VPERMT2W/D/Q/PS/PDâ€”Full Permute from Two Tables Overwriting one Table",
    "Expand packed double-word integer values from xmm2/m128 to xmm1 using writemask k1.",
    "Expand packed double-word integer values from ymm2/m256 to ymm1 using writemask k1.",
    "Expand packed double-word integer values from zmm2/m512 to zmm1 using writemask k1.",
    "Expand packed quad-word integer values from xmm2/m128 to xmm1 using writemask k1.",
    "Expand packed quad-word integer values from ymm2/m256 to ymm1 using writemask k1.",
    "Expand packed quad-word integer values from zmm2/m512 to zmm1 using writemask k1.",
    "Using signed dword indices, gather dword values from memory using writemask k1 for merging-masking.",
    "Using signed dword indices, gather dword values from memory using writemask k1 for merging-masking.",
    "Using signed dword indices, gather dword values from memory using writemask k1 for merging-masking.",
    "Using signed dword indices, gather quadword values from memory using writemask k1 for merging-masking.",
    "Using signed dword indices, gather quadword values from memory using writemask k1 for merging-masking.",
    "Using signed dword indices, gather quadword values from memory using writemask k1 for merging-masking.",
    "Using dword indices specified in vm32x, gather dword val-ues from memory conditioned on mask specified by xmm2. Conditionally gathered elements are merged into xmm1.",
    "Using qword indices specified in vm64x, gather dword val-ues from memory conditioned on mask specified by xmm2. Conditionally gathered elements are merged into xmm1.",
    "Using dword indices specified in vm32y, gather dword from memory conditioned on mask specified by ymm2. Conditionally gathered elements are merged into ymm1.",
    "Using qword indices specified in vm64y, gather dword val-ues from memory conditioned on mask specified by xmm2. Conditionally gathered elements are merged into xmm1.",
    "Using dword indices specified in vm32x, gather qword val-ues from memory conditioned on mask specified by xmm2. Conditionally gathered elements are merged into xmm1.",
    "Using qword indices specified in vm64x, gather qword val-ues from memory conditioned on mask specified by xmm2. Conditionally gathered elements are merged into xmm1.",
    "Using dword indices specified in vm32x, gather qword val-ues from memory conditioned on mask specified by ymm2. Conditionally gathered elements are merged into ymm1.",
    "Using qword indices specified in vm64y, gather qword val-ues from memory conditioned on mask specified by ymm2. Conditionally gathered elements are merged into ymm1.",
    "Using signed qword indices, gather dword values from memory using writemask k1 for merging-masking.",
    "Using signed qword indices, gather dword values from memory using writemask k1 for merging-masking.",
    "Using signed qword indices, gather dword values from memory using writemask k1 for merging-masking.",
    "Using signed qword indices, gather quadword values from memory using writemask k1 for merging-masking.",
    "Using signed qword indices, gather quadword values from memory using writemask k1 for merging-masking.",
    "Using signed qword indices, gather quadword values from memory using writemask k1 for merging-masking.",
    "Count the number of leading zero bits in each dword element of xmm2/m128/m32bcst using writemask k1.",
    "Count the number of leading zero bits in each dword element of ymm2/m256/m32bcst using writemask k1.",
    "Count the number of leading zero bits in each dword element of zmm2/m512/m32bcst using writemask k1.",
    "Count the number of leading zero bits in each qword element of xmm2/m128/m64bcst using writemask k1.",
    "Count the number of leading zero bits in each qword element of ymm2/m256/m64bcst using writemask k1.",
    "Count the number of leading zero bits in each qword element of zmm2/m512/m64bcst using writemask k1.",
    "Conditionally load dword values from m128 using mask in xmm2 and store in xmm1.",
    "Conditionally load dword values from m256 using mask in ymm2 and store in ymm1.",
    "Conditionally load qword values from m128 using mask in xmm2 and store in xmm1.",
    "Conditionally load qword values from m256 using mask in ymm2 and store in ymm1.",
    "Conditionally store dword values from xmm2 using mask in xmm1.",
    "Conditionally store dword values from ymm2 using mask in ymm1.",
    "Conditionally store qword values from xmm2 using mask in xmm1.",
    "Conditionally store qword values from ymm2 using mask in ymm1.",
    "Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding byte in XMM1.",
    "Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding byte in YMM1.",
    "Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding byte in ZMM1.",
    "Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding word in XMM1.",
    "Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding word in YMM1.",
    "Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding word in ZMM1.",
    "Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding doubleword in XMM1.",
    "Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding doubleword in YMM1.",
    "Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding doubleword in ZMM1.",
    "Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding quadword in XMM1.",
    "Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding quadword in YMM1.",
    "Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding quadword in ZMM1.",
    "Converts 4 packed double-word integers from xmm2 into 4 packed byte integers in xmm1/m32 with truncation under writemask k1.",
    "Converts 4 packed signed double-word integers from xmm2 into 4 packed signed byte integers in xmm1/m32 using signed saturation under writemask k1.",
    "Converts 4 packed unsigned double-word integers from xmm2 into 4 packed unsigned byte integers in xmm1/m32 using unsigned saturation under writemask k1.",
    "Converts 8 packed double-word integers from ymm2 into 8 packed byte integers in xmm1/m64 with truncation under writemask k1.",
    "Converts 8 packed signed double-word integers from ymm2 into 8 packed signed byte integers in xmm1/m64 using signed saturation under writemask k1.",
    "Converts 8 packed unsigned double-word integers from ymm2 into 8 packed unsigned byte integers in xmm1/m64 using unsigned saturation under writemask k1.",
    "Converts 16 packed double-word integers from zmm2 into 16 packed byte integers in xmm1/m128 with truncation under writemask k1.",
    "Converts 16 packed signed double-word integers from zmm2 into 16 packed signed byte integers in xmm1/m128 using signed saturation under writemask k1.",
    "Converts 16 packed unsigned double-word integers from zmm2 into 16 packed unsigned byte integers in xmm1/m128 using unsigned saturation under writemask k1.",
    "Converts 4 packed double-word integers from xmm2 into 4 packed word integers in xmm1/m64 with truncation under writemask k1.",
    "Converts 4 packed signed double-word integers from xmm2 into 4 packed signed word integers in ymm1/m64 using signed saturation under writemask k1.",
    "Converts 4 packed unsigned double-word integers from xmm2 into 4 packed unsigned word integers in xmm1/m64 using unsigned saturation under writemask k1.",
    "Converts 8 packed double-word integers from ymm2 into 8 packed word integers in xmm1/m128 with truncation under writemask k1.",
    "Converts 8 packed signed double-word integers from ymm2 into 8 packed signed word integers in xmm1/m128 using signed saturation under writemask k1.",
    "Converts 8 packed unsigned double-word integers from ymm2 into 8 packed unsigned word integers in xmm1/m128 using unsigned saturation under writemask k1.",
    "Converts 16 packed double-word integers from zmm2 into 16 packed word integers in ymm1/m256 with truncation under writemask k1.",
    "Converts 16 packed signed double-word integers from zmm2 into 16 packed signed word integers in ymm1/m256 using signed saturation under writemask k1.",
    "Converts 16 packed unsigned double-word integers from zmm2 into 16 packed unsigned word integers in ymm1/m256 using unsigned saturation under writemask k1.",
    "Sets each byte in XMM1 to all 1â€™s or all 0â€™s based on the value of the corresponding bit in k1.",
    "Sets each byte in YMM1 to all 1â€™s or all 0â€™s based on the value of the corresponding bit in k1.",
    "Sets each byte in ZMM1 to all 1â€™s or all 0â€™s based on the value of the corresponding bit in k1.",
    "Sets each word in XMM1 to all 1â€™s or all 0â€™s based on the value of the corresponding bit in k1.",
    "Sets each word in YMM1 to all 1â€™s or all 0â€™s based on the value of the corresponding bit in k1.",
    "Sets each word in ZMM1 to all 1â€™s or all 0â€™s based on the value of the corresponding bit in k1.",
    "Sets each doubleword in XMM1 to all 1â€™s or all 0â€™s based on the value of the corresponding bit in k1.",
    "Sets each doubleword in YMM1 to all 1â€™s or all 0â€™s based on the value of the corresponding bit in k1.",
    "Sets each doubleword in ZMM1 to all 1â€™s or all 0â€™s based on the value of the corresponding bit in k1.",
    "Sets each quadword in XMM1 to all 1â€™s or all 0â€™s based on the value of the corresponding bit in k1.",
    "Sets each quadword in YMM1 to all 1â€™s or all 0â€™s based on the value of the corresponding bit in k1.",
    "Sets each quadword in ZMM1 to all 1â€™s or all 0â€™s based on the value of the corresponding bit in k1.",
    "Converts 2 packed quad-word integers from xmm2 into 2 packed byte integers in xmm1/m16 with truncation under writemask k1.",
    "Converts 2 packed signed quad-word integers from xmm2 into 2 packed signed byte integers in xmm1/m16 using signed saturation under writemask k1.",
    "Converts 2 packed unsigned quad-word integers from xmm2 into 2 packed unsigned byte integers in xmm1/m16 using unsigned saturation under writemask k1.",
    "Converts 4 packed quad-word integers from ymm2 into 4 packed byte integers in xmm1/m32 with truncation under writemask k1.",
    "Converts 4 packed signed quad-word integers from ymm2 into 4 packed signed byte integers in xmm1/m32 using signed saturation under writemask k1.",
    "Converts 4 packed unsigned quad-word integers from ymm2 into 4 packed unsigned byte integers in xmm1/m32 using unsigned saturation under writemask k1.",
    "Converts 8 packed quad-word integers from zmm2 into 8 packed byte integers in xmm1/m64 with truncation under writemask k1.",
    "Converts 8 packed signed quad-word integers from zmm2 into 8 packed signed byte integers in xmm1/m64 using signed saturation under writemask k1.",
    "Converts 8 packed unsigned quad-word integers from zmm2 into 8 packed unsigned byte integers in xmm1/m64 using unsigned saturation under writemask k1.",
    "Converts 2 packed quad-word integers from xmm2 into 2 packed double-word integers in xmm1/m128 with truncation subject to writemask k1.",
    "Converts 2 packed signed quad-word integers from xmm2 into 2 packed signed double-word integers in xmm1/m64 using signed saturation subject to writemask k1.",
    "Converts 2 packed unsigned quad-word integers from xmm2 into 2 packed unsigned double-word integers in xmm1/m64 using unsigned saturation subject to writemask k1.",
    "Converts 4 packed quad-word integers from ymm2 into 4 packed double-word integers in xmm1/m128 with truncation subject to writemask k1.",
    "Converts 4 packed signed quad-word integers from ymm2 into 4 packed signed double-word integers in xmm1/m128 using signed saturation subject to writemask k1.",
    "Converts 4 packed unsigned quad-word integers from ymm2 into 4 packed unsigned double-word integers in xmm1/m128 using unsigned saturation subject to writemask k1.",
    "Converts 8 packed quad-word integers from zmm2 into 8 packed double-word integers in ymm1/m256 with truncation subject to writemask k1.",
    "Converts 8 packed signed quad-word integers from zmm2 into 8 packed signed double-word integers in ymm1/m256 using signed saturation subject to writemask k1.",
    "Converts 8 packed unsigned quad-word integers from zmm2 into 8 packed unsigned double-word integers in ymm1/m256 using unsigned saturation subject to writemask k1.",
    "Converts 2 packed quad-word integers from xmm2 into 2 packed word integers in xmm1/m32 with truncation under writemask k1.",
    "Converts 8 packed signed quad-word integers from zmm2 into 8 packed signed word integers in xmm1/m32 using signed saturation under writemask k1.",
    "Converts 2 packed unsigned quad-word integers from xmm2 into 2 packed unsigned word integers in xmm1/m32 using unsigned saturation under writemask k1.",
    "Converts 4 packed quad-word integers from ymm2 into 4 packed word integers in xmm1/m64 with truncation under writemask k1.",
    "Converts 4 packed signed quad-word integers from ymm2 into 4 packed signed word integers in xmm1/m64 using signed saturation under writemask k1.",
    "Converts 4 packed unsigned quad-word integers from ymm2 into 4 packed unsigned word integers in xmm1/m64 using unsigned saturation under writemask k1.",
    "Converts 8 packed quad-word integers from zmm2 into 8 packed word integers in xmm1/m128 with truncation under writemask k1.",
    "Converts 8 packed signed quad-word integers from zmm2 into 8 packed signed word integers in xmm1/m128 using signed saturation under writemask k1.",
    "Converts 8 packed unsigned quad-word integers from zmm2 into 8 packed unsigned word integers in xmm1/m128 using unsigned saturation under writemask k1.",
    "Converts 8 packed word integers from xmm2 into 8 packed bytes in xmm1/m64 with truncation under writemask k1.",
    "Converts 8 packed signed word integers from xmm2 into 8 packed signed bytes in xmm1/m64 using signed saturation under writemask k1.",
    "Converts 8 packed unsigned word integers from xmm2 into 8 packed unsigned bytes in 8mm1/m64 using unsigned saturation under writemask k1.",
    "Converts 16 packed word integers from ymm2 into 16 packed bytes in xmm1/m128 with truncation under writemask k1.",
    "Converts 16 packed signed word integers from ymm2 into 16 packed signed bytes in xmm1/m128 using signed saturation under writemask k1.",
    "Converts 16 packed unsigned word integers from ymm2 into 16 packed unsigned bytes in xmm1/m128 using unsigned saturation under writemask k1.",
    "Converts 32 packed word integers from zmm2 into 32 packed bytes in ymm1/m256 with truncation under writemask k1.",
    "Converts 32 packed signed word integers from zmm2 into 32 packed signed bytes in ymm1/m256 using signed saturation under writemask k1.",
    "Converts 32 packed unsigned word integers from zmm2 into 32 packed unsigned bytes in ymm1/m256 using unsigned saturation under writemask k1.",
    "Rotate doublewords in xmm2 left by count in the corresponding element of xmm3/m128/m32bcst. Result written to xmm1 under writemask k1.",
    "Rotate doublewords in xmm2/m128/m32bcst left by imm8. Result written to xmm1 using writemask k1.",
    "Rotate quadwords in xmm2 left by count in the corresponding element of xmm3/m128/m64bcst. Result written to xmm1 under writemask k1.",
    "Rotate quadwords in xmm2/m128/m64bcst left by imm8. Result written to xmm1 using writemask k1.",
    "Rotate doublewords in ymm2 left by count in the corresponding element of ymm3/m256/m32bcst. Result written to ymm1 under writemask k1.",
    "Rotate doublewords in ymm2/m256/m32bcst left by imm8. Result written to ymm1 using writemask k1.",
    "Rotate quadwords in ymm2 left by count in the corresponding element of ymm3/m256/m64bcst. Result written to ymm1 under writemask k1.",
    "Rotate quadwords in ymm2/m256/m64bcst left by imm8. Result written to ymm1 using writemask k1.",
    "Rotate left of doublewords in zmm2 by count in the corresponding element of zmm3/m512/m32bcst. Result written to zmm1 using writemask k1.",
    "Rotate left of doublewords in zmm3/m512/m32bcst by imm8. Result written to zmm1 using writemask k1.",
    "Rotate quadwords in zmm2 left by count in the corresponding element of zmm3/m512/m64bcst. Result written to zmm1under writemask k1.",
    "Rotate quadwords in zmm2/m512/m64bcst left by imm8. Result written to zmm1 using writemask k1.",
    "Rotate doublewords in xmm2 right by count in the corresponding element of xmm3/m128/m32bcst, store result using writemask k1.",
    "Rotate doublewords in xmm2/m128/m32bcst right by imm8, store result using writemask k1.",
    "Rotate quadwords in xmm2 right by count in the corresponding element of xmm3/m128/m64bcst, store result using writemask k1.",
    "Rotate quadwords in xmm2/m128/m64bcst right by imm8, store result using writemask k1.",
    "Rotate doublewords in ymm2 right by count in the corresponding element of ymm3/m256/m32bcst, store using result writemask k1.",
    "Rotate doublewords in ymm2/m256/m32bcst right by imm8, store result using writemask k1.",
    "Rotate quadwords in ymm2 right by count in the corresponding element of ymm3/m256/m64bcst, store result using writemask k1.",
    "Rotate quadwords in ymm2/m256/m64bcst right by imm8, store result using writemask k1.",
    "Rotate doublewords in zmm2 right by count in the corresponding element of zmm3/m512/m32bcst, store result using writemask k1.",
    "Rotate doublewords in zmm2/m512/m32bcst right by imm8, store result using writemask k1.",
    "Rotate quadwords in zmm2 right by count in the corresponding element of zmm3/m512/m64bcst, store result using writemask k1.",
    "Rotate quadwords in zmm2/m512/m64bcst right by imm8, store result using writemask k1.",
    "Using signed dword indices, scatter dword values to memory using writemask k1.",
    "Using signed dword indices, scatter dword values to memory using writemask k1.",
    "Using signed dword indices, scatter dword values to memory using writemask k1.",
    "Using signed dword indices, scatter qword values to memory using writemask k1.",
    "Using signed dword indices, scatter qword values to memory using writemask k1.",
    "Using signed dword indices, scatter qword values to memory using writemask k1.",
    "Using signed qword indices, scatter dword values to memory using writemask k1.",
    "Using signed qword indices, scatter dword values to memory using writemask k1.",
    "Using signed qword indices, scatter dword values to memory using writemask k1.",
    "Using signed qword indices, scatter qword values to memory using writemask k1.",
    "Using signed qword indices, scatter qword values to memory using writemask k1.",
    "Using signed qword indices, scatter qword values to memory using writemask k1.",
    "Shift doublewords in xmm2 left by amount specified in the corresponding element of xmm3/m128 while shifting in 0s.",
    "Shift quadwords in xmm2 left by amount specified in the corresponding element of xmm3/m128 while shifting in 0s.",
    "Shift doublewords in ymm2 left by amount specified in the corresponding element of ymm3/m256 while shifting in 0s.",
    "Shift quadwords in ymm2 left by amount specified in the corresponding element of ymm3/m256 while shifting in 0s.",
    "Shift words in xmm2 left by amount specified in the corresponding element of xmm3/m128 while shifting in 0s using writemask k1.",
    "Shift words in ymm2 left by amount specified in the corresponding element of ymm3/m256 while shifting in 0s using writemask k1.",
    "Shift words in zmm2 left by amount specified in the corresponding element of zmm3/m512 while shifting in 0s using writemask k1.",
    "Shift doublewords in xmm2 left by amount specified in the corresponding element of xmm3/m128/m32bcst while shifting in 0s using writemask k1.",
    "Shift doublewords in ymm2 left by amount specified in the corresponding element of ymm3/m256/m32bcst while shifting in 0s using writemask k1.",
    "Shift doublewords in zmm2 left by amount specified in the corresponding element of zmm3/m512/m32bcst while shifting in 0s using writemask k1.",
    "Shift quadwords in xmm2 left by amount specified in the corresponding element of xmm3/m128/m64bcst while shifting in 0s using writemask k1.",
    "Shift quadwords in ymm2 left by amount specified in the corresponding element of ymm3/m256/m64bcst while shifting in 0s using writemask k1.",
    "Shift quadwords in zmm2 left by amount specified in the corresponding element of zmm3/m512/m64bcst while shifting in 0s using writemask k1.",
    "Shift doublewords in xmm2 right by amount specified in the corresponding element of xmm3/m128 while shifting in sign bits.",
    "Shift doublewords in ymm2 right by amount specified in the corresponding element of ymm3/m256 while shifting in sign bits.",
    "Shift words in xmm2 right by amount specified in the corresponding element of xmm3/m128 while shifting in sign bits using writemask k1.",
    "Shift words in ymm2 right by amount specified in the corresponding element of ymm3/m256 while shifting in sign bits using writemask k1.",
    "Shift words in zmm2 right by amount specified in the corresponding element of zmm3/m512 while shifting in sign bits using writemask k1.",
    "Shift doublewords in xmm2 right by amount specified in the corresponding element of xmm3/m128/m32bcst while shifting in sign bits using writemask k1.",
    "Shift doublewords in ymm2 right by amount specified in the corresponding element of ymm3/m256/m32bcst while shifting in sign bits using writemask k1.",
    "Shift doublewords in zmm2 right by amount specified in the corresponding element of zmm3/m512/m32bcst while shifting in sign bits using writemask k1.",
    "Shift quadwords in xmm2 right by amount specified in the corresponding element of xmm3/m128/m64bcst while shifting in sign bits using writemask k1.",
    "Shift quadwords in ymm2 right by amount specified in the corresponding element of ymm3/m256/m64bcst while shifting in sign bits using writemask k1.",
    "Shift quadwords in zmm2 right by amount specified in the corresponding element of zmm3/m512/m64bcst while shifting in sign bits using writemask k1.",
    "Shift doublewords in xmm2 right by amount specified in the corresponding element of xmm3/m128 while shifting in 0s.",
    "Shift quadwords in xmm2 right by amount specified in the corresponding element of xmm3/m128 while shifting in 0s.",
    "Shift doublewords in ymm2 right by amount specified in the corresponding element of ymm3/m256 while shifting in 0s.",
    "Shift quadwords in ymm2 right by amount specified in the corresponding element of ymm3/m256 while shifting in 0s.",
    "Shift words in xmm2 right by amount specified in the corresponding element of xmm3/m128 while shifting in 0s using writemask k1.",
    "Shift words in ymm2 right by amount specified in the corresponding element of ymm3/m256 while shifting in 0s using writemask k1.",
    "Shift words in zmm2 right by amount specified in the corresponding element of zmm3/m512 while shifting in 0s using writemask k1.",
    "Shift doublewords in xmm2 right by amount specified in the corresponding element of xmm3/m128/m32bcst while shifting in 0s using writemask k1.",
    "Shift doublewords in ymm2 right by amount specified in the corresponding element of ymm3/m256/m32bcst while shifting in 0s using writemask k1.",
    "Shift doublewords in zmm2 right by amount specified in the corresponding element of zmm3/m512/m32bcst while shifting in 0s using writemask k1.",
    "Shift quadwords in xmm2 right by amount specified in the corresponding element of xmm3/m128/m64bcst while shifting in 0s using writemask k1.",
    "Shift quadwords in ymm2 right by amount specified in the corresponding element of ymm3/m256/m64bcst while shifting in 0s using writemask k1.",
    "Shift quadwords in zmm2 right by amount specified in the corresponding element of zmm3/m512/m64bcst while shifting in 0s using writemask k1.",
    "Bitwise ternary logic taking xmm1, xmm2 and xmm3/m128/m32bcst as source operands and writing the result to xmm1 under writemask k1 with dword granularity. The immediate value determines the specific binary function being implemented.",
    "Bitwise ternary logic taking ymm1, ymm2 and ymm3/m256/m32bcst as source operands and writing the result to ymm1 under writemask k1 with dword granularity. The immediate value determines the specific binary function being implemented.",
    "Bitwise ternary logic taking zmm1, zmm2 and zmm3/m512/m32bcst as source operands and writing the result to zmm1 under writemask k1 with dword granularity. The immediate value determines the specific binary function being implemented.",
    "Bitwise ternary logic taking xmm1, xmm2 and xmm3/m128/m64bcst as source operands and writing the result to xmm1 under writemask k1 with qword granularity. The immediate value determines the specific binary function being implemented.",
    "Bitwise ternary logic taking ymm1, ymm2 and ymm3/m256/m64bcst as source operands and writing the result to ymm1 under writemask k1 with qword granularity. The immediate value determines the specific binary function being implemented.",
    "Bitwise ternary logic taking zmm1, zmm2 and zmm3/m512/m64bcst as source operands and writing the result to zmm1 under writemask k1 with qword granularity. The immediate value determines the specific binary function being implemented.",
    "Bitwise AND of packed byte integers in xmm2 and xmm3/m128 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.",
    "Bitwise AND of packed byte integers in ymm2 and ymm3/m256 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.",
    "Bitwise AND of packed byte integers in zmm2 and zmm3/m512 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.",
    "Bitwise AND of packed word integers in xmm2 and xmm3/m128 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.",
    "Bitwise AND of packed word integers in ymm2 and ymm3/m256 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.",
    "Bitwise AND of packed word integers in zmm2 and zmm3/m512 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.",
    "Bitwise AND of packed doubleword integers in xmm2 and xmm3/m128/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.",
    "Bitwise AND of packed doubleword integers in ymm2 and ymm3/m256/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.",
    "Bitwise AND of packed doubleword integers in zmm2 and zmm3/m512/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.",
    "Bitwise AND of packed quadword integers in xmm2 and xmm3/m128/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.",
    "Bitwise AND of packed quadword integers in ymm2 and ymm3/m256/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.",
    "Bitwise AND of packed quadword integers in zmm2 and zmm3/m512/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.",
    "Bitwise NAND of packed byte integers in xmm2 and xmm3/m128 and set mask k2 to reflect the zero/non-zero status of each element of the result,under writemask k1.",
    "Bitwise NAND of packed byte integers in ymm2 and ymm3/m256 and set mask k2 to reflect the zero/non-zero status of each element of the result,under writemask k1.",
    "Bitwise NAND of packed byte integers in zmm2 and zmm3/m512 and set mask k2 to reflect the zero/non-zero status of each element of the result,under writemask k1.",
    "Bitwise NAND of packed word integers in xmm2 and xmm3/m128 and set mask k2 to reflect the zero/non-zero status of each element of the result,under writemask k1.",
    "Bitwise NAND of packed word integers in ymm2 and ymm3/m256 and set mask k2 to reflect the zero/non-zero status of each element of the result,under writemask k1.",
    "Bitwise NAND of packed word integers in zmm2 and zmm3/m512 and set mask k2 to reflect the zero/non-zero status of each element of the result,under writemask k1.",
    "Bitwise NAND of packed doubleword integers in xmm2 and xmm3/m128/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result,under writemask k1.",
    "Bitwise NAND of packed doubleword integers in ymm2 and ymm3/m256/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result,under writemask k1.",
    "Bitwise NAND of packed doubleword integers in zmm2 and zmm3/m512/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result,under writemask k1.",
    "Bitwise NAND of packed quadword integers in xmm2 and xmm3/m128/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result,under writemask k1.",
    "Bitwise NAND of packed quadword integers in ymm2 and ymm3/m256/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result,under writemask k1.",
    "Bitwise NAND of packed quadword integers in zmm2 and zmm3/m512/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result,under writemask k1.",
    "Calculate two RANGE operation output value from 2 pairs of double-precision floating-point values in xmm2 and xmm3/m128/m32bcst, store the results to xmm1 under the writemask k1. Imm8 specifies the comparison and sign of the range operation.",
    "Calculate four RANGE operation output value from 4pairs of double-precision floating-point values in ymm2 and ymm3/m256/m32bcst, store the results to ymm1 under the writemask k1. Imm8 specifies the comparison and sign of the range operation.",
    "Calculate eight RANGE operation output value from 8 pairs of double-precision floating-point values in zmm2 and zmm3/m512/m32bcst, store the results to zmm1 under the writemask k1. Imm8 specifies the comparison and sign of the range operation.",
    "Calculate four RANGE operation output value from 4 pairs of single-precision floating-point values in xmm2 and xmm3/m128/m32bcst, store the results to xmm1 under the writemask k1. Imm8 specifies the comparison and sign of the range operation.",
    "Calculate eight RANGE operation output value from 8 pairs of single-precision floating-point values in ymm2 and ymm3/m256/m32bcst, store the results to ymm1 under the writemask k1. Imm8 specifies the comparison and sign of the range operation.",
    "Calculate 16 RANGE operation output value from 16 pairs of single-precision floating-point values in zmm2 and zmm3/m512/m32bcst, store the results to zmm1 under the writemask k1. Imm8 specifies the comparison and sign of the range operation.",
    "Calculate a RANGE operation output value from 2 double-precision floating-point values in xmm2 and xmm3/m64, store the output to xmm1 under writemask. Imm8 specifies the comparison and sign of the range operation.",
    "Calculate a RANGE operation output value from 2 single-precision floating-point values in xmm2 and xmm3/m32, store the output to xmm1 under writemask. Imm8 specifies the comparison and sign of the range operation.",
    "Computes the approximate reciprocals of the packed double-precision floating-point values in xmm2/m128/m64bcst and stores the results in xmm1. Under writemask.",
    "Computes the approximate reciprocals of the packed double-precision floating-point values in ymm2/m256/m64bcst and stores the results in ymm1. Under writemask.",
    "Computes the approximate reciprocals of the packed double-precision floating-point values in zmm2/m512/m64bcst and stores the results in zmm1. Under writemask.",
    "Computes the approximate reciprocals of the packed single-precision floating-point values in xmm2/m128/m32bcst and stores the results in xmm1. Under writemask.",
    "Computes the approximate reciprocals of the packed single-precision floating-point values in ymm2/m256/m32bcst and stores the results in ymm1. Under writemask.",
    "Computes the approximate reciprocals of the packed single-precision floating-point values in zmm2/m512/m32bcst and stores the results in zmm1. Under writemask.",
    "Computes the approximate reciprocal of the scalar double-precision floating-point value in xmm3/m64 and stores the result in xmm1 using writemask k1. Also, upper double-precision floating-point value (bits[127:64]) from xmm2 is copied to xmm1[127:64].",
    "Computes the approximate reciprocal of the scalar single-precision floating-point value in xmm3/m32 and stores the results in xmm1 using writemask k1. Also, upper double-precision floating-point value (bits[127:32]) from xmm2 is copied to xmm1[127:32].",
    "Computes the approximate reciprocals ( < 2^-28 relative error) of the packed double-precision floating-point values in zmm2/m512/m64bcst and stores the results in zmm1. Under writemask.",
    "Computes the approximate reciprocals ( < 2^-28 relative error) of the packed single-precision floating-point values in zmm2/m512/m32bcst and stores the results in zmm1. Under writemask.",
    "Computes the approximate reciprocal ( < 2^-28 relative error) of the scalar double-precision floating-point value in xmm3/m64 and stores the results in xmm1. Under writemask. Also, upper double-precision floating-point value (bits[127:64]) from xmm2 is copied to xmm1[127:64].",
    "Computes the approximate reciprocal ( < 2^-28 relative error) of the scalar single-precision floating-point value in xmm3/m32 and stores the results in xmm1. Under writemask. Also, upper 3 single-precision floating-point values (bits[127:32]) from xmm2 is copied to xmm1[127:32].",
    "Perform reduction transformation on packed double-precision floating point values in xmm2/m128/m32bcst by subtracting a number of fraction bits specified by the imm8 field. Stores the result in xmm1 register under writemask k1.",
    "Perform reduction transformation on packed double-precision floating point values in ymm2/m256/m32bcst by subtracting a number of fraction bits specified by the imm8 field. Stores the result in ymm1 register under writemask k1.",
    "Perform reduction transformation on double-precision floating point values in zmm2/m512/m32bcst by subtracting a number of fraction bits specified by the imm8 field. Stores the result in zmm1 register under writemask k1.",
    "Perform reduction transformation on packed single-precision floating point values in xmm2/m128/m32bcst by subtracting a number of fraction bits specified by the imm8 field. Stores the result in xmm1 register under writemask k1.",
    "Perform reduction transformation on packed single-precision floating point values in ymm2/m256/m32bcst by subtracting a number of fraction bits specified by the imm8 field. Stores the result in ymm1 register under writemask k1.",
    "Perform reduction transformation on packed single-precision floating point values in zmm2/m512/m32bcst by subtracting a number of fraction bits specified by the imm8 field. Stores the result in zmm1 register under writemask k1.",
    "Perform a reduction transformation on a scalar double-precision floating point value in xmm3/m64 by subtracting a number of fraction bits specified by the imm8 field. Also, upper double precision floating-point value (bits[127:64]) from xmm2 are copied to xmm1[127:64]. Stores the result in xmm1 register.",
    "Perform a reduction transformation on a scalar single-precision floating point value in xmm3/m32 by subtracting a number of fraction bits specified by the imm8 field. Also, upper single precision floating-point values (bits[127:32]) from xmm2 are copied to xmm1[127:32]. Stores the result in xmm1 register.",
    "Rounds packed double-precision floating point values in xmm2/m128/m64bcst to a number of fraction bits specified by the imm8 field. Stores the result in xmm1 register. Under writemask.",
    "Rounds packed double-precision floating point values in ymm2/m256/m64bcst to a number of fraction bits specified by the imm8 field. Stores the result in ymm1 register. Under writemask.",
    "Rounds packed double-precision floating-point values in zmm2/m512/m64bcst to a number of fraction bits specified by the imm8 field. Stores the result in zmm1 register using writemask k1.",
    "Rounds packed single-precision floating point values in xmm2/m128/m32bcst to a number of fraction bits specified by the imm8 field. Stores the result in xmm1 register. Under writemask.",
    "Rounds packed single-precision floating point values in ymm2/m256/m32bcst to a number of fraction bits specified by the imm8 field. Stores the result in ymm1 register. Under writemask.",
    "Rounds packed single-precision floating-point values in zmm2/m512/m32bcst to a number of fraction bits specified by the imm8 field. Stores the result in zmm1 register using writemask.",
    "Rounds scalar double-precision floating-point value in xmm3/m64 to a number of fraction bits specified by the imm8 field. Stores the result in xmm1 register.",
    "Rounds scalar single-precision floating-point value in xmm3/m32 to a number of fraction bits specified by the imm8 field. Stores the result in xmm1 register under writemask.",
    "Computes the approximate reciprocal square roots of the packed double-precision floating-point values in xmm2/m128/m64bcst and stores the results in xmm1. Under writemask.",
    "Computes the approximate reciprocal square roots of the packed double-precision floating-point values in ymm2/m256/m64bcst and stores the results in ymm1. Under writemask.",
    "Computes the approximate reciprocal square roots of the packed double-precision floating-point values in zmm2/m512/m64bcst and stores the results in zmm1 under writemask.",
    "Computes the approximate reciprocal square roots of the packed single-precision floating-point values in xmm2/m128/m32bcst and stores the results in xmm1. Under writemask.",
    "Computes the approximate reciprocal square roots of the packed single-precision floating-point values in ymm2/m256/m32bcst and stores the results in ymm1. Under writemask.",
    "Computes the approximate reciprocal square roots of the packed single-precision floating-point values in zmm2/m512/m32bcst and stores the results in zmm1. Under writemask.",
    "Computes the approximate reciprocal square root of the scalar double-precision floating-point value in xmm3/m64 and stores the result in the low quadword element of xmm1 using writemask k1. Bits[127:64] of xmm2 is copied to xmm1[127:64].",
    "Computes the approximate reciprocal square root of the scalar single-precision floating-point value in xmm3/m32 and stores the result in the low doubleword element of xmm1 using writemask k1. Bits[127:32] of xmm2 is copied to xmm1[127:32].",
    "Computes approximations to the Reciprocal square root (<2^-28 relative error) of the packed double-precision floating-point values from zmm2/m512/m64bcst and stores result in zmm1with writemask k1.",
    "Computes approximations to the Reciprocal square root (<2^-28 relative error) of the packed single-precision floating-point values from zmm2/m512/m32bcst and stores result in zmm1with writemask k1.",
    "Computes approximate reciprocal square root (<2^-28 relative error) of the scalar double-precision floating-point value from xmm3/m64 and stores result in xmm1with writemask k1. Also, upper double-precision floating-point value (bits[127:64]) from xmm2 is copied to xmm1[127:64].",
    "Computes approximate reciprocal square root (<2^-28 relative error) of the scalar single-precision floating-point value from xmm3/m32 and stores result in xmm1with writemask k1. Also, upper 3 single-precision floating-point value (bits[127:32]) from xmm2 is copied to xmm1[127:32].",
    "Scale the packed double-precision floating-point values in xmm2 using values from xmm3/m128/m64bcst. Under writemask k1.",
    "Scale the packed double-precision floating-point values in ymm2 using values from ymm3/m256/m64bcst. Under writemask k1.",
    "Scale the packed double-precision floating-point values in zmm2 using values from zmm3/m512/m64bcst. Under writemask k1.",
    "Scale the packed single-precision floating-point values in xmm2 using values from xmm3/m128/m32bcst. Under writemask k1.",
    "Scale the packed single-precision values in ymm2 using floating point values from ymm3/m256/m32bcst. Under writemask k1.",
    "Scale the packed single-precision floating-point values in zmm2 using floating-point values from zmm3/m512/m32bcst. Under writemask k1.",
    "Scale the scalar double-precision floating-point values in xmm2 using the value from xmm3/m64. Under writemask k1.",
    "Scale the scalar single-precision floating-point value in xmm2 using floating-point value from xmm3/m32. Under writemask k1.",
    "Using signed dword indices, scatter single-precision floating-point values to memory using writemask k1.",
    "Using signed dword indices, scatter single-precision floating-point values to memory using writemask k1.",
    "Using signed dword indices, scatter single-precision floating-point values to memory using writemask k1.",
    "Using signed dword indices, scatter double-precision floating-point values to memory using writemask k1.",
    "Using signed dword indices, scatter double-precision floating-point values to memory using writemask k1.",
    "Using signed dword indices, scatter double-precision floating-point values to memory using writemask k1.",
    "Using signed qword indices, scatter single-precision floating-point values to memory using writemask k1.",
    "Using signed qword indices, scatter single-precision floating-point values to memory using writemask k1.",
    "Using signed qword indices, scatter single-precision floating-point values to memory using writemask k1.",
    "Using signed qword indices, scatter double-precision floating-point values to memory using writemask k1.",
    "Using signed qword indices, scatter double-precision floating-point values to memory using writemask k1.",
    "Using signed qword indices, scatter double-precision floating-point values to memory using writemask k1.",
    "Using signed dword indices, prefetch sparse byte memory locations containing single-precision data using writemask k1 and T0 hint with intent to write.",
    "Using signed qword indices, prefetch sparse byte memory locations containing single-precision data using writemask k1 and T0 hint with intent to write.",
    "Using signed dword indices, prefetch sparse byte memory locations containing double-precision data using writemask k1 and T0 hint with intent to write.",
    "Using signed qword indices, prefetch sparse byte memory locations containing double-precision data using writemask k1 and T0 hint with intent to write.",
    "Using signed dword indices, prefetch sparse byte memory locations containing single-precision data using writemask k1 and T1 hint with intent to write.",
    "Using signed qword indices, prefetch sparse byte memory locations containing single-precision data using writemask k1 and T1 hint with intent to write.",
    "Using signed dword indices, prefetch sparse byte memory locations containing double-precision data using writemask k1 and T1 hint with intent to write.",
    "Using signed qword indices, prefetch sparse byte memory locations containing double-precision data using writemask k1 and T1 hint with intent to write.",
    "Shuffle 128-bit packed single-precision floating-point values selected by imm8 from zmm2 and zmm3/m512/m32bcst and place results in zmm1 subject to writemask k1. EVEX.NDS.256.66.0F3A.W1 23 /r ib VSHUFF64X2 ymm1{k1}{z}, ymm2, ymm3/m256/m64bcst, imm8 A V/V AVX512VL AVX512F Shuffle 128-bit packed double-precision floating-point values selected by imm8 from ymm2 and ymm3/m256/m64bcst and place results in ymm1 subject to writemask k1.",
    "Shuffle 128-bit packed double-precision floating-point values selected by imm8 from zmm2 and zmm3/m512/m64bcst and place results in zmm1 subject to writemask k1. EVEX.NDS.256.66.0F3A.W0 43 /r ib VSHUFI32X4 ymm1{k1}{z}, ymm2, ymm3/m256/m32bcst, imm8 A V/V AVX512VL AVX512F Shuffle 128-bit packed double-word values selected by imm8 from ymm2 and ymm3/m256/m32bcst and place results in ymm1 subject to writemask k1.",
    "Shuffle 128-bit packed double-word values selected by imm8 from zmm2 and zmm3/m512/m32bcst and place results in zmm1 subject to writemask k1. EVEX.NDS.256.66.0F3A.W1 43 /r ib VSHUFI64X2 ymm1{k1}{z}, ymm2, ymm3/m256/m64bcst, imm8 A V/V AVX512VL AVX512F Shuffle 128-bit packed quad-word values selected by imm8 from ymm2 and ymm3/m256/m64bcst and place results in ymm1 subject to writemask k1.",
    "Shuffle 128-bit packed quad-word values selected by imm8 from zmm2 and zmm3/m512/m64bcst and place results in zmm1 subject to writemask k1.",
    "Set ZF and CF depending on sign bit AND and ANDN of packed single-precision floating-point sources.",
    "Set ZF and CF depending on sign bit AND and ANDN of packed single-precision floating-point sources.",
    "Set ZF and CF depending on sign bit AND and ANDN of packed double-precision floating-point sources.",
    "Set ZF and CF depending on sign bit AND and ANDN of packed double-precision floating-point sources.",
    "Zero all YMM registers.",
    "Zero upper 128 bits of all YMM registers.",
    "Check pending unmasked floating-point exceptions.",
    "Check pending unmasked floating-point exceptions.",
    "Write back and flush Internal caches; initiate writing-back and flushing of external caches.",
    "Load the FS base address with the 32-bit value in the source register.",
    "Load the FS base address with the 64-bit value in the source register.",
    "Load the GS base address with the 32-bit value in the source register.",
    "Load the GS base address with the 64-bit value in the source register.",
    "Write the value in EDX:EAX to MSR specified by ECX.",
    "Writes EAX into PKRU.",
    "Causes an RTM abort if in RTM execution",
    "A hint used with an “XACQUIRE-enabled“ instruction to start lock elision on the instruction memory operand address.",
    "A hint used with an “XRELEASE-enabled“ instruction to end lock elision on the instruction memory operand address.",
    "Exchange r8 and r/m8; load sum into r/m8.",
    "Exchange r8 and r/m8; load sum into r/m8.",
    "Exchange r16 and r/m16; load sum into r/m16.",
    "Exchange r32 and r/m32; load sum into r/m32.",
    "Exchange r64 and r/m64; load sum into r/m64.",
    "Specifies the start of an RTM region. Provides a 16-bit relative offset to compute the address of the fallback instruction address at which execution resumes following an RTM abort.",
    "Specifies the start of an RTM region. Provides a 32-bit relative offset to compute the address of the fallback instruction address at which execution resumes following an RTM abort.",
    "Exchange r16 with AX.",
    "Exchange AX with r16.",
    "Exchange r32 with EAX.",
    "Exchange r64 with RAX.",
    "Exchange EAX with r32.",
    "Exchange RAX with r64.",
    "Exchange r8 (byte register) with byte from r/m8.",
    "Exchange r8 (byte register) with byte from r/m8.",
    "Exchange byte from r/m8 with r8 (byte register).",
    "Exchange byte from r/m8 with r8 (byte register).",
    "Exchange r16 with word from r/m16.",
    "Exchange word from r/m16 with r16.",
    "Exchange r32 with doubleword from r/m32.",
    "Exchange r64 with quadword from r/m64.",
    "Exchange doubleword from r/m32 with r32.",
    "Exchange quadword from r/m64 with r64.",
    "Specifies the end of an RTM code region.",
    "Reads an XCR specified by ECX into EDX:EAX.",
    "Set AL to memory byte DS:[(E)BX + unsigned AL].",
    "Set AL to memory byte DS:[(E)BX + unsigned AL].",
    "Set AL to memory byte [RBX + unsigned AL].",
    "AL XOR imm8.",
    "AX XOR imm16.",
    "EAX XOR imm32.",
    "RAX XOR imm32 (sign-extended).",
    "r/m8 XOR imm8.",
    "r/m8 XOR imm8.",
    "r/m16 XOR imm16.",
    "r/m32 XOR imm32.",
    "r/m64 XOR imm32 (sign-extended).",
    "r/m16 XOR imm8 (sign-extended).",
    "r/m32 XOR imm8 (sign-extended).",
    "r/m64 XOR imm8 (sign-extended).",
    "r/m8 XOR r8.",
    "r/m8 XOR r8.",
    "r/m16 XOR r16.",
    "r/m32 XOR r32.",
    "r/m64 XOR r64.",
    "r8 XOR r/m8.",
    "r8 XOR r/m8.",
    "r16 XOR r/m16.",
    "r32 XOR r/m32.",
    "r64 XOR r/m64.",
    "Return the bitwise logical XOR of packed double-precision floating-point values in xmm1 and xmm2/mem.",
    "Return the bitwise logical XOR of packed double-precision floating-point values in xmm2 and xmm3/mem.",
    "Return the bitwise logical XOR of packed double-precision floating-point values in ymm2 and ymm3/mem.",
    "Return the bitwise logical XOR of packed double-precision floating-point values in xmm2 and xmm3/m128/m64bcst subject to writemask k1.",
    "Return the bitwise logical XOR of packed double-precision floating-point values in ymm2 and ymm3/m256/m64bcst subject to writemask k1.",
    "Return the bitwise logical XOR of packed double-precision floating-point values in zmm2 and zmm3/m512/m64bcst subject to writemask k1.",
    "Return the bitwise logical XOR of packed single-precision floating-point values in xmm1 and xmm2/mem.",
    "Return the bitwise logical XOR of packed single-precision floating-point values in xmm2 and xmm3/mem.",
    "Return the bitwise logical XOR of packed single-precision floating-point values in ymm2 and ymm3/mem.",
    "Return the bitwise logical XOR of packed single-precision floating-point values in xmm2 and xmm3/m128/m32bcst subject to writemask k1.",
    "Return the bitwise logical XOR of packed single-precision floating-point values in ymm2 and ymm3/m256/m32bcst subject to writemask k1.",
    "Return the bitwise logical XOR of packed single-precision floating-point values in zmm2 and zmm3/m512/m32bcst subject to writemask k1.",
    "Restore state components specified by EDX:EAX from mem.",
    "Restore state components specified by EDX:EAX from mem.",
    "Restore state components specified by EDX:EAX from mem.",
    "Restore state components specified by EDX:EAX from mem.",
    "Save state components specified by EDX:EAX to mem.",
    "Save state components specified by EDX:EAX to mem.",
    "Save state components specified by EDX:EAX to mem with compaction.",
    "Save state components specified by EDX:EAX to mem with compaction.",
    "Save state components specified by EDX:EAX to mem, optimizing if possible.",
    "Save state components specified by EDX:EAX to mem, optimizing if possible.",
    "Save state components specified by EDX:EAX to mem with compaction, optimizing if possible.",
    "Save state components specified by EDX:EAX to mem with compaction, optimizing if possible.",
    "Write the value in EDX:EAX to the XCR specified by ECX.",
    "Test if executing in a transactional region"
    ];

use super::instructions::{Instruction::*, InstructionOperand::*, InstructionVariation};
use super::registers::Register::*;

pub const VARIATIONS_TABLE: [InstructionVariation<'static>; INSTRUCTION_COUNT] = [
    InstructionVariation(AAA, &[]),
    InstructionVariation(AAD, &[]),
    InstructionVariation(AAD, &[Imm8]),
    InstructionVariation(AAM, &[]),
    InstructionVariation(AAM, &[Imm8]),
    InstructionVariation(AAS, &[]),
    InstructionVariation(ADC, &[SpecificRegister(AL), Imm8]),
    InstructionVariation(ADC, &[SpecificRegister(AX), Imm16]),
    InstructionVariation(ADC, &[SpecificRegister(EAX), Imm32]),
    InstructionVariation(ADC, &[SpecificRegister(RAX), Imm32]),
    InstructionVariation(ADC, &[RegOrMem8, Imm8]),
    InstructionVariation(ADC, &[RegOrMem8, Imm8]),
    InstructionVariation(ADC, &[RegOrMem16, Imm16]),
    InstructionVariation(ADC, &[RegOrMem32, Imm32]),
    InstructionVariation(ADC, &[RegOrMem64, Imm32]),
    InstructionVariation(ADC, &[RegOrMem16, Imm8]),
    InstructionVariation(ADC, &[RegOrMem32, Imm8]),
    InstructionVariation(ADC, &[RegOrMem64, Imm8]),
    InstructionVariation(ADC, &[RegOrMem8, Reg8]),
    InstructionVariation(ADC, &[RegOrMem8, Reg8]),
    InstructionVariation(ADC, &[RegOrMem16, Reg16]),
    InstructionVariation(ADC, &[RegOrMem32, Reg32]),
    InstructionVariation(ADC, &[RegOrMem64, Reg64]),
    InstructionVariation(ADC, &[Reg8, RegOrMem8]),
    InstructionVariation(ADC, &[Reg8, RegOrMem8]),
    InstructionVariation(ADC, &[Reg16, RegOrMem16]),
    InstructionVariation(ADC, &[Reg32, RegOrMem32]),
    InstructionVariation(ADC, &[Reg64, RegOrMem64]),
    InstructionVariation(ADCX, &[Reg32, RegOrMem32]),
    InstructionVariation(ADCX, &[Reg64, RegOrMem64]),
    InstructionVariation(ADD, &[SpecificRegister(AL), Imm8]),
    InstructionVariation(ADD, &[SpecificRegister(AX), Imm16]),
    InstructionVariation(ADD, &[SpecificRegister(EAX), Imm32]),
    InstructionVariation(ADD, &[SpecificRegister(RAX), Imm32]),
    InstructionVariation(ADD, &[RegOrMem8, Imm8]),
    InstructionVariation(ADD, &[RegOrMem8, Imm8]),
    InstructionVariation(ADD, &[RegOrMem16, Imm16]),
    InstructionVariation(ADD, &[RegOrMem32, Imm32]),
    InstructionVariation(ADD, &[RegOrMem64, Imm32]),
    InstructionVariation(ADD, &[RegOrMem16, Imm8]),
    InstructionVariation(ADD, &[RegOrMem32, Imm8]),
    InstructionVariation(ADD, &[RegOrMem64, Imm8]),
    InstructionVariation(ADD, &[RegOrMem8, Reg8]),
    InstructionVariation(ADD, &[RegOrMem8, Reg8]),
    InstructionVariation(ADD, &[RegOrMem16, Reg16]),
    InstructionVariation(ADD, &[RegOrMem32, Reg32]),
    InstructionVariation(ADD, &[RegOrMem64, Reg64]),
    InstructionVariation(ADD, &[Reg8, RegOrMem8]),
    InstructionVariation(ADD, &[Reg8, RegOrMem8]),
    InstructionVariation(ADD, &[Reg16, RegOrMem16]),
    InstructionVariation(ADD, &[Reg32, RegOrMem32]),
    InstructionVariation(ADD, &[Reg64, RegOrMem64]),
    InstructionVariation(
        ADDPD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VADDPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VADDPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VADDPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VADDPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VADDPD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        ADDPS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VADDPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VADDPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VADDPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VADDPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VADDPS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        ADDSD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem64(XMM2)],
    ),
    InstructionVariation(
        VADDSD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
        ],
    ),
    InstructionVariation(
        VADDSD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
        ],
    ),
    InstructionVariation(
        ADDSS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem32(XMM2)],
    ),
    InstructionVariation(
        VADDSS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(
        VADDSS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(
        ADDSUBPD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VADDSUBPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VADDSUBPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        ADDSUBPS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VADDSUBPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VADDSUBPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(ADOX, &[Reg32, RegOrMem32]),
    InstructionVariation(ADOX, &[Reg64, RegOrMem64]),
    InstructionVariation(
        AESDEC,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VAESDEC,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        AESDECLAST,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VAESDECLAST,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        AESENC,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VAESENC,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        AESENCLAST,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VAESENCLAST,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        AESIMC,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VAESIMC,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        AESKEYGENASSIST,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2), Imm8],
    ),
    InstructionVariation(
        VAESKEYGENASSIST,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2), Imm8],
    ),
    InstructionVariation(AND, &[SpecificRegister(AL), Imm8]),
    InstructionVariation(AND, &[SpecificRegister(AX), Imm16]),
    InstructionVariation(AND, &[SpecificRegister(EAX), Imm32]),
    InstructionVariation(AND, &[SpecificRegister(RAX), Imm32]),
    InstructionVariation(AND, &[RegOrMem8, Imm8]),
    InstructionVariation(AND, &[RegOrMem8, Imm8]),
    InstructionVariation(AND, &[RegOrMem16, Imm16]),
    InstructionVariation(AND, &[RegOrMem32, Imm32]),
    InstructionVariation(AND, &[RegOrMem64, Imm32]),
    InstructionVariation(AND, &[RegOrMem16, Imm8]),
    InstructionVariation(AND, &[RegOrMem32, Imm8]),
    InstructionVariation(AND, &[RegOrMem64, Imm8]),
    InstructionVariation(AND, &[RegOrMem8, Reg8]),
    InstructionVariation(AND, &[RegOrMem8, Reg8]),
    InstructionVariation(AND, &[RegOrMem16, Reg16]),
    InstructionVariation(AND, &[RegOrMem32, Reg32]),
    InstructionVariation(AND, &[RegOrMem64, Reg64]),
    InstructionVariation(AND, &[Reg8, RegOrMem8]),
    InstructionVariation(AND, &[Reg8, RegOrMem8]),
    InstructionVariation(AND, &[Reg16, RegOrMem16]),
    InstructionVariation(AND, &[Reg32, RegOrMem32]),
    InstructionVariation(AND, &[Reg64, RegOrMem64]),
    InstructionVariation(ANDN, &[Reg32a, Reg32b, RegOrMem32]),
    InstructionVariation(ANDN, &[Reg64a, Reg64b, RegOrMem64]),
    InstructionVariation(
        ANDNPD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VANDNPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VANDNPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VANDNPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VANDNPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VANDNPD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        ANDNPS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VANDNPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VANDNPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VANDNPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VANDNPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VANDNPS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        ANDPD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VANDPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VANDPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VANDPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VANDPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VANDPD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        ANDPS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VANDPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VANDPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VANDPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VANDPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VANDPS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(ARPL, &[RegOrMem16, Reg16]),
    InstructionVariation(BEXTR, &[Reg32a, RegOrMem32, Reg32b]),
    InstructionVariation(BEXTR, &[Reg64a, RegOrMem64, Reg64b]),
    InstructionVariation(
        BLENDPD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2), Imm8],
    ),
    InstructionVariation(
        VBLENDPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VBLENDPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        BLENDPS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2), Imm8],
    ),
    InstructionVariation(
        VBLENDPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VBLENDPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        BLENDVPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegisterOrMem128(XMM2),
            SpecificRegister(XMM0),
        ],
    ),
    InstructionVariation(
        VBLENDVPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
            SpecificRegister(XMM4),
        ],
    ),
    InstructionVariation(
        VBLENDVPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
            SpecificRegister(YMM4),
        ],
    ),
    InstructionVariation(
        BLENDVPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegisterOrMem128(XMM2),
            SpecificRegister(XMM0),
        ],
    ),
    InstructionVariation(
        VBLENDVPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
            SpecificRegister(XMM4),
        ],
    ),
    InstructionVariation(
        VBLENDVPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
            SpecificRegister(YMM4),
        ],
    ),
    InstructionVariation(BLSI, &[Reg32, RegOrMem32]),
    InstructionVariation(BLSI, &[Reg64, RegOrMem64]),
    InstructionVariation(BLSMSK, &[Reg32, RegOrMem32]),
    InstructionVariation(BLSMSK, &[Reg64, RegOrMem64]),
    InstructionVariation(BLSR, &[Reg32, RegOrMem32]),
    InstructionVariation(BLSR, &[Reg64, RegOrMem64]),
    InstructionVariation(BNDCL, &[Reg128BND, RegOrMem32]),
    InstructionVariation(BNDCL, &[Reg128BND, RegOrMem64]),
    InstructionVariation(BNDCU, &[Reg128BND, RegOrMem32]),
    InstructionVariation(BNDCU, &[Reg128BND, RegOrMem64]),
    InstructionVariation(BNDCN, &[Reg128BND, RegOrMem32]),
    InstructionVariation(BNDCN, &[Reg128BND, RegOrMem64]),
    InstructionVariation(BNDLDX, &[Reg128BND, Mib]),
    InstructionVariation(BNDMK, &[Reg128BND, Mem32]),
    InstructionVariation(BNDMK, &[Reg128BND, Mem64]),
    InstructionVariation(BNDMOV, &[SpecificRegister(BND1), SpecificRegister(BND2)]),
    InstructionVariation(
        BNDMOV,
        &[SpecificRegister(BND1), SpecificRegisterOrMem128(BND2)],
    ),
    InstructionVariation(BNDMOV, &[SpecificRegister(BND1), SpecificRegister(BND2)]),
    InstructionVariation(
        BNDMOV,
        &[SpecificRegisterOrMem128(BND1), SpecificRegister(BND2)],
    ),
    InstructionVariation(BNDSTX, &[Mib, Reg128BND]),
    InstructionVariation(BOUND, &[Reg16, Mem16]),
    InstructionVariation(BOUND, &[Reg32, Mem32]),
    InstructionVariation(BSF, &[Reg16, RegOrMem16]),
    InstructionVariation(BSF, &[Reg32, RegOrMem32]),
    InstructionVariation(BSF, &[Reg64, RegOrMem64]),
    InstructionVariation(BSR, &[Reg16, RegOrMem16]),
    InstructionVariation(BSR, &[Reg32, RegOrMem32]),
    InstructionVariation(BSR, &[Reg64, RegOrMem64]),
    InstructionVariation(BSWAP, &[Reg32]),
    InstructionVariation(BSWAP, &[Reg64]),
    InstructionVariation(BT, &[RegOrMem16, Reg16]),
    InstructionVariation(BT, &[RegOrMem32, Reg32]),
    InstructionVariation(BT, &[RegOrMem64, Reg64]),
    InstructionVariation(BT, &[RegOrMem16, Imm8]),
    InstructionVariation(BT, &[RegOrMem32, Imm8]),
    InstructionVariation(BT, &[RegOrMem64, Imm8]),
    InstructionVariation(BTC, &[RegOrMem16, Reg16]),
    InstructionVariation(BTC, &[RegOrMem32, Reg32]),
    InstructionVariation(BTC, &[RegOrMem64, Reg64]),
    InstructionVariation(BTC, &[RegOrMem16, Imm8]),
    InstructionVariation(BTC, &[RegOrMem32, Imm8]),
    InstructionVariation(BTC, &[RegOrMem64, Imm8]),
    InstructionVariation(BTR, &[RegOrMem16, Reg16]),
    InstructionVariation(BTR, &[RegOrMem32, Reg32]),
    InstructionVariation(BTR, &[RegOrMem64, Reg64]),
    InstructionVariation(BTR, &[RegOrMem16, Imm8]),
    InstructionVariation(BTR, &[RegOrMem32, Imm8]),
    InstructionVariation(BTR, &[RegOrMem64, Imm8]),
    InstructionVariation(BTS, &[RegOrMem16, Reg16]),
    InstructionVariation(BTS, &[RegOrMem32, Reg32]),
    InstructionVariation(BTS, &[RegOrMem64, Reg64]),
    InstructionVariation(BTS, &[RegOrMem16, Imm8]),
    InstructionVariation(BTS, &[RegOrMem32, Imm8]),
    InstructionVariation(BTS, &[RegOrMem64, Imm8]),
    InstructionVariation(BZHI, &[Reg32a, RegOrMem32, Reg32b]),
    InstructionVariation(BZHI, &[Reg64a, RegOrMem64, Reg64b]),
    InstructionVariation(CALL, &[Rel16]),
    InstructionVariation(CALL, &[Rel32]),
    InstructionVariation(CALL, &[RegOrMem16]),
    InstructionVariation(CALL, &[RegOrMem32]),
    InstructionVariation(CALL, &[RegOrMem64]),
    InstructionVariation(CALL, &[PtrReg16To16]),
    InstructionVariation(CALL, &[PtrReg16To32]),
    InstructionVariation(CALL, &[Mem16To16]),
    InstructionVariation(CALL, &[Mem16To32]),
    InstructionVariation(CALL, &[Mem16To64]),
    InstructionVariation(CBW, &[]),
    InstructionVariation(CWDE, &[]),
    InstructionVariation(CDQE, &[]),
    InstructionVariation(CLAC, &[]),
    InstructionVariation(CLC, &[]),
    InstructionVariation(CLD, &[]),
    InstructionVariation(CLFLUSH, &[Mem8]),
    InstructionVariation(CLFLUSHOPT, &[Mem8]),
    InstructionVariation(CLI, &[]),
    InstructionVariation(CLTS, &[]),
    InstructionVariation(CLWB, &[Mem8]),
    InstructionVariation(CMC, &[]),
    InstructionVariation(CMOVA, &[Reg16, RegOrMem16]),
    InstructionVariation(CMOVA, &[Reg32, RegOrMem32]),
    InstructionVariation(CMOVA, &[Reg64, RegOrMem64]),
    InstructionVariation(CMOVAE, &[Reg16, RegOrMem16]),
    InstructionVariation(CMOVAE, &[Reg32, RegOrMem32]),
    InstructionVariation(CMOVAE, &[Reg64, RegOrMem64]),
    InstructionVariation(CMOVB, &[Reg16, RegOrMem16]),
    InstructionVariation(CMOVB, &[Reg32, RegOrMem32]),
    InstructionVariation(CMOVB, &[Reg64, RegOrMem64]),
    InstructionVariation(CMOVBE, &[Reg16, RegOrMem16]),
    InstructionVariation(CMOVBE, &[Reg32, RegOrMem32]),
    InstructionVariation(CMOVBE, &[Reg64, RegOrMem64]),
    InstructionVariation(CMOVC, &[Reg16, RegOrMem16]),
    InstructionVariation(CMOVC, &[Reg32, RegOrMem32]),
    InstructionVariation(CMOVC, &[Reg64, RegOrMem64]),
    InstructionVariation(CMOVE, &[Reg16, RegOrMem16]),
    InstructionVariation(CMOVE, &[Reg32, RegOrMem32]),
    InstructionVariation(CMOVE, &[Reg64, RegOrMem64]),
    InstructionVariation(CMOVG, &[Reg16, RegOrMem16]),
    InstructionVariation(CMOVG, &[Reg32, RegOrMem32]),
    InstructionVariation(CMOVG, &[Reg64, RegOrMem64]),
    InstructionVariation(CMOVGE, &[Reg16, RegOrMem16]),
    InstructionVariation(CMOVGE, &[Reg32, RegOrMem32]),
    InstructionVariation(CMOVGE, &[Reg64, RegOrMem64]),
    InstructionVariation(CMOVL, &[Reg16, RegOrMem16]),
    InstructionVariation(CMOVL, &[Reg32, RegOrMem32]),
    InstructionVariation(CMOVL, &[Reg64, RegOrMem64]),
    InstructionVariation(CMOVLE, &[Reg16, RegOrMem16]),
    InstructionVariation(CMOVLE, &[Reg32, RegOrMem32]),
    InstructionVariation(CMOVLE, &[Reg64, RegOrMem64]),
    InstructionVariation(CMOVNA, &[Reg16, RegOrMem16]),
    InstructionVariation(CMOVNA, &[Reg32, RegOrMem32]),
    InstructionVariation(CMOVNA, &[Reg64, RegOrMem64]),
    InstructionVariation(CMOVNAE, &[Reg16, RegOrMem16]),
    InstructionVariation(CMOVNAE, &[Reg32, RegOrMem32]),
    InstructionVariation(CMOVNAE, &[Reg64, RegOrMem64]),
    InstructionVariation(CMOVNB, &[Reg16, RegOrMem16]),
    InstructionVariation(CMOVNB, &[Reg32, RegOrMem32]),
    InstructionVariation(CMOVNB, &[Reg64, RegOrMem64]),
    InstructionVariation(CMOVNBE, &[Reg16, RegOrMem16]),
    InstructionVariation(CMOVNBE, &[Reg32, RegOrMem32]),
    InstructionVariation(CMOVNBE, &[Reg64, RegOrMem64]),
    InstructionVariation(CMOVNC, &[Reg16, RegOrMem16]),
    InstructionVariation(CMOVNC, &[Reg32, RegOrMem32]),
    InstructionVariation(CMOVNC, &[Reg64, RegOrMem64]),
    InstructionVariation(CMOVNE, &[Reg16, RegOrMem16]),
    InstructionVariation(CMOVNE, &[Reg32, RegOrMem32]),
    InstructionVariation(CMOVNE, &[Reg64, RegOrMem64]),
    InstructionVariation(CMOVNG, &[Reg16, RegOrMem16]),
    InstructionVariation(CMOVNG, &[Reg32, RegOrMem32]),
    InstructionVariation(CMOVNG, &[Reg64, RegOrMem64]),
    InstructionVariation(CMOVNGE, &[Reg16, RegOrMem16]),
    InstructionVariation(CMOVNGE, &[Reg32, RegOrMem32]),
    InstructionVariation(CMOVNGE, &[Reg64, RegOrMem64]),
    InstructionVariation(CMOVNL, &[Reg16, RegOrMem16]),
    InstructionVariation(CMOVNL, &[Reg32, RegOrMem32]),
    InstructionVariation(CMOVNL, &[Reg64, RegOrMem64]),
    InstructionVariation(CMOVNLE, &[Reg16, RegOrMem16]),
    InstructionVariation(CMOVNLE, &[Reg32, RegOrMem32]),
    InstructionVariation(CMOVNLE, &[Reg64, RegOrMem64]),
    InstructionVariation(CMOVNO, &[Reg16, RegOrMem16]),
    InstructionVariation(CMOVNO, &[Reg32, RegOrMem32]),
    InstructionVariation(CMOVNO, &[Reg64, RegOrMem64]),
    InstructionVariation(CMOVNP, &[Reg16, RegOrMem16]),
    InstructionVariation(CMOVNP, &[Reg32, RegOrMem32]),
    InstructionVariation(CMOVNP, &[Reg64, RegOrMem64]),
    InstructionVariation(CMOVNS, &[Reg16, RegOrMem16]),
    InstructionVariation(CMOVNS, &[Reg32, RegOrMem32]),
    InstructionVariation(CMOVNS, &[Reg64, RegOrMem64]),
    InstructionVariation(CMOVNZ, &[Reg16, RegOrMem16]),
    InstructionVariation(CMOVNZ, &[Reg32, RegOrMem32]),
    InstructionVariation(CMOVNZ, &[Reg64, RegOrMem64]),
    InstructionVariation(CMOVO, &[Reg16, RegOrMem16]),
    InstructionVariation(CMOVO, &[Reg32, RegOrMem32]),
    InstructionVariation(CMOVO, &[Reg64, RegOrMem64]),
    InstructionVariation(CMOVP, &[Reg16, RegOrMem16]),
    InstructionVariation(CMOVP, &[Reg32, RegOrMem32]),
    InstructionVariation(CMOVP, &[Reg64, RegOrMem64]),
    InstructionVariation(CMOVPE, &[Reg16, RegOrMem16]),
    InstructionVariation(CMOVPE, &[Reg32, RegOrMem32]),
    InstructionVariation(CMOVPE, &[Reg64, RegOrMem64]),
    InstructionVariation(CMP, &[SpecificRegister(AL), Imm8]),
    InstructionVariation(CMP, &[SpecificRegister(AX), Imm16]),
    InstructionVariation(CMP, &[SpecificRegister(EAX), Imm32]),
    InstructionVariation(CMP, &[SpecificRegister(RAX), Imm32]),
    InstructionVariation(CMP, &[RegOrMem8, Imm8]),
    InstructionVariation(CMP, &[RegOrMem8, Imm8]),
    InstructionVariation(CMP, &[RegOrMem16, Imm16]),
    InstructionVariation(CMP, &[RegOrMem32, Imm32]),
    InstructionVariation(CMP, &[RegOrMem64, Imm32]),
    InstructionVariation(CMP, &[RegOrMem16, Imm8]),
    InstructionVariation(CMP, &[RegOrMem32, Imm8]),
    InstructionVariation(CMP, &[RegOrMem64, Imm8]),
    InstructionVariation(CMP, &[RegOrMem8, Reg8]),
    InstructionVariation(CMP, &[RegOrMem8, Reg8]),
    InstructionVariation(CMP, &[RegOrMem16, Reg16]),
    InstructionVariation(CMP, &[RegOrMem32, Reg32]),
    InstructionVariation(CMP, &[RegOrMem64, Reg64]),
    InstructionVariation(CMP, &[Reg8, RegOrMem8]),
    InstructionVariation(CMP, &[Reg8, RegOrMem8]),
    InstructionVariation(CMP, &[Reg16, RegOrMem16]),
    InstructionVariation(CMP, &[Reg32, RegOrMem32]),
    InstructionVariation(CMP, &[Reg64, RegOrMem64]),
    InstructionVariation(
        CMPPD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2), Imm8],
    ),
    InstructionVariation(
        VCMPPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VCMPPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VCMPPD,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VCMPPD,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VCMPPD,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        CMPPS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2), Imm8],
    ),
    InstructionVariation(
        VCMPPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VCMPPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VCMPPS,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VCMPPS,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VCMPPS,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
            Imm8,
        ],
    ),
    InstructionVariation(CMPS, &[Mem8, Mem8]),
    InstructionVariation(CMPS, &[Mem16, Mem16]),
    InstructionVariation(CMPS, &[Mem32, Mem32]),
    InstructionVariation(CMPS, &[Mem64, Mem64]),
    InstructionVariation(CMPSB, &[]),
    InstructionVariation(CMPSW, &[]),
    InstructionVariation(CMPSD, &[]),
    InstructionVariation(CMPSQ, &[]),
    InstructionVariation(
        CMPSD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem64(XMM2), Imm8],
    ),
    InstructionVariation(
        VCMPSD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VCMPSD,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        CMPSS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem32(XMM2), Imm8],
    ),
    InstructionVariation(
        VCMPSS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VCMPSS,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(CMPXCHG, &[RegOrMem8, Reg8]),
    InstructionVariation(CMPXCHG, &[RegOrMem8, Reg8]),
    InstructionVariation(CMPXCHG, &[RegOrMem16, Reg16]),
    InstructionVariation(CMPXCHG, &[RegOrMem32, Reg32]),
    InstructionVariation(CMPXCHG, &[RegOrMem64, Reg64]),
    InstructionVariation(CMPXCHG8B, &[Mem64]),
    InstructionVariation(CMPXCHG16B, &[Mem128]),
    InstructionVariation(
        COMISD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem64(XMM2)],
    ),
    InstructionVariation(
        VCOMISD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem64(XMM2)],
    ),
    InstructionVariation(
        VCOMISD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem64(XMM2)],
    ),
    InstructionVariation(
        COMISS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem32(XMM2)],
    ),
    InstructionVariation(
        VCOMISS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem32(XMM2)],
    ),
    InstructionVariation(
        VCOMISS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem32(XMM2)],
    ),
    InstructionVariation(CPUID, &[]),
    InstructionVariation(CRC32, &[Reg32, RegOrMem8]),
    InstructionVariation(CRC32, &[Reg32, RegOrMem8]),
    InstructionVariation(CRC32, &[Reg32, RegOrMem16]),
    InstructionVariation(CRC32, &[Reg32, RegOrMem32]),
    InstructionVariation(CRC32, &[Reg64, RegOrMem8]),
    InstructionVariation(CRC32, &[Reg64, RegOrMem64]),
    InstructionVariation(
        CVTDQ2PD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem64(XMM2)],
    ),
    InstructionVariation(
        VCVTDQ2PD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem64(XMM2)],
    ),
    InstructionVariation(
        VCVTDQ2PD,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VCVTDQ2PD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem32Bcst(XMM2),
        ],
    ),
    InstructionVariation(
        VCVTDQ2PD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem32Bcst(XMM2),
        ],
    ),
    InstructionVariation(
        VCVTDQ2PD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem32Bcst(YMM2),
        ],
    ),
    InstructionVariation(
        CVTDQ2PS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VCVTDQ2PS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VCVTDQ2PS,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem256(YMM2)],
    ),
    InstructionVariation(
        VCVTDQ2PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem32Bcst(XMM2),
        ],
    ),
    InstructionVariation(
        VCVTDQ2PS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem32Bcst(YMM2),
        ],
    ),
    InstructionVariation(
        VCVTDQ2PS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM2),
        ],
    ),
    InstructionVariation(
        CVTPD2DQ,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VCVTPD2DQ,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VCVTPD2DQ,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem256(YMM2)],
    ),
    InstructionVariation(
        VCVTPD2DQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem64Bcst(XMM2),
        ],
    ),
    InstructionVariation(
        VCVTPD2DQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem64Bcst(YMM2),
        ],
    ),
    InstructionVariation(
        VCVTPD2DQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM2),
        ],
    ),
    InstructionVariation(CVTPD2PI, &[Reg64MM, RegOrMem128]),
    InstructionVariation(
        CVTPD2PS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VCVTPD2PS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VCVTPD2PS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem256(YMM2)],
    ),
    InstructionVariation(
        VCVTPD2PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem64Bcst(XMM2),
        ],
    ),
    InstructionVariation(
        VCVTPD2PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem64Bcst(YMM2),
        ],
    ),
    InstructionVariation(
        VCVTPD2PS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM2),
        ],
    ),
    InstructionVariation(CVTPI2PD, &[Reg128, Reg64MMOrMem64]),
    InstructionVariation(CVTPI2PS, &[Reg128, Reg64MMOrMem64]),
    InstructionVariation(
        CVTPS2DQ,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VCVTPS2DQ,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VCVTPS2DQ,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem256(YMM2)],
    ),
    InstructionVariation(
        VCVTPS2DQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem32Bcst(XMM2),
        ],
    ),
    InstructionVariation(
        VCVTPS2DQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem32Bcst(YMM2),
        ],
    ),
    InstructionVariation(
        VCVTPS2DQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM2),
        ],
    ),
    InstructionVariation(
        CVTPS2PD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem64(XMM2)],
    ),
    InstructionVariation(
        VCVTPS2PD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem64(XMM2)],
    ),
    InstructionVariation(
        VCVTPS2PD,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VCVTPS2PD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem64OrMem32Bcst(XMM2),
        ],
    ),
    InstructionVariation(
        VCVTPS2PD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem32Bcst(XMM2),
        ],
    ),
    InstructionVariation(
        VCVTPS2PD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem32Bcst(YMM2),
        ],
    ),
    InstructionVariation(CVTPS2PI, &[Reg64MM, Reg128]),
    InstructionVariation(CVTSD2SI, &[Reg32, SpecificRegisterOrMem64(XMM1)]),
    InstructionVariation(CVTSD2SI, &[Reg64, SpecificRegisterOrMem64(XMM1)]),
    InstructionVariation(VCVTSD2SI, &[Reg32, SpecificRegisterOrMem64(XMM1)]),
    InstructionVariation(VCVTSD2SI, &[Reg64, SpecificRegisterOrMem64(XMM1)]),
    InstructionVariation(VCVTSD2SI, &[Reg32, SpecificRegisterOrMem64(XMM1)]),
    InstructionVariation(VCVTSD2SI, &[Reg64, SpecificRegisterOrMem64(XMM1)]),
    InstructionVariation(
        CVTSD2SS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem64(XMM2)],
    ),
    InstructionVariation(
        VCVTSD2SS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
        ],
    ),
    InstructionVariation(
        VCVTSD2SS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
        ],
    ),
    InstructionVariation(CVTSI2SD, &[SpecificRegister(XMM1), RegOrMem32]),
    InstructionVariation(CVTSI2SD, &[SpecificRegister(XMM1), RegOrMem64]),
    InstructionVariation(
        VCVTSI2SD,
        &[SpecificRegister(XMM1), SpecificRegister(XMM2), RegOrMem32],
    ),
    InstructionVariation(
        VCVTSI2SD,
        &[SpecificRegister(XMM1), SpecificRegister(XMM2), RegOrMem64],
    ),
    InstructionVariation(
        VCVTSI2SD,
        &[SpecificRegister(XMM1), SpecificRegister(XMM2), RegOrMem32],
    ),
    InstructionVariation(
        VCVTSI2SD,
        &[SpecificRegister(XMM1), SpecificRegister(XMM2), RegOrMem64],
    ),
    InstructionVariation(CVTSI2SS, &[SpecificRegister(XMM1), RegOrMem32]),
    InstructionVariation(CVTSI2SS, &[SpecificRegister(XMM1), RegOrMem64]),
    InstructionVariation(
        VCVTSI2SS,
        &[SpecificRegister(XMM1), SpecificRegister(XMM2), RegOrMem32],
    ),
    InstructionVariation(
        VCVTSI2SS,
        &[SpecificRegister(XMM1), SpecificRegister(XMM2), RegOrMem64],
    ),
    InstructionVariation(
        VCVTSI2SS,
        &[SpecificRegister(XMM1), SpecificRegister(XMM2), RegOrMem32],
    ),
    InstructionVariation(
        VCVTSI2SS,
        &[SpecificRegister(XMM1), SpecificRegister(XMM2), RegOrMem64],
    ),
    InstructionVariation(
        CVTSS2SD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem32(XMM2)],
    ),
    InstructionVariation(
        VCVTSS2SD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(
        VCVTSS2SD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(CVTSS2SI, &[Reg32, SpecificRegisterOrMem32(XMM1)]),
    InstructionVariation(CVTSS2SI, &[Reg64, SpecificRegisterOrMem32(XMM1)]),
    InstructionVariation(VCVTSS2SI, &[Reg32, SpecificRegisterOrMem32(XMM1)]),
    InstructionVariation(VCVTSS2SI, &[Reg64, SpecificRegisterOrMem32(XMM1)]),
    InstructionVariation(VCVTSS2SI, &[Reg32, SpecificRegisterOrMem32(XMM1)]),
    InstructionVariation(VCVTSS2SI, &[Reg64, SpecificRegisterOrMem32(XMM1)]),
    InstructionVariation(
        CVTTPD2DQ,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VCVTTPD2DQ,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VCVTTPD2DQ,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem256(YMM2)],
    ),
    InstructionVariation(
        VCVTTPD2DQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem64Bcst(XMM2),
        ],
    ),
    InstructionVariation(
        VCVTTPD2DQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem64Bcst(YMM2),
        ],
    ),
    InstructionVariation(
        VCVTTPD2DQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM2),
        ],
    ),
    InstructionVariation(CVTTPD2PI, &[Reg64MM, RegOrMem128]),
    InstructionVariation(
        CVTTPS2DQ,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VCVTTPS2DQ,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VCVTTPS2DQ,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem256(YMM2)],
    ),
    InstructionVariation(
        VCVTTPS2DQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem64Bcst(XMM2),
        ],
    ),
    InstructionVariation(
        VCVTTPS2DQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem64Bcst(YMM2),
        ],
    ),
    InstructionVariation(
        VCVTTPS2DQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM2),
        ],
    ),
    InstructionVariation(CVTTPS2PI, &[Reg64MM, Reg128]),
    InstructionVariation(CVTTSD2SI, &[Reg32, SpecificRegisterOrMem64(XMM1)]),
    InstructionVariation(CVTTSD2SI, &[Reg64, SpecificRegisterOrMem64(XMM1)]),
    InstructionVariation(VCVTTSD2SI, &[Reg32, SpecificRegisterOrMem64(XMM1)]),
    InstructionVariation(VCVTTSD2SI, &[Reg64, SpecificRegisterOrMem64(XMM1)]),
    InstructionVariation(VCVTTSD2SI, &[Reg32, SpecificRegisterOrMem64(XMM1)]),
    InstructionVariation(VCVTTSD2SI, &[Reg64, SpecificRegisterOrMem64(XMM1)]),
    InstructionVariation(CVTTSS2SI, &[Reg32, SpecificRegisterOrMem32(XMM1)]),
    InstructionVariation(CVTTSS2SI, &[Reg64, SpecificRegisterOrMem32(XMM1)]),
    InstructionVariation(VCVTTSS2SI, &[Reg32, SpecificRegisterOrMem32(XMM1)]),
    InstructionVariation(VCVTTSS2SI, &[Reg64, SpecificRegisterOrMem32(XMM1)]),
    InstructionVariation(VCVTTSS2SI, &[Reg32, SpecificRegisterOrMem32(XMM1)]),
    InstructionVariation(VCVTTSS2SI, &[Reg64, SpecificRegisterOrMem32(XMM1)]),
    InstructionVariation(CWD, &[]),
    InstructionVariation(CDQ, &[]),
    InstructionVariation(CQO, &[]),
    InstructionVariation(DAA, &[]),
    InstructionVariation(DAS, &[]),
    InstructionVariation(DEC, &[RegOrMem8]),
    InstructionVariation(DEC, &[RegOrMem8]),
    InstructionVariation(DEC, &[RegOrMem16]),
    InstructionVariation(DEC, &[RegOrMem32]),
    InstructionVariation(DEC, &[RegOrMem64]),
    InstructionVariation(DEC, &[Reg16]),
    InstructionVariation(DEC, &[Reg32]),
    InstructionVariation(DIV, &[RegOrMem8]),
    InstructionVariation(DIV, &[RegOrMem8]),
    InstructionVariation(DIV, &[RegOrMem16]),
    InstructionVariation(DIV, &[RegOrMem32]),
    InstructionVariation(DIV, &[RegOrMem64]),
    InstructionVariation(
        DIVPD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VDIVPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VDIVPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VDIVPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VDIVPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VDIVPD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        DIVPS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VDIVPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VDIVPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VDIVPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VDIVPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VDIVPS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        DIVSD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem64(XMM2)],
    ),
    InstructionVariation(
        VDIVSD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
        ],
    ),
    InstructionVariation(
        VDIVSD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
        ],
    ),
    InstructionVariation(
        DIVSS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem32(XMM2)],
    ),
    InstructionVariation(
        VDIVSS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(
        VDIVSS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(
        DPPD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2), Imm8],
    ),
    InstructionVariation(
        VDPPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        DPPS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2), Imm8],
    ),
    InstructionVariation(
        VDPPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VDPPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
            Imm8,
        ],
    ),
    InstructionVariation(EMMS, &[]),
    InstructionVariation(ENTER, &[Imm16]),
    InstructionVariation(ENTER, &[Imm16]),
    InstructionVariation(ENTER, &[Imm16, Imm8]),
    InstructionVariation(EXTRACTPS, &[RegOrMem32, SpecificRegister(XMM1), Imm8]),
    InstructionVariation(VEXTRACTPS, &[RegOrMem32, SpecificRegister(XMM1), Imm8]),
    InstructionVariation(VEXTRACTPS, &[RegOrMem32, SpecificRegister(XMM1), Imm8]),
    InstructionVariation(F2XM1, &[]),
    InstructionVariation(FABS, &[]),
    InstructionVariation(FADD, &[Mem32Fp]),
    InstructionVariation(FADD, &[Mem64Fp]),
    InstructionVariation(FADD, &[SpecificRegister(ST0), Reg80]),
    InstructionVariation(FADD, &[Reg80, SpecificRegister(ST0)]),
    InstructionVariation(FADDP, &[Reg80, SpecificRegister(ST0)]),
    InstructionVariation(FADDP, &[]),
    InstructionVariation(FIADD, &[Mem32Int]),
    InstructionVariation(FIADD, &[Mem16Int]),
    InstructionVariation(FBLD, &[Mem80Dec]),
    InstructionVariation(FBSTP, &[Mem80Bcd]),
    InstructionVariation(FCHS, &[]),
    InstructionVariation(FCLEX, &[]),
    InstructionVariation(FNCLEX, &[]),
    InstructionVariation(FCMOVB, &[SpecificRegister(ST0), Reg80]),
    InstructionVariation(FCMOVE, &[SpecificRegister(ST0), Reg80]),
    InstructionVariation(FCMOVBE, &[SpecificRegister(ST0), Reg80]),
    InstructionVariation(FCMOVU, &[SpecificRegister(ST0), Reg80]),
    InstructionVariation(FCMOVNB, &[SpecificRegister(ST0), Reg80]),
    InstructionVariation(FCMOVNE, &[SpecificRegister(ST0), Reg80]),
    InstructionVariation(FCMOVNBE, &[SpecificRegister(ST0), Reg80]),
    InstructionVariation(FCMOVNU, &[SpecificRegister(ST0), Reg80]),
    InstructionVariation(FCOM, &[Mem32Fp]),
    InstructionVariation(FCOM, &[Mem64Fp]),
    InstructionVariation(FCOM, &[Reg80]),
    InstructionVariation(FCOM, &[]),
    InstructionVariation(FCOMP, &[Mem32Fp]),
    InstructionVariation(FCOMP, &[Mem64Fp]),
    InstructionVariation(FCOMP, &[Reg80]),
    InstructionVariation(FCOMP, &[]),
    InstructionVariation(FCOMPP, &[]),
    InstructionVariation(FCOMI, &[Reg80, Reg80]),
    InstructionVariation(FCOMIP, &[Reg80, Reg80]),
    InstructionVariation(FUCOMI, &[Reg80, Reg80]),
    InstructionVariation(FUCOMIP, &[Reg80, Reg80]),
    InstructionVariation(FCOS, &[]),
    InstructionVariation(FDECSTP, &[]),
    InstructionVariation(FDIV, &[Mem32Fp]),
    InstructionVariation(FDIV, &[Mem64Fp]),
    InstructionVariation(FDIV, &[SpecificRegister(ST0), Reg80]),
    InstructionVariation(FDIV, &[Reg80, SpecificRegister(ST0)]),
    InstructionVariation(FDIVP, &[Reg80, SpecificRegister(ST0)]),
    InstructionVariation(FDIVP, &[]),
    InstructionVariation(FIDIV, &[Mem32Int]),
    InstructionVariation(FIDIV, &[Mem16Int]),
    InstructionVariation(FDIVR, &[Mem32Fp]),
    InstructionVariation(FDIVR, &[Mem64Fp]),
    InstructionVariation(FDIVR, &[SpecificRegister(ST0), Reg80]),
    InstructionVariation(FDIVR, &[Reg80, SpecificRegister(ST0)]),
    InstructionVariation(FDIVRP, &[Reg80, SpecificRegister(ST0)]),
    InstructionVariation(FDIVRP, &[]),
    InstructionVariation(FIDIVR, &[Mem32Int]),
    InstructionVariation(FIDIVR, &[Mem16Int]),
    InstructionVariation(FFREE, &[Reg80]),
    InstructionVariation(FICOM, &[Mem16Int]),
    InstructionVariation(FICOM, &[Mem32Int]),
    InstructionVariation(FICOMP, &[Mem16Int]),
    InstructionVariation(FICOMP, &[Mem32Int]),
    InstructionVariation(FILD, &[Mem16Int]),
    InstructionVariation(FILD, &[Mem32Int]),
    InstructionVariation(FILD, &[Mem64Int]),
    InstructionVariation(FINCSTP, &[]),
    InstructionVariation(FINIT, &[]),
    InstructionVariation(FNINIT, &[]),
    InstructionVariation(FIST, &[Mem16Int]),
    InstructionVariation(FIST, &[Mem32Int]),
    InstructionVariation(FISTP, &[Mem16Int]),
    InstructionVariation(FISTP, &[Mem32Int]),
    InstructionVariation(FISTP, &[Mem64Int]),
    InstructionVariation(FISTTP, &[Mem16Int]),
    InstructionVariation(FISTTP, &[Mem32Int]),
    InstructionVariation(FISTTP, &[Mem64Int]),
    InstructionVariation(FLD, &[Mem32Fp]),
    InstructionVariation(FLD, &[Mem64Fp]),
    InstructionVariation(FLD, &[Mem80Fp]),
    InstructionVariation(FLD, &[Reg80]),
    InstructionVariation(FLD1, &[]),
    InstructionVariation(FLDL2T, &[]),
    InstructionVariation(FLDL2E, &[]),
    InstructionVariation(FLDPI, &[]),
    InstructionVariation(FLDLG2, &[]),
    InstructionVariation(FLDLN2, &[]),
    InstructionVariation(FLDZ, &[]),
    InstructionVariation(FLDCW, &[Mem2Byte]),
    InstructionVariation(FLDENV, &[Mem14Or28Byte]),
    InstructionVariation(FMUL, &[Mem32Fp]),
    InstructionVariation(FMUL, &[Mem64Fp]),
    InstructionVariation(FMUL, &[SpecificRegister(ST0), Reg80]),
    InstructionVariation(FMUL, &[Reg80, SpecificRegister(ST0)]),
    InstructionVariation(FMULP, &[Reg80, SpecificRegister(ST0)]),
    InstructionVariation(FMULP, &[]),
    InstructionVariation(FIMUL, &[Mem32Int]),
    InstructionVariation(FIMUL, &[Mem16Int]),
    InstructionVariation(FNOP, &[]),
    InstructionVariation(FPATAN, &[]),
    InstructionVariation(FPREM, &[]),
    InstructionVariation(FPREM1, &[]),
    InstructionVariation(FPTAN, &[]),
    InstructionVariation(FRNDINT, &[]),
    InstructionVariation(FRSTOR, &[Mem94Or108Byte]),
    InstructionVariation(FSAVE, &[Mem94Or108Byte]),
    InstructionVariation(FNSAVE, &[Mem94Or108Byte]),
    InstructionVariation(FSCALE, &[]),
    InstructionVariation(FSIN, &[]),
    InstructionVariation(FSINCOS, &[]),
    InstructionVariation(FSQRT, &[]),
    InstructionVariation(FST, &[Mem32Fp]),
    InstructionVariation(FST, &[Mem64Fp]),
    InstructionVariation(FST, &[Reg80]),
    InstructionVariation(FSTP, &[Mem32Fp]),
    InstructionVariation(FSTP, &[Mem64Fp]),
    InstructionVariation(FSTP, &[Mem80Fp]),
    InstructionVariation(FSTP, &[Reg80]),
    InstructionVariation(FSTCW, &[Mem2Byte]),
    InstructionVariation(FNSTCW, &[Mem2Byte]),
    InstructionVariation(FSTENV, &[Mem14Or28Byte]),
    InstructionVariation(FNSTENV, &[Mem14Or28Byte]),
    InstructionVariation(FSTSW, &[Mem2Byte]),
    InstructionVariation(FSTSW, &[SpecificRegister(AX)]),
    InstructionVariation(FNSTSW, &[Mem2Byte]),
    InstructionVariation(FNSTSW, &[SpecificRegister(AX)]),
    InstructionVariation(FSUB, &[Mem32Fp]),
    InstructionVariation(FSUB, &[Mem64Fp]),
    InstructionVariation(FSUB, &[SpecificRegister(ST0), Reg80]),
    InstructionVariation(FSUB, &[Reg80, SpecificRegister(ST0)]),
    InstructionVariation(FSUBP, &[Reg80, SpecificRegister(ST0)]),
    InstructionVariation(FSUBP, &[]),
    InstructionVariation(FISUB, &[Mem32Int]),
    InstructionVariation(FISUB, &[Mem16Int]),
    InstructionVariation(FSUBR, &[Mem32Fp]),
    InstructionVariation(FSUBR, &[Mem64Fp]),
    InstructionVariation(FSUBR, &[SpecificRegister(ST0), Reg80]),
    InstructionVariation(FSUBR, &[Reg80, SpecificRegister(ST0)]),
    InstructionVariation(FSUBRP, &[Reg80, SpecificRegister(ST0)]),
    InstructionVariation(FSUBRP, &[]),
    InstructionVariation(FISUBR, &[Mem32Int]),
    InstructionVariation(FISUBR, &[Mem16Int]),
    InstructionVariation(FTST, &[]),
    InstructionVariation(FUCOM, &[Reg80]),
    InstructionVariation(FUCOM, &[]),
    InstructionVariation(FUCOMP, &[Reg80]),
    InstructionVariation(FUCOMP, &[]),
    InstructionVariation(FUCOMPP, &[]),
    InstructionVariation(FXAM, &[]),
    InstructionVariation(FXCH, &[Reg80]),
    InstructionVariation(FXCH, &[]),
    InstructionVariation(FXRSTOR, &[Mem512Byte]),
    InstructionVariation(FXRSTOR64, &[Mem512Byte]),
    InstructionVariation(FXSAVE, &[Mem512Byte]),
    InstructionVariation(FXSAVE64, &[Mem512Byte]),
    InstructionVariation(FXTRACT, &[]),
    InstructionVariation(FYL2X, &[]),
    InstructionVariation(FYL2XP1, &[]),
    InstructionVariation(
        HADDPD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VHADDPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VHADDPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        HADDPS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VHADDPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VHADDPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(HLT, &[]),
    InstructionVariation(
        HSUBPD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VHSUBPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VHSUBPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        HSUBPS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VHSUBPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VHSUBPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(IDIV, &[RegOrMem8]),
    InstructionVariation(IDIV, &[RegOrMem8]),
    InstructionVariation(IDIV, &[RegOrMem16]),
    InstructionVariation(IDIV, &[RegOrMem32]),
    InstructionVariation(IDIV, &[RegOrMem64]),
    InstructionVariation(IMUL, &[RegOrMem8]),
    InstructionVariation(IMUL, &[RegOrMem16]),
    InstructionVariation(IMUL, &[RegOrMem32]),
    InstructionVariation(IMUL, &[RegOrMem64]),
    InstructionVariation(IMUL, &[Reg16, RegOrMem16]),
    InstructionVariation(IMUL, &[Reg32, RegOrMem32]),
    InstructionVariation(IMUL, &[Reg64, RegOrMem64]),
    InstructionVariation(IMUL, &[Reg16, RegOrMem16, Imm8]),
    InstructionVariation(IMUL, &[Reg32, RegOrMem32, Imm8]),
    InstructionVariation(IMUL, &[Reg64, RegOrMem64, Imm8]),
    InstructionVariation(IMUL, &[Reg16, RegOrMem16, Imm16]),
    InstructionVariation(IMUL, &[Reg32, RegOrMem32, Imm32]),
    InstructionVariation(IMUL, &[Reg64, RegOrMem64, Imm32]),
    InstructionVariation(IN, &[SpecificRegister(AL), Imm8]),
    InstructionVariation(IN, &[SpecificRegister(AX), Imm8]),
    InstructionVariation(IN, &[SpecificRegister(EAX), Imm8]),
    InstructionVariation(IN, &[SpecificRegister(AL), SpecificRegister(DX)]),
    InstructionVariation(IN, &[SpecificRegister(AX), SpecificRegister(DX)]),
    InstructionVariation(IN, &[SpecificRegister(EAX), SpecificRegister(DX)]),
    InstructionVariation(INC, &[RegOrMem8]),
    InstructionVariation(INC, &[RegOrMem8]),
    InstructionVariation(INC, &[RegOrMem16]),
    InstructionVariation(INC, &[RegOrMem32]),
    InstructionVariation(INC, &[RegOrMem64]),
    InstructionVariation(INC, &[Reg16]),
    InstructionVariation(INC, &[Reg32]),
    InstructionVariation(INS, &[Mem8, SpecificRegister(DX)]),
    InstructionVariation(INS, &[Mem16, SpecificRegister(DX)]),
    InstructionVariation(INS, &[Mem32, SpecificRegister(DX)]),
    InstructionVariation(INSB, &[]),
    InstructionVariation(INSW, &[]),
    InstructionVariation(INSD, &[]),
    InstructionVariation(
        INSERTPS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem32(XMM2), Imm8],
    ),
    InstructionVariation(
        VINSERTPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VINSERTPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(INT, &[Imm8]),
    InstructionVariation(INTO, &[]),
    InstructionVariation(INVD, &[]),
    InstructionVariation(INVLPG, &[Mem]),
    InstructionVariation(INVPCID, &[Reg32, Mem128]),
    InstructionVariation(INVPCID, &[Reg64, Mem128]),
    InstructionVariation(IRET, &[]),
    InstructionVariation(IRETD, &[]),
    InstructionVariation(IRETQ, &[]),
    InstructionVariation(JA, &[Rel8]),
    InstructionVariation(JAE, &[Rel8]),
    InstructionVariation(JB, &[Rel8]),
    InstructionVariation(JBE, &[Rel8]),
    InstructionVariation(JC, &[Rel8]),
    InstructionVariation(JCXZ, &[Rel8]),
    InstructionVariation(JECXZ, &[Rel8]),
    InstructionVariation(JRCXZ, &[Rel8]),
    InstructionVariation(JE, &[Rel8]),
    InstructionVariation(JG, &[Rel8]),
    InstructionVariation(JGE, &[Rel8]),
    InstructionVariation(JL, &[Rel8]),
    InstructionVariation(JLE, &[Rel8]),
    InstructionVariation(JNA, &[Rel8]),
    InstructionVariation(JNAE, &[Rel8]),
    InstructionVariation(JNB, &[Rel8]),
    InstructionVariation(JNBE, &[Rel8]),
    InstructionVariation(JNC, &[Rel8]),
    InstructionVariation(JNE, &[Rel8]),
    InstructionVariation(JNG, &[Rel8]),
    InstructionVariation(JNGE, &[Rel8]),
    InstructionVariation(JNL, &[Rel8]),
    InstructionVariation(JNLE, &[Rel8]),
    InstructionVariation(JNO, &[Rel8]),
    InstructionVariation(JNP, &[Rel8]),
    InstructionVariation(JNS, &[Rel8]),
    InstructionVariation(JNZ, &[Rel8]),
    InstructionVariation(JO, &[Rel8]),
    InstructionVariation(JP, &[Rel8]),
    InstructionVariation(JPE, &[Rel8]),
    InstructionVariation(JPO, &[Rel8]),
    InstructionVariation(JS, &[Rel8]),
    InstructionVariation(JZ, &[Rel8]),
    InstructionVariation(JA, &[Rel16]),
    InstructionVariation(JA, &[Rel32]),
    InstructionVariation(JAE, &[Rel16]),
    InstructionVariation(JAE, &[Rel32]),
    InstructionVariation(JB, &[Rel16]),
    InstructionVariation(JB, &[Rel32]),
    InstructionVariation(JBE, &[Rel16]),
    InstructionVariation(JBE, &[Rel32]),
    InstructionVariation(JC, &[Rel16]),
    InstructionVariation(JC, &[Rel32]),
    InstructionVariation(JE, &[Rel16]),
    InstructionVariation(JE, &[Rel32]),
    InstructionVariation(JZ, &[Rel16]),
    InstructionVariation(JZ, &[Rel32]),
    InstructionVariation(JG, &[Rel16]),
    InstructionVariation(JG, &[Rel32]),
    InstructionVariation(JGE, &[Rel16]),
    InstructionVariation(JGE, &[Rel32]),
    InstructionVariation(JL, &[Rel16]),
    InstructionVariation(JL, &[Rel32]),
    InstructionVariation(JLE, &[Rel16]),
    InstructionVariation(JLE, &[Rel32]),
    InstructionVariation(JNA, &[Rel16]),
    InstructionVariation(JNA, &[Rel32]),
    InstructionVariation(JNAE, &[Rel16]),
    InstructionVariation(JNAE, &[Rel32]),
    InstructionVariation(JNB, &[Rel16]),
    InstructionVariation(JNB, &[Rel32]),
    InstructionVariation(JNBE, &[Rel16]),
    InstructionVariation(JNBE, &[Rel32]),
    InstructionVariation(JNC, &[Rel16]),
    InstructionVariation(JNC, &[Rel32]),
    InstructionVariation(JNE, &[Rel16]),
    InstructionVariation(JNE, &[Rel32]),
    InstructionVariation(JNG, &[Rel16]),
    InstructionVariation(JNG, &[Rel32]),
    InstructionVariation(JNGE, &[Rel16]),
    InstructionVariation(JNGE, &[Rel32]),
    InstructionVariation(JNL, &[Rel16]),
    InstructionVariation(JNL, &[Rel32]),
    InstructionVariation(JNLE, &[Rel16]),
    InstructionVariation(JNLE, &[Rel32]),
    InstructionVariation(JNO, &[Rel16]),
    InstructionVariation(JNO, &[Rel32]),
    InstructionVariation(JNP, &[Rel16]),
    InstructionVariation(JNP, &[Rel32]),
    InstructionVariation(JNS, &[Rel16]),
    InstructionVariation(JNS, &[Rel32]),
    InstructionVariation(JNZ, &[Rel16]),
    InstructionVariation(JNZ, &[Rel32]),
    InstructionVariation(JO, &[Rel16]),
    InstructionVariation(JO, &[Rel32]),
    InstructionVariation(JP, &[Rel16]),
    InstructionVariation(JP, &[Rel32]),
    InstructionVariation(JPE, &[Rel16]),
    InstructionVariation(JPE, &[Rel32]),
    InstructionVariation(JPO, &[Rel16]),
    InstructionVariation(JPO, &[Rel32]),
    InstructionVariation(JS, &[Rel16]),
    InstructionVariation(JMP, &[Rel8]),
    InstructionVariation(JMP, &[Rel16]),
    InstructionVariation(JMP, &[Rel32]),
    InstructionVariation(JMP, &[RegOrMem16]),
    InstructionVariation(JMP, &[RegOrMem32]),
    InstructionVariation(JMP, &[RegOrMem64]),
    InstructionVariation(JMP, &[PtrReg16To16]),
    InstructionVariation(JMP, &[PtrReg16To32]),
    InstructionVariation(JMP, &[Mem16To16]),
    InstructionVariation(JMP, &[Mem16To32]),
    InstructionVariation(JMP, &[Mem16To64]),
    InstructionVariation(
        KADDW,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(K3),
        ],
    ),
    InstructionVariation(
        KADDB,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(K3),
        ],
    ),
    InstructionVariation(
        KADDQ,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(K3),
        ],
    ),
    InstructionVariation(
        KADDD,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(K3),
        ],
    ),
    InstructionVariation(
        KANDNW,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(K3),
        ],
    ),
    InstructionVariation(
        KANDNB,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(K3),
        ],
    ),
    InstructionVariation(
        KANDNQ,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(K3),
        ],
    ),
    InstructionVariation(
        KANDND,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(K3),
        ],
    ),
    InstructionVariation(
        KANDW,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(K3),
        ],
    ),
    InstructionVariation(
        KANDB,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(K3),
        ],
    ),
    InstructionVariation(
        KANDQ,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(K3),
        ],
    ),
    InstructionVariation(
        KANDD,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(K3),
        ],
    ),
    InstructionVariation(KMOVW, &[SpecificRegister(K1), SpecificRegisterOrMem16(K2)]),
    InstructionVariation(KMOVB, &[SpecificRegister(K1), SpecificRegisterOrMem8(K2)]),
    InstructionVariation(KMOVQ, &[SpecificRegister(K1), SpecificRegister(K2)]),
    InstructionVariation(KMOVD, &[SpecificRegister(K1), SpecificRegisterOrMem32(K2)]),
    InstructionVariation(KMOVW, &[Mem16, SpecificRegister(K1)]),
    InstructionVariation(KMOVB, &[Mem8, SpecificRegister(K1)]),
    InstructionVariation(KMOVQ, &[Mem64, SpecificRegister(K1)]),
    InstructionVariation(KMOVD, &[Mem32, SpecificRegister(K1)]),
    InstructionVariation(KMOVW, &[SpecificRegister(K1), Reg32]),
    InstructionVariation(KMOVB, &[SpecificRegister(K1), Reg32]),
    InstructionVariation(KMOVQ, &[SpecificRegister(K1), Reg64]),
    InstructionVariation(KMOVD, &[SpecificRegister(K1), Reg32]),
    InstructionVariation(KMOVW, &[Reg32, SpecificRegister(K1)]),
    InstructionVariation(KMOVB, &[Reg32, SpecificRegister(K1)]),
    InstructionVariation(KMOVQ, &[Reg64, SpecificRegister(K1)]),
    InstructionVariation(KMOVD, &[Reg32, SpecificRegister(K1)]),
    InstructionVariation(KNOTW, &[SpecificRegister(K1), SpecificRegister(K2)]),
    InstructionVariation(KNOTB, &[SpecificRegister(K1), SpecificRegister(K2)]),
    InstructionVariation(KNOTQ, &[SpecificRegister(K1), SpecificRegister(K2)]),
    InstructionVariation(KNOTD, &[SpecificRegister(K1), SpecificRegister(K2)]),
    InstructionVariation(KORTESTW, &[SpecificRegister(K1), SpecificRegister(K2)]),
    InstructionVariation(KORTESTB, &[SpecificRegister(K1), SpecificRegister(K2)]),
    InstructionVariation(KORTESTQ, &[SpecificRegister(K1), SpecificRegister(K2)]),
    InstructionVariation(KORTESTD, &[SpecificRegister(K1), SpecificRegister(K2)]),
    InstructionVariation(
        KORW,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(K3),
        ],
    ),
    InstructionVariation(
        KORB,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(K3),
        ],
    ),
    InstructionVariation(
        KORQ,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(K3),
        ],
    ),
    InstructionVariation(
        KORD,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(K3),
        ],
    ),
    InstructionVariation(
        KSHIFTLW,
        &[SpecificRegister(K1), SpecificRegister(K2), Imm8],
    ),
    InstructionVariation(
        KSHIFTLB,
        &[SpecificRegister(K1), SpecificRegister(K2), Imm8],
    ),
    InstructionVariation(
        KSHIFTLQ,
        &[SpecificRegister(K1), SpecificRegister(K2), Imm8],
    ),
    InstructionVariation(
        KSHIFTLD,
        &[SpecificRegister(K1), SpecificRegister(K2), Imm8],
    ),
    InstructionVariation(
        KSHIFTRW,
        &[SpecificRegister(K1), SpecificRegister(K2), Imm8],
    ),
    InstructionVariation(
        KSHIFTRB,
        &[SpecificRegister(K1), SpecificRegister(K2), Imm8],
    ),
    InstructionVariation(
        KSHIFTRQ,
        &[SpecificRegister(K1), SpecificRegister(K2), Imm8],
    ),
    InstructionVariation(
        KSHIFTRD,
        &[SpecificRegister(K1), SpecificRegister(K2), Imm8],
    ),
    InstructionVariation(KTESTW, &[SpecificRegister(K1), SpecificRegister(K2)]),
    InstructionVariation(KTESTB, &[SpecificRegister(K1), SpecificRegister(K2)]),
    InstructionVariation(KTESTQ, &[SpecificRegister(K1), SpecificRegister(K2)]),
    InstructionVariation(KTESTD, &[SpecificRegister(K1), SpecificRegister(K2)]),
    InstructionVariation(
        KUNPCKBW,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(K3),
        ],
    ),
    InstructionVariation(
        KUNPCKWD,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(K3),
        ],
    ),
    InstructionVariation(
        KUNPCKDQ,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(K3),
        ],
    ),
    InstructionVariation(
        KXNORW,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(K3),
        ],
    ),
    InstructionVariation(
        KXNORB,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(K3),
        ],
    ),
    InstructionVariation(
        KXNORQ,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(K3),
        ],
    ),
    InstructionVariation(
        KXNORD,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(K3),
        ],
    ),
    InstructionVariation(
        KXORW,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(K3),
        ],
    ),
    InstructionVariation(
        KXORB,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(K3),
        ],
    ),
    InstructionVariation(
        KXORQ,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(K3),
        ],
    ),
    InstructionVariation(
        KXORD,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(K3),
        ],
    ),
    InstructionVariation(LAHF, &[]),
    InstructionVariation(LAR, &[Reg16, RegOrMem16]),
    InstructionVariation(LAR, &[AnyRegister, Reg32OrMem16]),
    InstructionVariation(LDDQU, &[SpecificRegister(XMM1), Mem]),
    InstructionVariation(VLDDQU, &[SpecificRegister(XMM1), Mem128]),
    InstructionVariation(VLDDQU, &[SpecificRegister(YMM1), Mem256]),
    InstructionVariation(LDMXCSR, &[Mem32]),
    InstructionVariation(VLDMXCSR, &[Mem32]),
    InstructionVariation(LDS, &[Reg16, Mem16To16]),
    InstructionVariation(LDS, &[Reg32, Mem16To32]),
    InstructionVariation(LSS, &[Reg16, Mem16To16]),
    InstructionVariation(LSS, &[Reg32, Mem16To32]),
    InstructionVariation(LSS, &[Reg64, Mem16To64]),
    InstructionVariation(LES, &[Reg16, Mem16To16]),
    InstructionVariation(LES, &[Reg32, Mem16To32]),
    InstructionVariation(LFS, &[Reg16, Mem16To16]),
    InstructionVariation(LFS, &[Reg32, Mem16To32]),
    InstructionVariation(LFS, &[Reg64, Mem16To64]),
    InstructionVariation(LGS, &[Reg16, Mem16To16]),
    InstructionVariation(LGS, &[Reg32, Mem16To32]),
    InstructionVariation(LGS, &[Reg64, Mem16To64]),
    InstructionVariation(LEA, &[Reg16, Mem]),
    InstructionVariation(LEA, &[Reg32, Mem]),
    InstructionVariation(LEA, &[Reg64, Mem]),
    InstructionVariation(LEAVE, &[]),
    InstructionVariation(LEAVE, &[]),
    InstructionVariation(LEAVE, &[]),
    InstructionVariation(LFENCE, &[]),
    InstructionVariation(LGDT, &[Mem16Or32]),
    InstructionVariation(LIDT, &[Mem16Or32]),
    InstructionVariation(LGDT, &[Mem16Or64]),
    InstructionVariation(LIDT, &[Mem16Or64]),
    InstructionVariation(LLDT, &[RegOrMem16]),
    InstructionVariation(LMSW, &[RegOrMem16]),
    InstructionVariation(LOCK, &[]),
    InstructionVariation(LODS, &[Mem8]),
    InstructionVariation(LODS, &[Mem16]),
    InstructionVariation(LODS, &[Mem32]),
    InstructionVariation(LODS, &[Mem64]),
    InstructionVariation(LODSB, &[]),
    InstructionVariation(LODSW, &[]),
    InstructionVariation(LODSD, &[]),
    InstructionVariation(LODSQ, &[]),
    InstructionVariation(LOOP, &[Rel8]),
    InstructionVariation(LOOPE, &[Rel8]),
    InstructionVariation(LOOPNE, &[Rel8]),
    InstructionVariation(LSL, &[Reg16, RegOrMem16]),
    InstructionVariation(LSL, &[Reg32, Reg32OrMem16]),
    InstructionVariation(LSL, &[Reg64, Reg32OrMem16]),
    InstructionVariation(LTR, &[RegOrMem16]),
    InstructionVariation(LZCNT, &[Reg16, RegOrMem16]),
    InstructionVariation(LZCNT, &[Reg32, RegOrMem32]),
    InstructionVariation(LZCNT, &[Reg64, RegOrMem64]),
    InstructionVariation(
        MASKMOVDQU,
        &[SpecificRegister(XMM1), SpecificRegister(XMM2)],
    ),
    InstructionVariation(
        VMASKMOVDQU,
        &[SpecificRegister(XMM1), SpecificRegister(XMM2)],
    ),
    InstructionVariation(
        MASKMOVQ,
        &[SpecificRegister(MM1), SpecificRegisterOrMem64(MM2)],
    ),
    InstructionVariation(
        MAXPD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VMAXPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VMAXPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VMAXPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VMAXPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VMAXPD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        MAXPS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VMAXPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VMAXPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VMAXPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VMAXPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VMAXPS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        MAXSD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem64(XMM2)],
    ),
    InstructionVariation(
        VMAXSD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
        ],
    ),
    InstructionVariation(
        VMAXSD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
        ],
    ),
    InstructionVariation(
        MAXSS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem32(XMM2)],
    ),
    InstructionVariation(
        VMAXSS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(
        VMAXSS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(MFENCE, &[]),
    InstructionVariation(
        MINPD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VMINPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VMINPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VMINPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VMINPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VMINPD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        MINPS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VMINPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VMINPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VMINPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VMINPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VMINPS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        MINSD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem64(XMM2)],
    ),
    InstructionVariation(
        VMINSD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
        ],
    ),
    InstructionVariation(
        VMINSD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
        ],
    ),
    InstructionVariation(
        MINSS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem32(XMM2)],
    ),
    InstructionVariation(
        VMINSS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(
        VMINSS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(MONITOR, &[]),
    InstructionVariation(MOV, &[RegOrMem8, Reg8]),
    InstructionVariation(MOV, &[RegOrMem8, Reg8]),
    InstructionVariation(MOV, &[RegOrMem16, Reg16]),
    InstructionVariation(MOV, &[RegOrMem32, Reg32]),
    InstructionVariation(MOV, &[RegOrMem64, Reg64]),
    InstructionVariation(MOV, &[Reg8, RegOrMem8]),
    InstructionVariation(MOV, &[Reg8, RegOrMem8]),
    InstructionVariation(MOV, &[Reg16, RegOrMem16]),
    InstructionVariation(MOV, &[Reg32, RegOrMem32]),
    InstructionVariation(MOV, &[Reg64, RegOrMem64]),
    InstructionVariation(MOV, &[RegOrMem16, SReg]),
    InstructionVariation(MOV, &[RegOrMem64, SReg]),
    InstructionVariation(MOV, &[SReg, RegOrMem16]),
    InstructionVariation(MOV, &[SReg, RegOrMem64]),
    InstructionVariation(MOV, &[SpecificRegister(AL), Moffs8]),
    InstructionVariation(MOV, &[SpecificRegister(AL), Moffs8]),
    InstructionVariation(MOV, &[SpecificRegister(AX), Moffs16]),
    InstructionVariation(MOV, &[SpecificRegister(EAX), Moffs32]),
    InstructionVariation(MOV, &[SpecificRegister(RAX), Moffs64]),
    InstructionVariation(MOV, &[Moffs8, SpecificRegister(AL)]),
    InstructionVariation(MOV, &[Moffs8, SpecificRegister(AL)]),
    InstructionVariation(MOV, &[Moffs16, SpecificRegister(AX)]),
    InstructionVariation(MOV, &[Moffs32, SpecificRegister(EAX)]),
    InstructionVariation(MOV, &[Moffs64, SpecificRegister(RAX)]),
    InstructionVariation(MOV, &[Reg8, Imm8]),
    InstructionVariation(MOV, &[Reg8, Imm8]),
    InstructionVariation(MOV, &[Reg16, Imm16]),
    InstructionVariation(MOV, &[Reg32, Imm32]),
    InstructionVariation(MOV, &[Reg64, Imm64]),
    InstructionVariation(MOV, &[RegOrMem8, Imm8]),
    InstructionVariation(MOV, &[RegOrMem8, Imm8]),
    InstructionVariation(MOV, &[RegOrMem16, Imm16]),
    InstructionVariation(MOV, &[RegOrMem32, Imm32]),
    InstructionVariation(MOV, &[RegOrMem64, Imm32]),
    InstructionVariation(MOV, &[Reg32, Reg32Cr]),
    InstructionVariation(MOV, &[Reg64, Reg32Cr]),
    InstructionVariation(MOV, &[Reg64, SpecificRegister(CR8)]),
    InstructionVariation(MOV, &[Reg32Cr, Reg32]),
    InstructionVariation(MOV, &[Reg32Cr, Reg64]),
    InstructionVariation(MOV, &[SpecificRegister(CR8), Reg64]),
    InstructionVariation(MOV, &[Reg32, Reg32Dr]),
    InstructionVariation(MOV, &[Reg64, Reg32Dr]),
    InstructionVariation(MOV, &[Reg32Dr, Reg32]),
    InstructionVariation(MOV, &[Reg32Dr, Reg64]),
    InstructionVariation(
        MOVAPD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        MOVAPD,
        &[SpecificRegisterOrMem128(XMM2), SpecificRegister(XMM1)],
    ),
    InstructionVariation(
        VMOVAPD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VMOVAPD,
        &[SpecificRegisterOrMem128(XMM2), SpecificRegister(XMM1)],
    ),
    InstructionVariation(
        VMOVAPD,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem256(YMM2)],
    ),
    InstructionVariation(
        VMOVAPD,
        &[SpecificRegisterOrMem256(YMM2), SpecificRegister(YMM1)],
    ),
    InstructionVariation(
        VMOVAPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128(XMM2),
        ],
    ),
    InstructionVariation(
        VMOVAPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256(YMM2),
        ],
    ),
    InstructionVariation(
        VMOVAPD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512(ZMM2),
        ],
    ),
    InstructionVariation(
        VMOVAPD,
        &[
            SpecificRegisterOrMem128(XMM2),
            SpecificRegister(K1),
            SpecificRegister(XMM1),
        ],
    ),
    InstructionVariation(
        VMOVAPD,
        &[
            SpecificRegisterOrMem256(YMM2),
            SpecificRegister(K1),
            SpecificRegister(YMM1),
        ],
    ),
    InstructionVariation(
        VMOVAPD,
        &[
            SpecificRegisterOrMem512(ZMM2),
            SpecificRegister(K1),
            SpecificRegister(ZMM1),
        ],
    ),
    InstructionVariation(
        MOVAPS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        MOVAPS,
        &[SpecificRegisterOrMem128(XMM2), SpecificRegister(XMM1)],
    ),
    InstructionVariation(
        VMOVAPS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VMOVAPS,
        &[SpecificRegisterOrMem128(XMM2), SpecificRegister(XMM1)],
    ),
    InstructionVariation(
        VMOVAPS,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem256(YMM2)],
    ),
    InstructionVariation(
        VMOVAPS,
        &[SpecificRegisterOrMem256(YMM2), SpecificRegister(YMM1)],
    ),
    InstructionVariation(
        VMOVAPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128(XMM2),
        ],
    ),
    InstructionVariation(
        VMOVAPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256(YMM2),
        ],
    ),
    InstructionVariation(
        VMOVAPS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512(ZMM2),
        ],
    ),
    InstructionVariation(
        VMOVAPS,
        &[
            SpecificRegisterOrMem128(XMM2),
            SpecificRegister(K1),
            SpecificRegister(XMM1),
        ],
    ),
    InstructionVariation(
        VMOVAPS,
        &[
            SpecificRegisterOrMem256(YMM2),
            SpecificRegister(K1),
            SpecificRegister(YMM1),
        ],
    ),
    InstructionVariation(
        VMOVAPS,
        &[
            SpecificRegisterOrMem512(ZMM2),
            SpecificRegister(K1),
            SpecificRegister(ZMM1),
        ],
    ),
    InstructionVariation(MOVBE, &[Reg16, Mem16]),
    InstructionVariation(MOVBE, &[Reg32, Mem32]),
    InstructionVariation(MOVBE, &[Reg64, Mem64]),
    InstructionVariation(MOVBE, &[Mem16, Reg16]),
    InstructionVariation(MOVBE, &[Mem32, Reg32]),
    InstructionVariation(MOVBE, &[Mem64, Reg64]),
    InstructionVariation(MOVD, &[Reg64MM, RegOrMem32]),
    InstructionVariation(MOVQ, &[Reg64MM, RegOrMem64]),
    InstructionVariation(MOVD, &[RegOrMem32, Reg64MM]),
    InstructionVariation(MOVQ, &[RegOrMem64, Reg64MM]),
    InstructionVariation(MOVD, &[Reg128, RegOrMem32]),
    InstructionVariation(MOVQ, &[Reg128, RegOrMem64]),
    InstructionVariation(MOVD, &[RegOrMem32, Reg128]),
    InstructionVariation(MOVQ, &[RegOrMem64, Reg128]),
    InstructionVariation(VMOVD, &[SpecificRegister(XMM1), RegOrMem32]),
    InstructionVariation(VMOVQ, &[SpecificRegister(XMM1), Reg64]),
    InstructionVariation(VMOVD, &[RegOrMem32, SpecificRegister(XMM1)]),
    InstructionVariation(VMOVQ, &[Reg64, SpecificRegister(XMM1)]),
    InstructionVariation(VMOVD, &[SpecificRegister(XMM1), RegOrMem32]),
    InstructionVariation(VMOVQ, &[SpecificRegister(XMM1), Reg64]),
    InstructionVariation(VMOVD, &[RegOrMem32, SpecificRegister(XMM1)]),
    InstructionVariation(VMOVQ, &[Reg64, SpecificRegister(XMM1)]),
    InstructionVariation(
        MOVDDUP,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem64(XMM2)],
    ),
    InstructionVariation(
        VMOVDDUP,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem64(XMM2)],
    ),
    InstructionVariation(
        VMOVDDUP,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem256(YMM2)],
    ),
    InstructionVariation(
        VMOVDDUP,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem64(XMM2),
        ],
    ),
    InstructionVariation(
        VMOVDDUP,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256(YMM2),
        ],
    ),
    InstructionVariation(
        VMOVDDUP,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512(ZMM2),
        ],
    ),
    InstructionVariation(MOVDQ2Q, &[Reg64MM, Reg128]),
    InstructionVariation(
        MOVDQA,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        MOVDQA,
        &[SpecificRegisterOrMem128(XMM2), SpecificRegister(XMM1)],
    ),
    InstructionVariation(
        VMOVDQA,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VMOVDQA,
        &[SpecificRegisterOrMem128(XMM2), SpecificRegister(XMM1)],
    ),
    InstructionVariation(
        VMOVDQA,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem256(YMM2)],
    ),
    InstructionVariation(
        VMOVDQA,
        &[SpecificRegisterOrMem256(YMM2), SpecificRegister(YMM1)],
    ),
    InstructionVariation(
        VMOVDQA32,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128(XMM2),
        ],
    ),
    InstructionVariation(
        VMOVDQA32,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256(YMM2),
        ],
    ),
    InstructionVariation(
        VMOVDQA32,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512(ZMM2),
        ],
    ),
    InstructionVariation(
        VMOVDQA32,
        &[
            SpecificRegisterOrMem128(XMM2),
            SpecificRegister(K1),
            SpecificRegister(XMM1),
        ],
    ),
    InstructionVariation(
        VMOVDQA32,
        &[
            SpecificRegisterOrMem256(YMM2),
            SpecificRegister(K1),
            SpecificRegister(YMM1),
        ],
    ),
    InstructionVariation(
        VMOVDQA32,
        &[
            SpecificRegisterOrMem512(ZMM2),
            SpecificRegister(K1),
            SpecificRegister(ZMM1),
        ],
    ),
    InstructionVariation(
        VMOVDQA64,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128(XMM2),
        ],
    ),
    InstructionVariation(
        VMOVDQA64,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256(YMM2),
        ],
    ),
    InstructionVariation(
        VMOVDQA64,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512(ZMM2),
        ],
    ),
    InstructionVariation(
        VMOVDQA64,
        &[
            SpecificRegisterOrMem128(XMM2),
            SpecificRegister(K1),
            SpecificRegister(XMM1),
        ],
    ),
    InstructionVariation(
        VMOVDQA64,
        &[
            SpecificRegisterOrMem256(YMM2),
            SpecificRegister(K1),
            SpecificRegister(YMM1),
        ],
    ),
    InstructionVariation(
        VMOVDQA64,
        &[
            SpecificRegisterOrMem512(ZMM2),
            SpecificRegister(K1),
            SpecificRegister(ZMM1),
        ],
    ),
    InstructionVariation(
        MOVDQU,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        MOVDQU,
        &[SpecificRegisterOrMem128(XMM2), SpecificRegister(XMM1)],
    ),
    InstructionVariation(
        VMOVDQU,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VMOVDQU,
        &[SpecificRegisterOrMem128(XMM2), SpecificRegister(XMM1)],
    ),
    InstructionVariation(
        VMOVDQU,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem256(YMM2)],
    ),
    InstructionVariation(
        VMOVDQU,
        &[SpecificRegisterOrMem256(YMM2), SpecificRegister(YMM1)],
    ),
    InstructionVariation(
        VMOVDQU8,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128(XMM2),
        ],
    ),
    InstructionVariation(
        VMOVDQU8,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256(YMM2),
        ],
    ),
    InstructionVariation(
        VMOVDQU8,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512(ZMM2),
        ],
    ),
    InstructionVariation(
        VMOVDQU8,
        &[
            SpecificRegisterOrMem128(XMM2),
            SpecificRegister(K1),
            SpecificRegister(XMM1),
        ],
    ),
    InstructionVariation(
        VMOVDQU8,
        &[
            SpecificRegisterOrMem256(YMM2),
            SpecificRegister(K1),
            SpecificRegister(YMM1),
        ],
    ),
    InstructionVariation(
        VMOVDQU8,
        &[
            SpecificRegisterOrMem512(ZMM2),
            SpecificRegister(K1),
            SpecificRegister(ZMM1),
        ],
    ),
    InstructionVariation(
        VMOVDQU16,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128(XMM2),
        ],
    ),
    InstructionVariation(
        VMOVDQU16,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256(YMM2),
        ],
    ),
    InstructionVariation(
        VMOVDQU16,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512(ZMM2),
        ],
    ),
    InstructionVariation(
        VMOVDQU16,
        &[
            SpecificRegisterOrMem128(XMM2),
            SpecificRegister(K1),
            SpecificRegister(XMM1),
        ],
    ),
    InstructionVariation(
        VMOVDQU16,
        &[
            SpecificRegisterOrMem256(YMM2),
            SpecificRegister(K1),
            SpecificRegister(YMM1),
        ],
    ),
    InstructionVariation(
        VMOVDQU16,
        &[
            SpecificRegisterOrMem512(ZMM2),
            SpecificRegister(K1),
            SpecificRegister(ZMM1),
        ],
    ),
    InstructionVariation(
        VMOVDQU32,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128(XMM2),
        ],
    ),
    InstructionVariation(
        VMOVDQU32,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256(YMM2),
        ],
    ),
    InstructionVariation(
        VMOVDQU32,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512(ZMM2),
        ],
    ),
    InstructionVariation(
        VMOVDQU32,
        &[
            SpecificRegisterOrMem128(XMM2),
            SpecificRegister(K1),
            SpecificRegister(XMM1),
        ],
    ),
    InstructionVariation(
        VMOVDQU32,
        &[
            SpecificRegisterOrMem256(YMM2),
            SpecificRegister(K1),
            SpecificRegister(YMM1),
        ],
    ),
    InstructionVariation(
        VMOVDQU32,
        &[
            SpecificRegisterOrMem512(ZMM2),
            SpecificRegister(K1),
            SpecificRegister(ZMM1),
        ],
    ),
    InstructionVariation(
        VMOVDQU64,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128(XMM2),
        ],
    ),
    InstructionVariation(
        VMOVDQU64,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256(YMM2),
        ],
    ),
    InstructionVariation(
        VMOVDQU64,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512(ZMM2),
        ],
    ),
    InstructionVariation(
        VMOVDQU64,
        &[
            SpecificRegisterOrMem128(XMM2),
            SpecificRegister(K1),
            SpecificRegister(XMM1),
        ],
    ),
    InstructionVariation(
        VMOVDQU64,
        &[
            SpecificRegisterOrMem256(YMM2),
            SpecificRegister(K1),
            SpecificRegister(YMM1),
        ],
    ),
    InstructionVariation(
        VMOVDQU64,
        &[
            SpecificRegisterOrMem512(ZMM2),
            SpecificRegister(K1),
            SpecificRegister(ZMM1),
        ],
    ),
    InstructionVariation(MOVHLPS, &[SpecificRegister(XMM1), SpecificRegister(XMM2)]),
    InstructionVariation(
        VMOVHLPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegister(XMM3),
        ],
    ),
    InstructionVariation(
        VMOVHLPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegister(XMM3),
        ],
    ),
    InstructionVariation(MOVHPD, &[SpecificRegister(XMM1), Mem64]),
    InstructionVariation(
        VMOVHPD,
        &[SpecificRegister(XMM2), SpecificRegister(XMM1), Mem64],
    ),
    InstructionVariation(
        VMOVHPD,
        &[SpecificRegister(XMM2), SpecificRegister(XMM1), Mem64],
    ),
    InstructionVariation(MOVHPD, &[Mem64, SpecificRegister(XMM1)]),
    InstructionVariation(VMOVHPD, &[Mem64, SpecificRegister(XMM1)]),
    InstructionVariation(VMOVHPD, &[Mem64, SpecificRegister(XMM1)]),
    InstructionVariation(MOVHPS, &[SpecificRegister(XMM1), Mem64]),
    InstructionVariation(
        VMOVHPS,
        &[SpecificRegister(XMM2), SpecificRegister(XMM1), Mem64],
    ),
    InstructionVariation(
        VMOVHPS,
        &[SpecificRegister(XMM2), SpecificRegister(XMM1), Mem64],
    ),
    InstructionVariation(MOVHPS, &[Mem64, SpecificRegister(XMM1)]),
    InstructionVariation(VMOVHPS, &[Mem64, SpecificRegister(XMM1)]),
    InstructionVariation(VMOVHPS, &[Mem64, SpecificRegister(XMM1)]),
    InstructionVariation(MOVLHPS, &[SpecificRegister(XMM1), SpecificRegister(XMM2)]),
    InstructionVariation(
        VMOVLHPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegister(XMM3),
        ],
    ),
    InstructionVariation(
        VMOVLHPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegister(XMM3),
        ],
    ),
    InstructionVariation(MOVLPD, &[SpecificRegister(XMM1), Mem64]),
    InstructionVariation(
        VMOVLPD,
        &[SpecificRegister(XMM2), SpecificRegister(XMM1), Mem64],
    ),
    InstructionVariation(
        VMOVLPD,
        &[SpecificRegister(XMM2), SpecificRegister(XMM1), Mem64],
    ),
    InstructionVariation(MOVLPD, &[Mem64, SpecificRegister(XMM1)]),
    InstructionVariation(VMOVLPD, &[Mem64, SpecificRegister(XMM1)]),
    InstructionVariation(VMOVLPD, &[Mem64, SpecificRegister(XMM1)]),
    InstructionVariation(MOVLPS, &[SpecificRegister(XMM1), Mem64]),
    InstructionVariation(
        VMOVLPS,
        &[SpecificRegister(XMM2), SpecificRegister(XMM1), Mem64],
    ),
    InstructionVariation(
        VMOVLPS,
        &[SpecificRegister(XMM2), SpecificRegister(XMM1), Mem64],
    ),
    InstructionVariation(MOVLPS, &[Mem64, SpecificRegister(XMM1)]),
    InstructionVariation(VMOVLPS, &[Mem64, SpecificRegister(XMM1)]),
    InstructionVariation(VMOVLPS, &[Mem64, SpecificRegister(XMM1)]),
    InstructionVariation(MOVMSKPD, &[AnyRegister, Reg128]),
    InstructionVariation(VMOVMSKPD, &[AnyRegister, SpecificRegister(XMM2)]),
    InstructionVariation(VMOVMSKPD, &[AnyRegister, SpecificRegister(YMM2)]),
    InstructionVariation(MOVMSKPS, &[AnyRegister, Reg128]),
    InstructionVariation(VMOVMSKPS, &[AnyRegister, SpecificRegister(XMM2)]),
    InstructionVariation(VMOVMSKPS, &[AnyRegister, SpecificRegister(YMM2)]),
    InstructionVariation(MOVNTDQ, &[Mem128, SpecificRegister(XMM1)]),
    InstructionVariation(VMOVNTDQ, &[Mem128, SpecificRegister(XMM1)]),
    InstructionVariation(VMOVNTDQ, &[Mem256, SpecificRegister(YMM1)]),
    InstructionVariation(VMOVNTDQ, &[Mem128, SpecificRegister(XMM1)]),
    InstructionVariation(VMOVNTDQ, &[Mem256, SpecificRegister(YMM1)]),
    InstructionVariation(VMOVNTDQ, &[Mem512, SpecificRegister(ZMM1)]),
    InstructionVariation(MOVNTDQA, &[SpecificRegister(XMM1), Mem128]),
    InstructionVariation(VMOVNTDQA, &[SpecificRegister(XMM1), Mem128]),
    InstructionVariation(VMOVNTDQA, &[SpecificRegister(YMM1), Mem256]),
    InstructionVariation(VMOVNTDQA, &[SpecificRegister(XMM1), Mem128]),
    InstructionVariation(VMOVNTDQA, &[SpecificRegister(YMM1), Mem256]),
    InstructionVariation(VMOVNTDQA, &[SpecificRegister(ZMM1), Mem512]),
    InstructionVariation(MOVNTI, &[Mem32, Reg32]),
    InstructionVariation(MOVNTI, &[Mem64, Reg64]),
    InstructionVariation(MOVNTPD, &[Mem128, SpecificRegister(XMM1)]),
    InstructionVariation(VMOVNTPD, &[Mem128, SpecificRegister(XMM1)]),
    InstructionVariation(VMOVNTPD, &[Mem256, SpecificRegister(YMM1)]),
    InstructionVariation(VMOVNTPD, &[Mem128, SpecificRegister(XMM1)]),
    InstructionVariation(VMOVNTPD, &[Mem256, SpecificRegister(YMM1)]),
    InstructionVariation(VMOVNTPD, &[Mem512, SpecificRegister(ZMM1)]),
    InstructionVariation(MOVNTPS, &[Mem128, SpecificRegister(XMM1)]),
    InstructionVariation(VMOVNTPS, &[Mem128, SpecificRegister(XMM1)]),
    InstructionVariation(VMOVNTPS, &[Mem256, SpecificRegister(YMM1)]),
    InstructionVariation(VMOVNTPS, &[Mem128, SpecificRegister(XMM1)]),
    InstructionVariation(VMOVNTPS, &[Mem256, SpecificRegister(YMM1)]),
    InstructionVariation(VMOVNTPS, &[Mem512, SpecificRegister(ZMM1)]),
    InstructionVariation(MOVNTQ, &[Mem64, Reg64MM]),
    InstructionVariation(MOVQ, &[Reg64MM, Reg64MMOrMem64]),
    InstructionVariation(MOVQ, &[Reg64MMOrMem64, Reg64MM]),
    InstructionVariation(
        MOVQ,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem64(XMM2)],
    ),
    InstructionVariation(
        VMOVQ,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem64(XMM2)],
    ),
    InstructionVariation(
        VMOVQ,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem64(XMM2)],
    ),
    InstructionVariation(
        MOVQ,
        &[SpecificRegisterOrMem64(XMM2), SpecificRegister(XMM1)],
    ),
    InstructionVariation(
        VMOVQ,
        &[SpecificRegisterOrMem64(XMM1), SpecificRegister(XMM2)],
    ),
    InstructionVariation(
        VMOVQ,
        &[SpecificRegisterOrMem64(XMM1), SpecificRegister(XMM2)],
    ),
    InstructionVariation(MOVQ2DQ, &[Reg128, Reg64MM]),
    InstructionVariation(MOVS, &[Mem8, Mem8]),
    InstructionVariation(MOVS, &[Mem16, Mem16]),
    InstructionVariation(MOVS, &[Mem32, Mem32]),
    InstructionVariation(MOVS, &[Mem64, Mem64]),
    InstructionVariation(MOVSB, &[]),
    InstructionVariation(MOVSW, &[]),
    InstructionVariation(MOVSD, &[]),
    InstructionVariation(MOVSQ, &[]),
    InstructionVariation(MOVSD, &[SpecificRegister(XMM1), SpecificRegister(XMM2)]),
    InstructionVariation(MOVSD, &[SpecificRegister(XMM1), Mem64]),
    InstructionVariation(
        MOVSD,
        &[SpecificRegisterOrMem64(XMM1), SpecificRegister(XMM2)],
    ),
    InstructionVariation(
        VMOVSD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegister(XMM3),
        ],
    ),
    InstructionVariation(VMOVSD, &[SpecificRegister(XMM1), Mem64]),
    InstructionVariation(
        VMOVSD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegister(XMM3),
        ],
    ),
    InstructionVariation(VMOVSD, &[Mem64, SpecificRegister(XMM1)]),
    InstructionVariation(
        VMOVSD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegister(XMM3),
        ],
    ),
    InstructionVariation(
        VMOVSD,
        &[SpecificRegister(XMM1), SpecificRegister(K1), Mem64],
    ),
    InstructionVariation(
        VMOVSD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegister(XMM3),
        ],
    ),
    InstructionVariation(
        VMOVSD,
        &[Mem64, SpecificRegister(K1), SpecificRegister(XMM1)],
    ),
    InstructionVariation(
        MOVSHDUP,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VMOVSHDUP,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VMOVSHDUP,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem256(YMM2)],
    ),
    InstructionVariation(
        VMOVSHDUP,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128(XMM2),
        ],
    ),
    InstructionVariation(
        VMOVSHDUP,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256(YMM2),
        ],
    ),
    InstructionVariation(
        VMOVSHDUP,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512(ZMM2),
        ],
    ),
    InstructionVariation(
        MOVSLDUP,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VMOVSLDUP,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VMOVSLDUP,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem256(YMM2)],
    ),
    InstructionVariation(
        VMOVSLDUP,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128(XMM2),
        ],
    ),
    InstructionVariation(
        VMOVSLDUP,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256(YMM2),
        ],
    ),
    InstructionVariation(
        VMOVSLDUP,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512(ZMM2),
        ],
    ),
    InstructionVariation(MOVSS, &[SpecificRegister(XMM1), SpecificRegister(XMM2)]),
    InstructionVariation(MOVSS, &[SpecificRegister(XMM1), Mem32]),
    InstructionVariation(
        VMOVSS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegister(XMM3),
        ],
    ),
    InstructionVariation(VMOVSS, &[SpecificRegister(XMM1), Mem32]),
    InstructionVariation(
        MOVSS,
        &[SpecificRegisterOrMem32(XMM2), SpecificRegister(XMM1)],
    ),
    InstructionVariation(
        VMOVSS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegister(XMM3),
        ],
    ),
    InstructionVariation(VMOVSS, &[Mem32, SpecificRegister(XMM1)]),
    InstructionVariation(
        VMOVSS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegister(XMM3),
        ],
    ),
    InstructionVariation(
        VMOVSS,
        &[SpecificRegister(XMM1), SpecificRegister(K1), Mem32],
    ),
    InstructionVariation(
        VMOVSS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegister(XMM3),
        ],
    ),
    InstructionVariation(
        VMOVSS,
        &[Mem32, SpecificRegister(K1), SpecificRegister(XMM1)],
    ),
    InstructionVariation(MOVSX, &[Reg16, RegOrMem8]),
    InstructionVariation(MOVSX, &[Reg32, RegOrMem8]),
    InstructionVariation(MOVSX, &[Reg64, RegOrMem8]),
    InstructionVariation(MOVSX, &[Reg32, RegOrMem16]),
    InstructionVariation(MOVSX, &[Reg64, RegOrMem16]),
    InstructionVariation(MOVSXD, &[Reg64, RegOrMem32]),
    InstructionVariation(
        MOVUPD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        MOVUPD,
        &[SpecificRegisterOrMem128(XMM2), SpecificRegister(XMM1)],
    ),
    InstructionVariation(
        VMOVUPD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VMOVUPD,
        &[SpecificRegisterOrMem128(XMM2), SpecificRegister(XMM1)],
    ),
    InstructionVariation(
        VMOVUPD,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem256(YMM2)],
    ),
    InstructionVariation(
        VMOVUPD,
        &[SpecificRegisterOrMem256(YMM2), SpecificRegister(YMM1)],
    ),
    InstructionVariation(
        VMOVUPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128(XMM2),
        ],
    ),
    InstructionVariation(
        VMOVUPD,
        &[
            SpecificRegisterOrMem128(XMM2),
            SpecificRegister(K1),
            SpecificRegister(XMM1),
        ],
    ),
    InstructionVariation(
        VMOVUPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256(YMM2),
        ],
    ),
    InstructionVariation(
        VMOVUPD,
        &[
            SpecificRegisterOrMem256(YMM2),
            SpecificRegister(K1),
            SpecificRegister(YMM1),
        ],
    ),
    InstructionVariation(
        VMOVUPD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512(ZMM2),
        ],
    ),
    InstructionVariation(
        VMOVUPD,
        &[
            SpecificRegisterOrMem512(ZMM2),
            SpecificRegister(K1),
            SpecificRegister(ZMM1),
        ],
    ),
    InstructionVariation(
        MOVUPS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        MOVUPS,
        &[SpecificRegisterOrMem128(XMM2), SpecificRegister(XMM1)],
    ),
    InstructionVariation(
        VMOVUPS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VMOVUPS,
        &[SpecificRegisterOrMem128(XMM2), SpecificRegister(XMM1)],
    ),
    InstructionVariation(
        VMOVUPS,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem256(YMM2)],
    ),
    InstructionVariation(
        VMOVUPS,
        &[SpecificRegisterOrMem256(YMM2), SpecificRegister(YMM1)],
    ),
    InstructionVariation(
        VMOVUPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128(XMM2),
        ],
    ),
    InstructionVariation(
        VMOVUPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256(YMM2),
        ],
    ),
    InstructionVariation(
        VMOVUPS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512(ZMM2),
        ],
    ),
    InstructionVariation(
        VMOVUPS,
        &[
            SpecificRegisterOrMem128(XMM2),
            SpecificRegister(K1),
            SpecificRegister(XMM1),
        ],
    ),
    InstructionVariation(
        VMOVUPS,
        &[
            SpecificRegisterOrMem256(YMM2),
            SpecificRegister(K1),
            SpecificRegister(YMM1),
        ],
    ),
    InstructionVariation(
        VMOVUPS,
        &[
            SpecificRegisterOrMem512(ZMM2),
            SpecificRegister(K1),
            SpecificRegister(ZMM1),
        ],
    ),
    InstructionVariation(MOVZX, &[Reg16, RegOrMem8]),
    InstructionVariation(MOVZX, &[Reg32, RegOrMem8]),
    InstructionVariation(MOVZX, &[Reg64, RegOrMem8]),
    InstructionVariation(MOVZX, &[Reg32, RegOrMem16]),
    InstructionVariation(MOVZX, &[Reg64, RegOrMem16]),
    InstructionVariation(
        MPSADBW,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2), Imm8],
    ),
    InstructionVariation(
        VMPSADBW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VMPSADBW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
            Imm8,
        ],
    ),
    InstructionVariation(MUL, &[RegOrMem8]),
    InstructionVariation(MUL, &[RegOrMem8]),
    InstructionVariation(MUL, &[RegOrMem16]),
    InstructionVariation(MUL, &[RegOrMem32]),
    InstructionVariation(MUL, &[RegOrMem64]),
    InstructionVariation(
        MULPD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VMULPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VMULPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VMULPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VMULPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VMULPD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        MULPS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VMULPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VMULPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VMULPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VMULPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VMULPS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        MULSD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem64(XMM2)],
    ),
    InstructionVariation(
        VMULSD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
        ],
    ),
    InstructionVariation(
        VMULSD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
        ],
    ),
    InstructionVariation(
        MULSS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem32(XMM2)],
    ),
    InstructionVariation(
        VMULSS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(
        VMULSS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(MULX, &[Reg32a, Reg32b, RegOrMem32]),
    InstructionVariation(MULX, &[Reg64a, Reg64b, RegOrMem64]),
    InstructionVariation(MWAIT, &[]),
    InstructionVariation(NEG, &[RegOrMem8]),
    InstructionVariation(NEG, &[RegOrMem8]),
    InstructionVariation(NEG, &[RegOrMem16]),
    InstructionVariation(NEG, &[RegOrMem32]),
    InstructionVariation(NEG, &[RegOrMem64]),
    InstructionVariation(NOP, &[]),
    InstructionVariation(NOP, &[RegOrMem16]),
    InstructionVariation(NOP, &[RegOrMem32]),
    InstructionVariation(NOT, &[RegOrMem8]),
    InstructionVariation(NOT, &[RegOrMem8]),
    InstructionVariation(NOT, &[RegOrMem16]),
    InstructionVariation(NOT, &[RegOrMem32]),
    InstructionVariation(NOT, &[RegOrMem64]),
    InstructionVariation(OR, &[SpecificRegister(AL), Imm8]),
    InstructionVariation(OR, &[SpecificRegister(AX), Imm16]),
    InstructionVariation(OR, &[SpecificRegister(EAX), Imm32]),
    InstructionVariation(OR, &[SpecificRegister(RAX), Imm32]),
    InstructionVariation(OR, &[RegOrMem8, Imm8]),
    InstructionVariation(OR, &[RegOrMem8, Imm8]),
    InstructionVariation(OR, &[RegOrMem16, Imm16]),
    InstructionVariation(OR, &[RegOrMem32, Imm32]),
    InstructionVariation(OR, &[RegOrMem64, Imm32]),
    InstructionVariation(OR, &[RegOrMem16, Imm8]),
    InstructionVariation(OR, &[RegOrMem32, Imm8]),
    InstructionVariation(OR, &[RegOrMem64, Imm8]),
    InstructionVariation(OR, &[RegOrMem8, Reg8]),
    InstructionVariation(OR, &[RegOrMem8, Reg8]),
    InstructionVariation(OR, &[RegOrMem16, Reg16]),
    InstructionVariation(OR, &[RegOrMem32, Reg32]),
    InstructionVariation(OR, &[RegOrMem64, Reg64]),
    InstructionVariation(OR, &[Reg8, RegOrMem8]),
    InstructionVariation(OR, &[Reg8, RegOrMem8]),
    InstructionVariation(OR, &[Reg16, RegOrMem16]),
    InstructionVariation(OR, &[Reg32, RegOrMem32]),
    InstructionVariation(OR, &[Reg64, RegOrMem64]),
    InstructionVariation(
        ORPD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VORPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VORPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VORPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VORPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VORPD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        ORPS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VORPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VORPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VORPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VORPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VORPS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(OUT, &[Imm8, SpecificRegister(AL)]),
    InstructionVariation(OUT, &[Imm8, SpecificRegister(AX)]),
    InstructionVariation(OUT, &[Imm8, SpecificRegister(EAX)]),
    InstructionVariation(OUT, &[SpecificRegister(DX), SpecificRegister(AL)]),
    InstructionVariation(OUT, &[SpecificRegister(DX), SpecificRegister(AX)]),
    InstructionVariation(OUT, &[SpecificRegister(DX), SpecificRegister(EAX)]),
    InstructionVariation(OUTS, &[SpecificRegister(DX), Mem8]),
    InstructionVariation(OUTS, &[SpecificRegister(DX), Mem16]),
    InstructionVariation(OUTS, &[SpecificRegister(DX), Mem32]),
    InstructionVariation(OUTSB, &[]),
    InstructionVariation(OUTSW, &[]),
    InstructionVariation(OUTSD, &[]),
    InstructionVariation(
        PABSB,
        &[SpecificRegister(MM1), SpecificRegisterOrMem64(MM2)],
    ),
    InstructionVariation(
        PABSB,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        PABSW,
        &[SpecificRegister(MM1), SpecificRegisterOrMem64(MM2)],
    ),
    InstructionVariation(
        PABSW,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        PABSD,
        &[SpecificRegister(MM1), SpecificRegisterOrMem64(MM2)],
    ),
    InstructionVariation(
        PABSD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPABSB,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPABSW,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPABSD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPABSB,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem256(YMM2)],
    ),
    InstructionVariation(
        VPABSW,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem256(YMM2)],
    ),
    InstructionVariation(
        VPABSD,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem256(YMM2)],
    ),
    InstructionVariation(
        VPABSB,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128(XMM2),
        ],
    ),
    InstructionVariation(
        VPABSB,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256(YMM2),
        ],
    ),
    InstructionVariation(
        VPABSB,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512(ZMM2),
        ],
    ),
    InstructionVariation(
        VPABSW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128(XMM2),
        ],
    ),
    InstructionVariation(
        PACKSSWB,
        &[SpecificRegister(MM1), SpecificRegisterOrMem64(MM2)],
    ),
    InstructionVariation(
        PACKSSWB,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        PACKSSDW,
        &[SpecificRegister(MM1), SpecificRegisterOrMem64(MM2)],
    ),
    InstructionVariation(
        PACKSSDW,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPACKSSWB,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPACKSSDW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPACKSSWB,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPACKSSDW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPACKSSWB,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPACKSSWB,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPACKSSWB,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
        ],
    ),
    InstructionVariation(
        VPACKSSDW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        PACKUSDW,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPACKUSDW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPACKUSDW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPACKUSDW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPACKUSDW,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(PACKUSWB, &[Reg64MM, Reg64MMOrMem64]),
    InstructionVariation(
        PACKUSWB,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPACKUSWB,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPACKUSWB,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPACKUSWB,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPACKUSWB,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPACKUSWB,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
        ],
    ),
    InstructionVariation(PADDB, &[Reg64MM, Reg64MMOrMem64]),
    InstructionVariation(PADDW, &[Reg64MM, Reg64MMOrMem64]),
    InstructionVariation(PADDD, &[Reg64MM, Reg64MMOrMem64]),
    InstructionVariation(PADDQ, &[Reg64MM, Reg64MMOrMem64]),
    InstructionVariation(
        PADDB,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        PADDW,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        PADDD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        PADDQ,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPADDB,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPADDW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPADDD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPADDQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPADDB,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPADDW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPADDD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPADDQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPADDB,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPADDW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPADDD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPADDQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPADDB,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPADDW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(PADDSB, &[Reg64MM, Reg64MMOrMem64]),
    InstructionVariation(
        PADDSB,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(PADDSW, &[Reg64MM, Reg64MMOrMem64]),
    InstructionVariation(
        PADDSW,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPADDSB,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPADDSW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPADDSB,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPADDSW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPADDSB,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPADDSB,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPADDSB,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
        ],
    ),
    InstructionVariation(
        VPADDSW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPADDSW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPADDSW,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
        ],
    ),
    InstructionVariation(PADDUSB, &[Reg64MM, Reg64MMOrMem64]),
    InstructionVariation(
        PADDUSB,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(PADDUSW, &[Reg64MM, Reg64MMOrMem64]),
    InstructionVariation(
        PADDUSW,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPADDUSB,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPADDUSW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPADDUSB,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPADDUSW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPADDUSB,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPADDUSB,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPADDUSB,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
        ],
    ),
    InstructionVariation(
        VPADDUSW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPADDUSW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPADDUSW,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
        ],
    ),
    InstructionVariation(
        PALIGNR,
        &[SpecificRegister(MM1), SpecificRegisterOrMem64(MM2), Imm8],
    ),
    InstructionVariation(
        PALIGNR,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2), Imm8],
    ),
    InstructionVariation(
        VPALIGNR,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPALIGNR,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPALIGNR,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPALIGNR,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPALIGNR,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
            Imm8,
        ],
    ),
    InstructionVariation(PAND, &[Reg64MM, Reg64MMOrMem64]),
    InstructionVariation(
        PAND,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPAND,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPAND,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPANDD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPANDD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPANDD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VPANDQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPANDQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPANDQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(PANDN, &[Reg64MM, Reg64MMOrMem64]),
    InstructionVariation(
        PANDN,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPANDN,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPANDN,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPANDND,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPANDND,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPANDND,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VPANDNQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPANDNQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPANDNQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(PAUSE, &[]),
    InstructionVariation(
        PAVGB,
        &[SpecificRegister(MM1), SpecificRegisterOrMem64(MM2)],
    ),
    InstructionVariation(
        PAVGB,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        PAVGW,
        &[SpecificRegister(MM1), SpecificRegisterOrMem64(MM2)],
    ),
    InstructionVariation(
        PAVGW,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPAVGB,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPAVGW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPAVGB,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPAVGW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPAVGB,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPAVGB,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPAVGB,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
        ],
    ),
    InstructionVariation(
        VPAVGW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPAVGW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPAVGW,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
        ],
    ),
    InstructionVariation(
        PBLENDVB,
        &[
            SpecificRegister(XMM1),
            SpecificRegisterOrMem128(XMM2),
            SpecificRegister(XMM0),
        ],
    ),
    InstructionVariation(
        VPBLENDVB,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
            SpecificRegister(XMM4),
        ],
    ),
    InstructionVariation(
        VPBLENDVB,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
            SpecificRegister(YMM4),
        ],
    ),
    InstructionVariation(
        PBLENDW,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2), Imm8],
    ),
    InstructionVariation(
        VPBLENDW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPBLENDW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        PCLMULQDQ,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2), Imm8],
    ),
    InstructionVariation(
        VPCLMULQDQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(PCMPEQB, &[Reg64MM, Reg64MMOrMem64]),
    InstructionVariation(
        PCMPEQB,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(PCMPEQW, &[Reg64MM, Reg64MMOrMem64]),
    InstructionVariation(
        PCMPEQW,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(PCMPEQD, &[Reg64MM, Reg64MMOrMem64]),
    InstructionVariation(
        PCMPEQD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPCMPEQB,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPCMPEQW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPCMPEQD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPCMPEQB,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPCMPEQW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPCMPEQD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPCMPEQD,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPCMPEQD,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPCMPEQD,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VPCMPEQB,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPCMPEQB,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPCMPEQB,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
        ],
    ),
    InstructionVariation(
        VPCMPEQW,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPCMPEQW,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPCMPEQW,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
        ],
    ),
    InstructionVariation(
        PCMPEQQ,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPCMPEQQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPCMPEQQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPCMPEQQ,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPCMPEQQ,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPCMPEQQ,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        PCMPESTRI,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2), Imm8],
    ),
    InstructionVariation(
        VPCMPESTRI,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2), Imm8],
    ),
    InstructionVariation(
        PCMPESTRM,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2), Imm8],
    ),
    InstructionVariation(
        VPCMPESTRM,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2), Imm8],
    ),
    InstructionVariation(PCMPGTB, &[Reg64MM, Reg64MMOrMem64]),
    InstructionVariation(
        PCMPGTB,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(PCMPGTW, &[Reg64MM, Reg64MMOrMem64]),
    InstructionVariation(
        PCMPGTW,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(PCMPGTD, &[Reg64MM, Reg64MMOrMem64]),
    InstructionVariation(
        PCMPGTD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPCMPGTB,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPCMPGTW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPCMPGTD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPCMPGTB,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPCMPGTW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPCMPGTD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPCMPGTD,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPCMPGTD,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPCMPGTD,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VPCMPGTB,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPCMPGTB,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPCMPGTB,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
        ],
    ),
    InstructionVariation(
        VPCMPGTW,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPCMPGTW,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPCMPGTW,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
        ],
    ),
    InstructionVariation(
        PCMPGTQ,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPCMPGTQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPCMPGTQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPCMPGTQ,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPCMPGTQ,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPCMPGTQ,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        PCMPISTRI,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2), Imm8],
    ),
    InstructionVariation(
        VPCMPISTRI,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2), Imm8],
    ),
    InstructionVariation(
        PCMPISTRM,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2), Imm8],
    ),
    InstructionVariation(
        VPCMPISTRM,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2), Imm8],
    ),
    InstructionVariation(PDEP, &[Reg32a, Reg32b, RegOrMem32]),
    InstructionVariation(PDEP, &[Reg64a, Reg64b, RegOrMem64]),
    InstructionVariation(PEXT, &[Reg32a, Reg32b, RegOrMem32]),
    InstructionVariation(PEXT, &[Reg64a, Reg64b, RegOrMem64]),
    InstructionVariation(PEXTRB, &[RegOrMem8, SpecificRegister(XMM2), Imm8]),
    InstructionVariation(PEXTRD, &[RegOrMem32, SpecificRegister(XMM2), Imm8]),
    InstructionVariation(PEXTRQ, &[RegOrMem64, SpecificRegister(XMM2), Imm8]),
    InstructionVariation(VPEXTRB, &[RegOrMem8, SpecificRegister(XMM2), Imm8]),
    InstructionVariation(VPEXTRD, &[RegOrMem32, SpecificRegister(XMM2), Imm8]),
    InstructionVariation(VPEXTRQ, &[Reg64, SpecificRegister(XMM2), Imm8]),
    InstructionVariation(VPEXTRB, &[RegOrMem8, SpecificRegister(XMM2), Imm8]),
    InstructionVariation(VPEXTRD, &[RegOrMem32, SpecificRegister(XMM2), Imm8]),
    InstructionVariation(VPEXTRQ, &[Reg64, SpecificRegister(XMM2), Imm8]),
    InstructionVariation(PEXTRW, &[AnyRegister, Reg64MM, Imm8]),
    InstructionVariation(PEXTRW, &[AnyRegister, Reg128, Imm8]),
    InstructionVariation(PEXTRW, &[RegOrMem16, Reg128, Imm8]),
    InstructionVariation(VPEXTRW, &[AnyRegister, SpecificRegister(XMM1), Imm8]),
    InstructionVariation(VPEXTRW, &[RegOrMem16, SpecificRegister(XMM2), Imm8]),
    InstructionVariation(VPEXTRW, &[AnyRegister, SpecificRegister(XMM1), Imm8]),
    InstructionVariation(VPEXTRW, &[RegOrMem16, SpecificRegister(XMM2), Imm8]),
    InstructionVariation(
        PHADDSW,
        &[SpecificRegister(MM1), SpecificRegisterOrMem64(MM2)],
    ),
    InstructionVariation(
        PHADDSW,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPHADDSW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPHADDSW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        PHADDW,
        &[SpecificRegister(MM1), SpecificRegisterOrMem64(MM2)],
    ),
    InstructionVariation(
        PHADDW,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        PHADDD,
        &[SpecificRegister(MM1), SpecificRegisterOrMem64(MM2)],
    ),
    InstructionVariation(
        PHADDD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPHADDW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPHADDD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPHADDW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPHADDD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        PHMINPOSUW,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPHMINPOSUW,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        PHSUBSW,
        &[SpecificRegister(MM1), SpecificRegisterOrMem64(MM2)],
    ),
    InstructionVariation(
        PHSUBSW,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPHSUBSW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPHSUBSW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        PHSUBW,
        &[SpecificRegister(MM1), SpecificRegisterOrMem64(MM2)],
    ),
    InstructionVariation(
        PHSUBW,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        PHSUBD,
        &[SpecificRegister(MM1), SpecificRegisterOrMem64(MM2)],
    ),
    InstructionVariation(
        PHSUBD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPHSUBW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPHSUBD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPHSUBW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPHSUBD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(PINSRB, &[SpecificRegister(XMM1), Reg32OrMem8, Imm8]),
    InstructionVariation(PINSRD, &[SpecificRegister(XMM1), RegOrMem32, Imm8]),
    InstructionVariation(PINSRQ, &[SpecificRegister(XMM1), RegOrMem64, Imm8]),
    InstructionVariation(
        VPINSRB,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            Reg32OrMem8,
            Imm8,
        ],
    ),
    InstructionVariation(
        VPINSRD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            RegOrMem32,
            Imm8,
        ],
    ),
    InstructionVariation(
        VPINSRQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            RegOrMem64,
            Imm8,
        ],
    ),
    InstructionVariation(
        VPINSRB,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            RegOrMem8,
            Imm8,
        ],
    ),
    InstructionVariation(
        VPINSRD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            RegOrMem32,
            Imm8,
        ],
    ),
    InstructionVariation(
        VPINSRQ,
        &[SpecificRegister(XMM1), SpecificRegister(XMM2), Reg64, Imm8],
    ),
    InstructionVariation(PINSRW, &[Reg64MM, Reg32OrMem16, Imm8]),
    InstructionVariation(PINSRW, &[Reg128, Reg32OrMem16, Imm8]),
    InstructionVariation(
        VPINSRW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            Reg32OrMem16,
            Imm8,
        ],
    ),
    InstructionVariation(
        VPINSRW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            Reg32OrMem16,
            Imm8,
        ],
    ),
    InstructionVariation(
        PMADDUBSW,
        &[SpecificRegister(MM1), SpecificRegisterOrMem64(MM2)],
    ),
    InstructionVariation(
        PMADDUBSW,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPMADDUBSW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPMADDUBSW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPMADDUBSW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPMADDUBSW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPMADDUBSW,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
        ],
    ),
    InstructionVariation(PMADDWD, &[Reg64MM, Reg64MMOrMem64]),
    InstructionVariation(
        PMADDWD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPMADDWD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPMADDWD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPMADDWD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPMADDWD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPMADDWD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
        ],
    ),
    InstructionVariation(
        PMAXSW,
        &[SpecificRegister(MM1), SpecificRegisterOrMem64(MM2)],
    ),
    InstructionVariation(
        PMAXSB,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        PMAXSW,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        PMAXSD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPMAXSB,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPMAXSW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPMAXSD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPMAXSB,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPMAXSW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPMAXSD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPMAXSB,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPMAXSB,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPMAXSB,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
        ],
    ),
    InstructionVariation(
        VPMAXSW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPMAXSW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPMAXSW,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
        ],
    ),
    InstructionVariation(
        VPMAXSD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        PMAXUB,
        &[SpecificRegister(MM1), SpecificRegisterOrMem64(MM2)],
    ),
    InstructionVariation(
        PMAXUB,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        PMAXUW,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPMAXUB,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPMAXUW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPMAXUB,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPMAXUW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPMAXUB,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPMAXUB,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPMAXUB,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
        ],
    ),
    InstructionVariation(
        VPMAXUW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPMAXUW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPMAXUW,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
        ],
    ),
    InstructionVariation(
        PMAXUD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPMAXUD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPMAXUD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPMAXUD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPMAXUD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPMAXUD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VPMAXUQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPMAXUQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPMAXUQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        PMINSW,
        &[SpecificRegister(MM1), SpecificRegisterOrMem64(MM2)],
    ),
    InstructionVariation(
        PMINSB,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        PMINSW,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPMINSB,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPMINSW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPMINSB,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPMINSW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPMINSB,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPMINSB,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPMINSB,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
        ],
    ),
    InstructionVariation(
        VPMINSW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPMINSW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPMINSW,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
        ],
    ),
    InstructionVariation(
        PMINSD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPMINSD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPMINSD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPMINSD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPMINSD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPMINSD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VPMINSQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPMINSQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPMINSQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        PMINUB,
        &[SpecificRegister(MM1), SpecificRegisterOrMem64(MM2)],
    ),
    InstructionVariation(
        PMINUB,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        PMINUW,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPMINUB,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPMINUW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPMINUB,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPMINUW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPMINUB,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPMINUB,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPMINUB,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
        ],
    ),
    InstructionVariation(
        VPMINUW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPMINUW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPMINUW,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
        ],
    ),
    InstructionVariation(
        PMINUD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPMINUD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPMINUD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPMINUD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPMINUD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPMINUD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VPMINUQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPMINUQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPMINUQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(PMOVMSKB, &[AnyRegister, Reg64MM]),
    InstructionVariation(PMOVMSKB, &[AnyRegister, Reg128]),
    InstructionVariation(VPMOVMSKB, &[AnyRegister, SpecificRegister(XMM1)]),
    InstructionVariation(VPMOVMSKB, &[AnyRegister, SpecificRegister(YMM1)]),
    InstructionVariation(
        PMOVSXBW,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem64(XMM2)],
    ),
    InstructionVariation(
        PMOVSXBD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem32(XMM2)],
    ),
    InstructionVariation(
        PMOVSXBQ,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem16(XMM2)],
    ),
    InstructionVariation(
        PMOVSXWD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem64(XMM2)],
    ),
    InstructionVariation(
        PMOVSXWQ,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem32(XMM2)],
    ),
    InstructionVariation(
        PMOVSXDQ,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem64(XMM2)],
    ),
    InstructionVariation(
        VPMOVSXBW,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem64(XMM2)],
    ),
    InstructionVariation(
        VPMOVSXBD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem32(XMM2)],
    ),
    InstructionVariation(
        VPMOVSXBQ,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem16(XMM2)],
    ),
    InstructionVariation(
        VPMOVSXWD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem64(XMM2)],
    ),
    InstructionVariation(
        VPMOVSXWQ,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem32(XMM2)],
    ),
    InstructionVariation(
        VPMOVSXDQ,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem64(XMM2)],
    ),
    InstructionVariation(
        VPMOVSXBW,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPMOVSXBD,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem64(XMM2)],
    ),
    InstructionVariation(
        VPMOVSXBQ,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem32(XMM2)],
    ),
    InstructionVariation(
        VPMOVSXWD,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPMOVSXWQ,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem64(XMM2)],
    ),
    InstructionVariation(
        VPMOVSXDQ,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPMOVSXBW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem64(XMM2),
        ],
    ),
    InstructionVariation(
        VPMOVSXBW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128(XMM2),
        ],
    ),
    InstructionVariation(
        VPMOVSXBW,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256(YMM2),
        ],
    ),
    InstructionVariation(
        VPMOVSXBD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem32(XMM2),
        ],
    ),
    InstructionVariation(
        VPMOVSXBD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem64(XMM2),
        ],
    ),
    InstructionVariation(
        VPMOVSXBD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128(XMM2),
        ],
    ),
    InstructionVariation(
        VPMOVSXBQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem16(XMM2),
        ],
    ),
    InstructionVariation(
        VPMOVSXBQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem32(XMM2),
        ],
    ),
    InstructionVariation(
        VPMOVSXBQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem64(XMM2),
        ],
    ),
    InstructionVariation(
        VPMOVSXWD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem64(XMM2),
        ],
    ),
    InstructionVariation(
        VPMOVSXWD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128(XMM2),
        ],
    ),
    InstructionVariation(
        VPMOVSXWD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256(YMM2),
        ],
    ),
    InstructionVariation(
        VPMOVSXWQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem32(XMM2),
        ],
    ),
    InstructionVariation(
        VPMOVSXWQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem64(XMM2),
        ],
    ),
    InstructionVariation(
        VPMOVSXWQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128(XMM2),
        ],
    ),
    InstructionVariation(
        VPMOVSXDQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem64(XMM2),
        ],
    ),
    InstructionVariation(
        VPMOVSXDQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128(XMM2),
        ],
    ),
    InstructionVariation(
        VPMOVSXDQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256(YMM2),
        ],
    ),
    InstructionVariation(
        PMOVZXBW,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem64(XMM2)],
    ),
    InstructionVariation(
        PMOVZXBD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem32(XMM2)],
    ),
    InstructionVariation(
        PMOVZXBQ,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem16(XMM2)],
    ),
    InstructionVariation(
        PMOVZXWD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem64(XMM2)],
    ),
    InstructionVariation(
        PMOVZXWQ,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem32(XMM2)],
    ),
    InstructionVariation(
        PMOVZXDQ,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem64(XMM2)],
    ),
    InstructionVariation(
        VPMOVZXBW,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem64(XMM2)],
    ),
    InstructionVariation(
        VPMOVZXBD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem32(XMM2)],
    ),
    InstructionVariation(
        VPMOVZXBQ,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem16(XMM2)],
    ),
    InstructionVariation(
        VPMOVZXWD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem64(XMM2)],
    ),
    InstructionVariation(
        VPMOVZXWQ,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem32(XMM2)],
    ),
    InstructionVariation(
        VPMOVZXDQ,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem64(XMM2)],
    ),
    InstructionVariation(
        VPMOVZXBW,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPMOVZXBD,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem64(XMM2)],
    ),
    InstructionVariation(
        VPMOVZXBQ,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem32(XMM2)],
    ),
    InstructionVariation(
        VPMOVZXWD,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPMOVZXWQ,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem64(XMM2)],
    ),
    InstructionVariation(
        VPMOVZXDQ,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPMOVZXBW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem64(XMM2),
        ],
    ),
    InstructionVariation(
        VPMOVZXBW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128(XMM2),
        ],
    ),
    InstructionVariation(
        VPMOVZXBW,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256(YMM2),
        ],
    ),
    InstructionVariation(
        VPMOVZXBD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem32(XMM2),
        ],
    ),
    InstructionVariation(
        VPMOVZXBD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem64(XMM2),
        ],
    ),
    InstructionVariation(
        VPMOVZXBD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128(XMM2),
        ],
    ),
    InstructionVariation(
        VPMOVZXBQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem16(XMM2),
        ],
    ),
    InstructionVariation(
        VPMOVZXBQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem32(XMM2),
        ],
    ),
    InstructionVariation(
        VPMOVZXBQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem64(XMM2),
        ],
    ),
    InstructionVariation(
        VPMOVZXWD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem64(XMM2),
        ],
    ),
    InstructionVariation(
        VPMOVZXWD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128(XMM2),
        ],
    ),
    InstructionVariation(
        VPMOVZXWD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256(YMM2),
        ],
    ),
    InstructionVariation(
        VPMOVZXWQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem32(XMM2),
        ],
    ),
    InstructionVariation(
        VPMOVZXWQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem64(XMM2),
        ],
    ),
    InstructionVariation(
        VPMOVZXWQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128(XMM2),
        ],
    ),
    InstructionVariation(
        PMULDQ,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPMULDQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPMULDQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPMULDQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPMULDQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPMULDQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        PMULHRSW,
        &[SpecificRegister(MM1), SpecificRegisterOrMem64(MM2)],
    ),
    InstructionVariation(
        PMULHRSW,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPMULHRSW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPMULHRSW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPMULHRSW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPMULHRSW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPMULHRSW,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
        ],
    ),
    InstructionVariation(
        PMULHUW,
        &[SpecificRegister(MM1), SpecificRegisterOrMem64(MM2)],
    ),
    InstructionVariation(
        PMULHUW,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPMULHUW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPMULHUW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPMULHUW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPMULHUW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPMULHUW,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
        ],
    ),
    InstructionVariation(PMULHW, &[Reg64MM, Reg64MMOrMem64]),
    InstructionVariation(
        PMULHW,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPMULHW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPMULHW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPMULHW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPMULHW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPMULHW,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
        ],
    ),
    InstructionVariation(
        PMULLD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPMULLD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPMULLD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPMULLD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPMULLD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPMULLD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VPMULLQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPMULLQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPMULLQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(PMULLW, &[Reg64MM, Reg64MMOrMem64]),
    InstructionVariation(
        PMULLW,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPMULLW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPMULLW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPMULLW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPMULLW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPMULLW,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
        ],
    ),
    InstructionVariation(
        PMULUDQ,
        &[SpecificRegister(MM1), SpecificRegisterOrMem64(MM2)],
    ),
    InstructionVariation(
        PMULUDQ,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPMULUDQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPMULUDQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPMULUDQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPMULUDQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPMULUDQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(POP, &[RegOrMem16]),
    InstructionVariation(POP, &[RegOrMem32]),
    InstructionVariation(POP, &[RegOrMem64]),
    InstructionVariation(POP, &[Reg16]),
    InstructionVariation(POP, &[Reg32]),
    InstructionVariation(POP, &[Reg64]),
    InstructionVariation(POP, &[SpecificRegister(DS)]),
    InstructionVariation(POP, &[SpecificRegister(ES)]),
    InstructionVariation(POP, &[SpecificRegister(SS)]),
    InstructionVariation(POP, &[SpecificRegister(FS)]),
    InstructionVariation(POP, &[SpecificRegister(FS)]),
    InstructionVariation(POP, &[SpecificRegister(FS)]),
    InstructionVariation(POP, &[SpecificRegister(GS)]),
    InstructionVariation(POP, &[SpecificRegister(GS)]),
    InstructionVariation(POP, &[SpecificRegister(GS)]),
    InstructionVariation(POPA, &[]),
    InstructionVariation(POPAD, &[]),
    InstructionVariation(POPCNT, &[Reg16, RegOrMem16]),
    InstructionVariation(POPCNT, &[Reg32, RegOrMem32]),
    InstructionVariation(POPCNT, &[Reg64, RegOrMem64]),
    InstructionVariation(POPF, &[]),
    InstructionVariation(POPFD, &[]),
    InstructionVariation(POPFQ, &[]),
    InstructionVariation(POR, &[Reg64MM, Reg64MMOrMem64]),
    InstructionVariation(
        POR,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPOR,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPOR,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPORD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPORD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPORD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VPORQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPORQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPORQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(PREFETCHT0, &[Mem8]),
    InstructionVariation(PREFETCHT1, &[Mem8]),
    InstructionVariation(PREFETCHT2, &[Mem8]),
    InstructionVariation(PREFETCHNTA, &[Mem8]),
    InstructionVariation(PREFETCHW, &[Mem8]),
    InstructionVariation(PREFETCHWT1, &[Mem8]),
    InstructionVariation(
        PSADBW,
        &[SpecificRegister(MM1), SpecificRegisterOrMem64(MM2)],
    ),
    InstructionVariation(
        PSADBW,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPSADBW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSADBW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPSADBW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSADBW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPSADBW,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
        ],
    ),
    InstructionVariation(
        PSHUFB,
        &[SpecificRegister(MM1), SpecificRegisterOrMem64(MM2)],
    ),
    InstructionVariation(
        PSHUFB,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPSHUFB,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSHUFB,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPSHUFB,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSHUFB,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPSHUFB,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
        ],
    ),
    InstructionVariation(
        PSHUFD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2), Imm8],
    ),
    InstructionVariation(
        VPSHUFD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2), Imm8],
    ),
    InstructionVariation(
        VPSHUFD,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem256(YMM2), Imm8],
    ),
    InstructionVariation(
        VPSHUFD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem32Bcst(XMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPSHUFD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem32Bcst(YMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPSHUFD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        PSHUFHW,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2), Imm8],
    ),
    InstructionVariation(
        VPSHUFHW,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2), Imm8],
    ),
    InstructionVariation(
        VPSHUFHW,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem256(YMM2), Imm8],
    ),
    InstructionVariation(
        VPSHUFHW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128(XMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPSHUFHW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256(YMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPSHUFHW,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512(ZMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        PSHUFLW,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2), Imm8],
    ),
    InstructionVariation(
        VPSHUFLW,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2), Imm8],
    ),
    InstructionVariation(
        VPSHUFLW,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem256(YMM2), Imm8],
    ),
    InstructionVariation(
        VPSHUFLW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128(XMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPSHUFLW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256(YMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPSHUFLW,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512(ZMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        PSHUFW,
        &[SpecificRegister(MM1), SpecificRegisterOrMem64(MM2), Imm8],
    ),
    InstructionVariation(
        PSIGNB,
        &[SpecificRegister(MM1), SpecificRegisterOrMem64(MM2)],
    ),
    InstructionVariation(
        PSIGNB,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        PSIGNW,
        &[SpecificRegister(MM1), SpecificRegisterOrMem64(MM2)],
    ),
    InstructionVariation(
        PSIGNW,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        PSIGND,
        &[SpecificRegister(MM1), SpecificRegisterOrMem64(MM2)],
    ),
    InstructionVariation(
        PSIGND,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPSIGNB,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSIGNW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSIGND,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSIGNB,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPSIGNW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPSIGND,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(PSLLDQ, &[SpecificRegister(XMM1), Imm8]),
    InstructionVariation(
        VPSLLDQ,
        &[SpecificRegister(XMM1), SpecificRegister(XMM2), Imm8],
    ),
    InstructionVariation(
        VPSLLDQ,
        &[SpecificRegister(YMM1), SpecificRegister(YMM2), Imm8],
    ),
    InstructionVariation(
        VPSLLDQ,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2), Imm8],
    ),
    InstructionVariation(
        VPSLLDQ,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem256(YMM2), Imm8],
    ),
    InstructionVariation(
        VPSLLDQ,
        &[SpecificRegister(ZMM1), SpecificRegisterOrMem512(ZMM2), Imm8],
    ),
    InstructionVariation(PSLLW, &[Reg64MM, Reg64MMOrMem64]),
    InstructionVariation(
        PSLLW,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(PSLLW, &[SpecificRegister(MM1), Imm8]),
    InstructionVariation(PSLLW, &[SpecificRegister(XMM1), Imm8]),
    InstructionVariation(PSLLD, &[Reg64MM, Reg64MMOrMem64]),
    InstructionVariation(
        PSLLD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(PSLLD, &[Reg64MM, Imm8]),
    InstructionVariation(PSLLD, &[SpecificRegister(XMM1), Imm8]),
    InstructionVariation(PSLLQ, &[Reg64MM, Reg64MMOrMem64]),
    InstructionVariation(
        PSLLQ,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(PSLLQ, &[Reg64MM, Imm8]),
    InstructionVariation(PSLLQ, &[SpecificRegister(XMM1), Imm8]),
    InstructionVariation(
        VPSLLW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSLLW,
        &[SpecificRegister(XMM1), SpecificRegister(XMM2), Imm8],
    ),
    InstructionVariation(
        VPSLLD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSLLD,
        &[SpecificRegister(XMM1), SpecificRegister(XMM2), Imm8],
    ),
    InstructionVariation(
        VPSLLQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSLLQ,
        &[SpecificRegister(XMM1), SpecificRegister(XMM2), Imm8],
    ),
    InstructionVariation(
        VPSLLW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSLLW,
        &[SpecificRegister(YMM1), SpecificRegister(YMM2), Imm8],
    ),
    InstructionVariation(
        VPSLLD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSLLD,
        &[SpecificRegister(YMM1), SpecificRegister(YMM2), Imm8],
    ),
    InstructionVariation(
        VPSLLQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSLLQ,
        &[SpecificRegister(YMM1), SpecificRegister(YMM2), Imm8],
    ),
    InstructionVariation(
        VPSLLW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSLLW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSLLW,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSLLW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128(XMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPSLLW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256(YMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPSLLW,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512(ZMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPSLLD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSLLD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSLLD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSLLD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem32Bcst(XMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPSLLD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem32Bcst(YMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPSLLD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPSLLQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSLLQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSLLQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(PSRAW, &[Reg64MM, Reg64MMOrMem64]),
    InstructionVariation(
        PSRAW,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(PSRAW, &[Reg64MM, Imm8]),
    InstructionVariation(PSRAW, &[SpecificRegister(XMM1), Imm8]),
    InstructionVariation(PSRAD, &[Reg64MM, Reg64MMOrMem64]),
    InstructionVariation(
        PSRAD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(PSRAD, &[Reg64MM, Imm8]),
    InstructionVariation(PSRAD, &[SpecificRegister(XMM1), Imm8]),
    InstructionVariation(
        VPSRAW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSRAW,
        &[SpecificRegister(XMM1), SpecificRegister(XMM2), Imm8],
    ),
    InstructionVariation(
        VPSRAD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSRAD,
        &[SpecificRegister(XMM1), SpecificRegister(XMM2), Imm8],
    ),
    InstructionVariation(
        VPSRAW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSRAW,
        &[SpecificRegister(YMM1), SpecificRegister(YMM2), Imm8],
    ),
    InstructionVariation(
        VPSRAD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSRAD,
        &[SpecificRegister(YMM1), SpecificRegister(YMM2), Imm8],
    ),
    InstructionVariation(
        VPSRAW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSRAW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSRAW,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSRAW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128(XMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPSRAW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256(YMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPSRAW,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512(ZMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPSRAD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSRAD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSRAD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSRAD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem32Bcst(XMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPSRAD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem32Bcst(YMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPSRAD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPSRAQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSRAQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSRAQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSRAQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem64Bcst(XMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPSRAQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem64Bcst(YMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPSRAQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM2),
            Imm8,
        ],
    ),
    InstructionVariation(PSRLDQ, &[SpecificRegister(XMM1), Imm8]),
    InstructionVariation(
        VPSRLDQ,
        &[SpecificRegister(XMM1), SpecificRegister(XMM2), Imm8],
    ),
    InstructionVariation(
        VPSRLDQ,
        &[SpecificRegister(YMM1), SpecificRegister(YMM2), Imm8],
    ),
    InstructionVariation(
        VPSRLDQ,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2), Imm8],
    ),
    InstructionVariation(
        VPSRLDQ,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem256(YMM2), Imm8],
    ),
    InstructionVariation(
        VPSRLDQ,
        &[SpecificRegister(ZMM1), SpecificRegisterOrMem512(ZMM2), Imm8],
    ),
    InstructionVariation(PSRLW, &[Reg64MM, Reg64MMOrMem64]),
    InstructionVariation(
        PSRLW,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(PSRLW, &[Reg64MM, Imm8]),
    InstructionVariation(PSRLW, &[SpecificRegister(XMM1), Imm8]),
    InstructionVariation(PSRLD, &[Reg64MM, Reg64MMOrMem64]),
    InstructionVariation(
        PSRLD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(PSRLD, &[Reg64MM, Imm8]),
    InstructionVariation(PSRLD, &[SpecificRegister(XMM1), Imm8]),
    InstructionVariation(PSRLQ, &[Reg64MM, Reg64MMOrMem64]),
    InstructionVariation(
        PSRLQ,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(PSRLQ, &[Reg64MM, Imm8]),
    InstructionVariation(PSRLQ, &[SpecificRegister(XMM1), Imm8]),
    InstructionVariation(
        VPSRLW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSRLW,
        &[SpecificRegister(XMM1), SpecificRegister(XMM2), Imm8],
    ),
    InstructionVariation(
        VPSRLD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSRLD,
        &[SpecificRegister(XMM1), SpecificRegister(XMM2), Imm8],
    ),
    InstructionVariation(
        VPSRLQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSRLQ,
        &[SpecificRegister(XMM1), SpecificRegister(XMM2), Imm8],
    ),
    InstructionVariation(
        VPSRLW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSRLW,
        &[SpecificRegister(YMM1), SpecificRegister(YMM2), Imm8],
    ),
    InstructionVariation(
        VPSRLD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSRLD,
        &[SpecificRegister(YMM1), SpecificRegister(YMM2), Imm8],
    ),
    InstructionVariation(
        VPSRLQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSRLQ,
        &[SpecificRegister(YMM1), SpecificRegister(YMM2), Imm8],
    ),
    InstructionVariation(
        VPSRLW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSRLW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSRLW,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSRLW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128(XMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPSRLW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256(YMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPSRLW,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512(ZMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPSRLD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSRLD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSRLD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSRLD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem32Bcst(XMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPSRLD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem32Bcst(YMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPSRLD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPSRLQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSRLQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSRLQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(PSUBB, &[Reg64MM, Reg64MMOrMem64]),
    InstructionVariation(
        PSUBB,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(PSUBW, &[Reg64MM, Reg64MMOrMem64]),
    InstructionVariation(
        PSUBW,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(PSUBD, &[Reg64MM, Reg64MMOrMem64]),
    InstructionVariation(
        PSUBD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPSUBB,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSUBW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSUBD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSUBB,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPSUBW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPSUBD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPSUBB,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSUBB,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPSUBB,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
        ],
    ),
    InstructionVariation(
        VPSUBW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSUBW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPSUBW,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
        ],
    ),
    InstructionVariation(
        PSUBQ,
        &[SpecificRegister(MM1), SpecificRegisterOrMem64(MM2)],
    ),
    InstructionVariation(
        PSUBQ,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPSUBQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSUBQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPSUBQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPSUBQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPSUBQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(PSUBSB, &[Reg64MM, Reg64MMOrMem64]),
    InstructionVariation(
        PSUBSB,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(PSUBSW, &[Reg64MM, Reg64MMOrMem64]),
    InstructionVariation(
        PSUBSW,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPSUBSB,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSUBSW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSUBSB,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPSUBSW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPSUBSB,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSUBSB,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPSUBSB,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
        ],
    ),
    InstructionVariation(
        VPSUBSW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSUBSW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(PSUBUSB, &[Reg64MM, Reg64MMOrMem64]),
    InstructionVariation(
        PSUBUSB,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(PSUBUSW, &[Reg64MM, Reg64MMOrMem64]),
    InstructionVariation(
        PSUBUSW,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPSUBUSB,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSUBUSW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSUBUSB,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPSUBUSW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPSUBUSB,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSUBUSB,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPSUBUSB,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
        ],
    ),
    InstructionVariation(
        VPSUBUSW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSUBUSW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        PTEST,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPTEST,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPTEST,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem256(YMM2)],
    ),
    InstructionVariation(PTWRITE, &[Reg64]),
    InstructionVariation(PTWRITE, &[RegOrMem32]),
    InstructionVariation(PUNPCKHBW, &[Reg64MM, Reg64MMOrMem64]),
    InstructionVariation(
        PUNPCKHBW,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(PUNPCKHWD, &[Reg64MM, Reg64MMOrMem64]),
    InstructionVariation(
        PUNPCKHWD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(PUNPCKHDQ, &[Reg64MM, Reg64MMOrMem64]),
    InstructionVariation(
        PUNPCKHDQ,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        PUNPCKHQDQ,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPUNPCKHBW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPUNPCKHWD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPUNPCKHDQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPUNPCKHQDQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPUNPCKHBW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPUNPCKHWD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPUNPCKHDQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPUNPCKHQDQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPUNPCKHBW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPUNPCKHWD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPUNPCKHDQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPUNPCKHQDQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(PUNPCKLBW, &[Reg64MM, Reg64MMOrMem32]),
    InstructionVariation(
        PUNPCKLBW,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(PUNPCKLWD, &[Reg64MM, Reg64MMOrMem32]),
    InstructionVariation(
        PUNPCKLWD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(PUNPCKLDQ, &[Reg64MM, Reg64MMOrMem32]),
    InstructionVariation(
        PUNPCKLDQ,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        PUNPCKLQDQ,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPUNPCKLBW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPUNPCKLWD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPUNPCKLDQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPUNPCKLQDQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPUNPCKLBW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPUNPCKLWD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPUNPCKLDQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPUNPCKLQDQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPUNPCKLBW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPUNPCKLWD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPUNPCKLDQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPUNPCKLQDQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(PUSH, &[RegOrMem16]),
    InstructionVariation(PUSH, &[RegOrMem32]),
    InstructionVariation(PUSH, &[RegOrMem64]),
    InstructionVariation(PUSH, &[Reg16]),
    InstructionVariation(PUSH, &[Reg32]),
    InstructionVariation(PUSH, &[Reg64]),
    InstructionVariation(PUSH, &[Imm8]),
    InstructionVariation(PUSH, &[Imm16]),
    InstructionVariation(PUSH, &[Imm32]),
    InstructionVariation(PUSH, &[SpecificRegister(CS)]),
    InstructionVariation(PUSH, &[SpecificRegister(SS)]),
    InstructionVariation(PUSH, &[SpecificRegister(DS)]),
    InstructionVariation(PUSH, &[SpecificRegister(ES)]),
    InstructionVariation(PUSH, &[SpecificRegister(FS)]),
    InstructionVariation(PUSH, &[SpecificRegister(GS)]),
    InstructionVariation(PUSHA, &[]),
    InstructionVariation(PUSHAD, &[]),
    InstructionVariation(PUSHF, &[]),
    InstructionVariation(PUSHFD, &[]),
    InstructionVariation(PUSHFQ, &[]),
    InstructionVariation(PXOR, &[Reg64MM, Reg64MMOrMem64]),
    InstructionVariation(
        PXOR,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VPXOR,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPXOR,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPXORD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPXORD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPXORD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VPXORQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPXORQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPXORQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(RCL, &[RegOrMem8]),
    InstructionVariation(RCL, &[RegOrMem8]),
    InstructionVariation(RCL, &[RegOrMem8, SpecificRegister(CL)]),
    InstructionVariation(RCL, &[RegOrMem8, SpecificRegister(CL)]),
    InstructionVariation(RCL, &[RegOrMem8, Imm8]),
    InstructionVariation(RCL, &[RegOrMem8, Imm8]),
    InstructionVariation(RCL, &[RegOrMem16]),
    InstructionVariation(RCL, &[RegOrMem16, SpecificRegister(CL)]),
    InstructionVariation(RCL, &[RegOrMem16, Imm8]),
    InstructionVariation(RCL, &[RegOrMem32]),
    InstructionVariation(RCL, &[RegOrMem64]),
    InstructionVariation(RCL, &[RegOrMem32, SpecificRegister(CL)]),
    InstructionVariation(RCL, &[RegOrMem64, SpecificRegister(CL)]),
    InstructionVariation(RCL, &[RegOrMem32, Imm8]),
    InstructionVariation(RCL, &[RegOrMem64, Imm8]),
    InstructionVariation(RCR, &[RegOrMem8]),
    InstructionVariation(RCR, &[RegOrMem8]),
    InstructionVariation(RCR, &[RegOrMem8, SpecificRegister(CL)]),
    InstructionVariation(RCR, &[RegOrMem8, SpecificRegister(CL)]),
    InstructionVariation(RCR, &[RegOrMem8, Imm8]),
    InstructionVariation(RCR, &[RegOrMem8, Imm8]),
    InstructionVariation(RCR, &[RegOrMem16]),
    InstructionVariation(RCR, &[RegOrMem16, SpecificRegister(CL)]),
    InstructionVariation(RCR, &[RegOrMem16, Imm8]),
    InstructionVariation(RCR, &[RegOrMem32]),
    InstructionVariation(RCR, &[RegOrMem64]),
    InstructionVariation(RCR, &[RegOrMem32, SpecificRegister(CL)]),
    InstructionVariation(RCR, &[RegOrMem64, SpecificRegister(CL)]),
    InstructionVariation(RCR, &[RegOrMem32, Imm8]),
    InstructionVariation(RCR, &[RegOrMem64, Imm8]),
    InstructionVariation(ROL, &[RegOrMem8]),
    InstructionVariation(ROL, &[RegOrMem8]),
    InstructionVariation(ROL, &[RegOrMem8, SpecificRegister(CL)]),
    InstructionVariation(ROL, &[RegOrMem8, SpecificRegister(CL)]),
    InstructionVariation(ROL, &[RegOrMem8, Imm8]),
    InstructionVariation(ROL, &[RegOrMem8, Imm8]),
    InstructionVariation(ROL, &[RegOrMem16]),
    InstructionVariation(ROL, &[RegOrMem16, SpecificRegister(CL)]),
    InstructionVariation(ROL, &[RegOrMem16, Imm8]),
    InstructionVariation(ROL, &[RegOrMem32]),
    InstructionVariation(ROL, &[RegOrMem64]),
    InstructionVariation(ROL, &[RegOrMem32, SpecificRegister(CL)]),
    InstructionVariation(ROL, &[RegOrMem64, SpecificRegister(CL)]),
    InstructionVariation(ROL, &[RegOrMem32, Imm8]),
    InstructionVariation(ROL, &[RegOrMem64, Imm8]),
    InstructionVariation(ROR, &[RegOrMem8]),
    InstructionVariation(ROR, &[RegOrMem8]),
    InstructionVariation(ROR, &[RegOrMem8, SpecificRegister(CL)]),
    InstructionVariation(ROR, &[RegOrMem8, SpecificRegister(CL)]),
    InstructionVariation(ROR, &[RegOrMem8, Imm8]),
    InstructionVariation(ROR, &[RegOrMem8, Imm8]),
    InstructionVariation(ROR, &[RegOrMem16]),
    InstructionVariation(ROR, &[RegOrMem16, SpecificRegister(CL)]),
    InstructionVariation(ROR, &[RegOrMem16, Imm8]),
    InstructionVariation(ROR, &[RegOrMem32]),
    InstructionVariation(ROR, &[RegOrMem64]),
    InstructionVariation(ROR, &[RegOrMem32, SpecificRegister(CL)]),
    InstructionVariation(ROR, &[RegOrMem64, SpecificRegister(CL)]),
    InstructionVariation(ROR, &[RegOrMem32, Imm8]),
    InstructionVariation(ROR, &[RegOrMem64, Imm8]),
    InstructionVariation(
        RCPPS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VRCPPS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VRCPPS,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem256(YMM2)],
    ),
    InstructionVariation(
        RCPSS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem32(XMM2)],
    ),
    InstructionVariation(
        VRCPSS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(RDFSBASE, &[Reg32]),
    InstructionVariation(RDFSBASE, &[Reg64]),
    InstructionVariation(RDGSBASE, &[Reg32]),
    InstructionVariation(RDGSBASE, &[Reg64]),
    InstructionVariation(RDMSR, &[]),
    InstructionVariation(RDPID, &[Reg32]),
    InstructionVariation(RDPID, &[Reg64]),
    InstructionVariation(RDPKRU, &[]),
    InstructionVariation(RDPMC, &[]),
    InstructionVariation(RDRAND, &[Reg16]),
    InstructionVariation(RDRAND, &[Reg32]),
    InstructionVariation(RDRAND, &[Reg64]),
    InstructionVariation(RDSEED, &[Reg16]),
    InstructionVariation(RDSEED, &[Reg32]),
    InstructionVariation(RDSEED, &[Reg64]),
    InstructionVariation(RDTSC, &[]),
    InstructionVariation(RDTSCP, &[]),
    InstructionVariation(RET, &[]),
    InstructionVariation(RET, &[]),
    InstructionVariation(RET, &[Imm16]),
    InstructionVariation(RET, &[Imm16]),
    InstructionVariation(RORX, &[Reg32, RegOrMem32, Imm8]),
    InstructionVariation(RORX, &[Reg64, RegOrMem64, Imm8]),
    InstructionVariation(
        ROUNDPD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2), Imm8],
    ),
    InstructionVariation(
        VROUNDPD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2), Imm8],
    ),
    InstructionVariation(
        VROUNDPD,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem256(YMM2), Imm8],
    ),
    InstructionVariation(
        ROUNDPS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2), Imm8],
    ),
    InstructionVariation(
        VROUNDPS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2), Imm8],
    ),
    InstructionVariation(
        VROUNDPS,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem256(YMM2), Imm8],
    ),
    InstructionVariation(
        ROUNDSD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem64(XMM2), Imm8],
    ),
    InstructionVariation(
        VROUNDSD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        ROUNDSS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem32(XMM2), Imm8],
    ),
    InstructionVariation(
        VROUNDSS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(RSM, &[]),
    InstructionVariation(
        RSQRTPS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VRSQRTPS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VRSQRTPS,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem256(YMM2)],
    ),
    InstructionVariation(
        RSQRTSS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem32(XMM2)],
    ),
    InstructionVariation(
        VRSQRTSS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(SAHF, &[]),
    InstructionVariation(SAL, &[RegOrMem8]),
    InstructionVariation(SAL, &[RegOrMem8]),
    InstructionVariation(SAL, &[RegOrMem8, SpecificRegister(CL)]),
    InstructionVariation(SAL, &[RegOrMem8, SpecificRegister(CL)]),
    InstructionVariation(SAL, &[RegOrMem8, Imm8]),
    InstructionVariation(SAL, &[RegOrMem8, Imm8]),
    InstructionVariation(SAL, &[RegOrMem16]),
    InstructionVariation(SAL, &[RegOrMem16, SpecificRegister(CL)]),
    InstructionVariation(SAL, &[RegOrMem16, Imm8]),
    InstructionVariation(SAL, &[RegOrMem32]),
    InstructionVariation(SAL, &[RegOrMem64]),
    InstructionVariation(SAL, &[RegOrMem32, SpecificRegister(CL)]),
    InstructionVariation(SAL, &[RegOrMem64, SpecificRegister(CL)]),
    InstructionVariation(SAL, &[RegOrMem32, Imm8]),
    InstructionVariation(SAL, &[RegOrMem64, Imm8]),
    InstructionVariation(SAR, &[RegOrMem8]),
    InstructionVariation(SAR, &[RegOrMem8]),
    InstructionVariation(SAR, &[RegOrMem8, SpecificRegister(CL)]),
    InstructionVariation(SAR, &[RegOrMem8, SpecificRegister(CL)]),
    InstructionVariation(SAR, &[RegOrMem8, Imm8]),
    InstructionVariation(SAR, &[RegOrMem8, Imm8]),
    InstructionVariation(SAR, &[RegOrMem16]),
    InstructionVariation(SAR, &[RegOrMem16, SpecificRegister(CL)]),
    InstructionVariation(SAR, &[RegOrMem16, Imm8]),
    InstructionVariation(SAR, &[RegOrMem32]),
    InstructionVariation(SAR, &[RegOrMem64]),
    InstructionVariation(SAR, &[RegOrMem32, SpecificRegister(CL)]),
    InstructionVariation(SAR, &[RegOrMem64, SpecificRegister(CL)]),
    InstructionVariation(SAR, &[RegOrMem32, Imm8]),
    InstructionVariation(SAR, &[RegOrMem64, Imm8]),
    InstructionVariation(SHL, &[RegOrMem8]),
    InstructionVariation(SHL, &[RegOrMem8]),
    InstructionVariation(SHL, &[RegOrMem8, SpecificRegister(CL)]),
    InstructionVariation(SHL, &[RegOrMem8, SpecificRegister(CL)]),
    InstructionVariation(SHL, &[RegOrMem8, Imm8]),
    InstructionVariation(SHL, &[RegOrMem8, Imm8]),
    InstructionVariation(SHL, &[RegOrMem16]),
    InstructionVariation(SHL, &[RegOrMem16, SpecificRegister(CL)]),
    InstructionVariation(SHL, &[RegOrMem16, Imm8]),
    InstructionVariation(SHL, &[RegOrMem32]),
    InstructionVariation(SHL, &[RegOrMem64]),
    InstructionVariation(SHL, &[RegOrMem32, SpecificRegister(CL)]),
    InstructionVariation(SHL, &[RegOrMem64, SpecificRegister(CL)]),
    InstructionVariation(SHL, &[RegOrMem32, Imm8]),
    InstructionVariation(SHL, &[RegOrMem64, Imm8]),
    InstructionVariation(SHR, &[RegOrMem8]),
    InstructionVariation(SHR, &[RegOrMem8]),
    InstructionVariation(SHR, &[RegOrMem8, SpecificRegister(CL)]),
    InstructionVariation(SHR, &[RegOrMem8, SpecificRegister(CL)]),
    InstructionVariation(SHR, &[RegOrMem8, Imm8]),
    InstructionVariation(SHR, &[RegOrMem8, Imm8]),
    InstructionVariation(SHR, &[RegOrMem16]),
    InstructionVariation(SHR, &[RegOrMem16, SpecificRegister(CL)]),
    InstructionVariation(SHR, &[RegOrMem16, Imm8]),
    InstructionVariation(SHR, &[RegOrMem32]),
    InstructionVariation(SHR, &[RegOrMem64]),
    InstructionVariation(SHR, &[RegOrMem32, SpecificRegister(CL)]),
    InstructionVariation(SHR, &[RegOrMem64, SpecificRegister(CL)]),
    InstructionVariation(SHR, &[RegOrMem32, Imm8]),
    InstructionVariation(SHR, &[RegOrMem64, Imm8]),
    InstructionVariation(SARX, &[Reg32a, RegOrMem32, Reg32b]),
    InstructionVariation(SHLX, &[Reg32a, RegOrMem32, Reg32b]),
    InstructionVariation(SHRX, &[Reg32a, RegOrMem32, Reg32b]),
    InstructionVariation(SARX, &[Reg64a, RegOrMem64, Reg64b]),
    InstructionVariation(SHLX, &[Reg64a, RegOrMem64, Reg64b]),
    InstructionVariation(SHRX, &[Reg64a, RegOrMem64, Reg64b]),
    InstructionVariation(SBB, &[SpecificRegister(AL), Imm8]),
    InstructionVariation(SBB, &[SpecificRegister(AX), Imm16]),
    InstructionVariation(SBB, &[SpecificRegister(EAX), Imm32]),
    InstructionVariation(SBB, &[SpecificRegister(RAX), Imm32]),
    InstructionVariation(SBB, &[RegOrMem8, Imm8]),
    InstructionVariation(SBB, &[RegOrMem8, Imm8]),
    InstructionVariation(SBB, &[RegOrMem16, Imm16]),
    InstructionVariation(SBB, &[RegOrMem32, Imm32]),
    InstructionVariation(SBB, &[RegOrMem64, Imm32]),
    InstructionVariation(SBB, &[RegOrMem16, Imm8]),
    InstructionVariation(SBB, &[RegOrMem32, Imm8]),
    InstructionVariation(SBB, &[RegOrMem64, Imm8]),
    InstructionVariation(SBB, &[RegOrMem8, Reg8]),
    InstructionVariation(SBB, &[RegOrMem8, Reg8]),
    InstructionVariation(SBB, &[RegOrMem16, Reg16]),
    InstructionVariation(SBB, &[RegOrMem32, Reg32]),
    InstructionVariation(SBB, &[RegOrMem64, Reg64]),
    InstructionVariation(SBB, &[Reg8, RegOrMem8]),
    InstructionVariation(SBB, &[Reg8, RegOrMem8]),
    InstructionVariation(SBB, &[Reg16, RegOrMem16]),
    InstructionVariation(SBB, &[Reg32, RegOrMem32]),
    InstructionVariation(SBB, &[Reg64, RegOrMem64]),
    InstructionVariation(SCAS, &[Mem8]),
    InstructionVariation(SCAS, &[Mem16]),
    InstructionVariation(SCAS, &[Mem32]),
    InstructionVariation(SCAS, &[Mem64]),
    InstructionVariation(SCASB, &[]),
    InstructionVariation(SCASW, &[]),
    InstructionVariation(SCASD, &[]),
    InstructionVariation(SCASQ, &[]),
    InstructionVariation(SETA, &[RegOrMem8]),
    InstructionVariation(SETA, &[RegOrMem8]),
    InstructionVariation(SETAE, &[RegOrMem8]),
    InstructionVariation(SETAE, &[RegOrMem8]),
    InstructionVariation(SETB, &[RegOrMem8]),
    InstructionVariation(SETB, &[RegOrMem8]),
    InstructionVariation(SETBE, &[RegOrMem8]),
    InstructionVariation(SETBE, &[RegOrMem8]),
    InstructionVariation(SETC, &[RegOrMem8]),
    InstructionVariation(SETC, &[RegOrMem8]),
    InstructionVariation(SETE, &[RegOrMem8]),
    InstructionVariation(SETE, &[RegOrMem8]),
    InstructionVariation(SETG, &[RegOrMem8]),
    InstructionVariation(SETG, &[RegOrMem8]),
    InstructionVariation(SETGE, &[RegOrMem8]),
    InstructionVariation(SETGE, &[RegOrMem8]),
    InstructionVariation(SETL, &[RegOrMem8]),
    InstructionVariation(SETL, &[RegOrMem8]),
    InstructionVariation(SETLE, &[RegOrMem8]),
    InstructionVariation(SETLE, &[RegOrMem8]),
    InstructionVariation(SETNA, &[RegOrMem8]),
    InstructionVariation(SETNA, &[RegOrMem8]),
    InstructionVariation(SETNAE, &[RegOrMem8]),
    InstructionVariation(SETNAE, &[RegOrMem8]),
    InstructionVariation(SETNB, &[RegOrMem8]),
    InstructionVariation(SETNB, &[RegOrMem8]),
    InstructionVariation(SETNBE, &[RegOrMem8]),
    InstructionVariation(SETNBE, &[RegOrMem8]),
    InstructionVariation(SETNC, &[RegOrMem8]),
    InstructionVariation(SETNC, &[RegOrMem8]),
    InstructionVariation(SETNE, &[RegOrMem8]),
    InstructionVariation(SETNE, &[RegOrMem8]),
    InstructionVariation(SETNG, &[RegOrMem8]),
    InstructionVariation(SETNG, &[RegOrMem8]),
    InstructionVariation(SETNGE, &[RegOrMem8]),
    InstructionVariation(SETNGE, &[RegOrMem8]),
    InstructionVariation(SETNL, &[RegOrMem8]),
    InstructionVariation(SETNL, &[RegOrMem8]),
    InstructionVariation(SETNLE, &[RegOrMem8]),
    InstructionVariation(SFENCE, &[]),
    InstructionVariation(SGDT, &[Mem]),
    InstructionVariation(
        SHA1MSG1,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        SHA1MSG2,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        SHA1NEXTE,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        SHA1RNDS4,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2), Imm8],
    ),
    InstructionVariation(
        SHA256MSG1,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        SHA256MSG2,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        SHA256RNDS2,
        &[
            SpecificRegister(XMM1),
            SpecificRegisterOrMem128(XMM2),
            SpecificRegisterOrMem128(XMM0),
        ],
    ),
    InstructionVariation(SHLD, &[RegOrMem16, Reg16, Imm8]),
    InstructionVariation(SHLD, &[RegOrMem16, Reg16, SpecificRegister(CL)]),
    InstructionVariation(SHLD, &[RegOrMem32, Reg32, Imm8]),
    InstructionVariation(SHLD, &[RegOrMem64, Reg64, Imm8]),
    InstructionVariation(SHLD, &[RegOrMem32, Reg32, SpecificRegister(CL)]),
    InstructionVariation(SHLD, &[RegOrMem64, Reg64, SpecificRegister(CL)]),
    InstructionVariation(SHRD, &[RegOrMem16, Reg16, Imm8]),
    InstructionVariation(SHRD, &[RegOrMem16, Reg16, SpecificRegister(CL)]),
    InstructionVariation(SHRD, &[RegOrMem32, Reg32, Imm8]),
    InstructionVariation(SHRD, &[RegOrMem64, Reg64, Imm8]),
    InstructionVariation(SHRD, &[RegOrMem32, Reg32, SpecificRegister(CL)]),
    InstructionVariation(SHRD, &[RegOrMem64, Reg64, SpecificRegister(CL)]),
    InstructionVariation(
        SHUFPD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2), Imm8],
    ),
    InstructionVariation(
        VSHUFPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VSHUFPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VSHUFPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VSHUFPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VSHUFPD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        SHUFPS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM3), Imm8],
    ),
    InstructionVariation(
        VSHUFPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VSHUFPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VSHUFPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VSHUFPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VSHUFPS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
            Imm8,
        ],
    ),
    InstructionVariation(SIDT, &[Mem]),
    InstructionVariation(SLDT, &[RegOrMem16]),
    InstructionVariation(SLDT, &[Reg64OrMem16]),
    InstructionVariation(SMSW, &[RegOrMem16]),
    InstructionVariation(SMSW, &[Reg32OrMem16]),
    InstructionVariation(SMSW, &[Reg64OrMem16]),
    InstructionVariation(
        SQRTPD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VSQRTPD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VSQRTPD,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem256(YMM2)],
    ),
    InstructionVariation(
        VSQRTPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem32Bcst(XMM2),
        ],
    ),
    InstructionVariation(
        VSQRTPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem32Bcst(YMM2),
        ],
    ),
    InstructionVariation(
        VSQRTPD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM2),
        ],
    ),
    InstructionVariation(
        SQRTPS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VSQRTPS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VSQRTPS,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem256(YMM2)],
    ),
    InstructionVariation(
        VSQRTPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem32Bcst(XMM2),
        ],
    ),
    InstructionVariation(
        VSQRTPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem32Bcst(YMM2),
        ],
    ),
    InstructionVariation(
        VSQRTPS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM2),
        ],
    ),
    InstructionVariation(
        SQRTSD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem64(XMM2)],
    ),
    InstructionVariation(
        VSQRTSD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
        ],
    ),
    InstructionVariation(
        VSQRTSD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
        ],
    ),
    InstructionVariation(
        SQRTSS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem32(XMM2)],
    ),
    InstructionVariation(
        VSQRTSS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(
        VSQRTSS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(STAC, &[]),
    InstructionVariation(STC, &[]),
    InstructionVariation(STD, &[]),
    InstructionVariation(STI, &[]),
    InstructionVariation(STMXCSR, &[Mem32]),
    InstructionVariation(VSTMXCSR, &[Mem32]),
    InstructionVariation(STOS, &[Mem8]),
    InstructionVariation(STOS, &[Mem16]),
    InstructionVariation(STOS, &[Mem32]),
    InstructionVariation(STOS, &[Mem64]),
    InstructionVariation(STOSB, &[]),
    InstructionVariation(STOSW, &[]),
    InstructionVariation(STOSD, &[]),
    InstructionVariation(STOS, &[]),
    InstructionVariation(STR, &[RegOrMem16]),
    InstructionVariation(SUB, &[SpecificRegister(AL), Imm8]),
    InstructionVariation(SUB, &[SpecificRegister(AX), Imm16]),
    InstructionVariation(SUB, &[SpecificRegister(EAX), Imm32]),
    InstructionVariation(SUB, &[SpecificRegister(RAX), Imm32]),
    InstructionVariation(SUB, &[RegOrMem8, Imm8]),
    InstructionVariation(SUB, &[RegOrMem8, Imm8]),
    InstructionVariation(SUB, &[RegOrMem16, Imm16]),
    InstructionVariation(SUB, &[RegOrMem32, Imm32]),
    InstructionVariation(SUB, &[RegOrMem64, Imm32]),
    InstructionVariation(SUB, &[RegOrMem16, Imm8]),
    InstructionVariation(SUB, &[RegOrMem32, Imm8]),
    InstructionVariation(SUB, &[RegOrMem64, Imm8]),
    InstructionVariation(SUB, &[RegOrMem8, Reg8]),
    InstructionVariation(SUB, &[RegOrMem8, Reg8]),
    InstructionVariation(SUB, &[RegOrMem16, Reg16]),
    InstructionVariation(SUB, &[RegOrMem32, Reg32]),
    InstructionVariation(SUB, &[RegOrMem64, Reg64]),
    InstructionVariation(SUB, &[Reg8, RegOrMem8]),
    InstructionVariation(SUB, &[Reg8, RegOrMem8]),
    InstructionVariation(SUB, &[Reg16, RegOrMem16]),
    InstructionVariation(SUB, &[Reg32, RegOrMem32]),
    InstructionVariation(SUB, &[Reg64, RegOrMem64]),
    InstructionVariation(
        SUBPD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VSUBPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VSUBPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VSUBPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VSUBPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VSUBPD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        SUBPS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VSUBPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VSUBPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VSUBPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VSUBPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VSUBPS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        SUBSD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem64(XMM2)],
    ),
    InstructionVariation(
        VSUBSD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
        ],
    ),
    InstructionVariation(
        VSUBSD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
        ],
    ),
    InstructionVariation(
        SUBSS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem32(XMM2)],
    ),
    InstructionVariation(
        VSUBSS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(
        VSUBSS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(SWAPGS, &[]),
    InstructionVariation(SYSCALL, &[]),
    InstructionVariation(SYSENTER, &[]),
    InstructionVariation(SYSEXIT, &[]),
    InstructionVariation(SYSEXIT, &[]),
    InstructionVariation(SYSRET, &[]),
    InstructionVariation(SYSRET, &[]),
    InstructionVariation(TEST, &[SpecificRegister(AL), Imm8]),
    InstructionVariation(TEST, &[SpecificRegister(AX), Imm16]),
    InstructionVariation(TEST, &[SpecificRegister(EAX), Imm32]),
    InstructionVariation(TEST, &[SpecificRegister(RAX), Imm32]),
    InstructionVariation(TEST, &[RegOrMem8, Imm8]),
    InstructionVariation(TEST, &[RegOrMem8, Imm8]),
    InstructionVariation(TEST, &[RegOrMem16, Imm16]),
    InstructionVariation(TEST, &[RegOrMem32, Imm32]),
    InstructionVariation(TEST, &[RegOrMem64, Imm32]),
    InstructionVariation(TEST, &[RegOrMem8, Reg8]),
    InstructionVariation(TEST, &[RegOrMem8, Reg8]),
    InstructionVariation(TEST, &[RegOrMem16, Reg16]),
    InstructionVariation(TEST, &[RegOrMem32, Reg32]),
    InstructionVariation(TEST, &[RegOrMem64, Reg64]),
    InstructionVariation(TZCNT, &[Reg16, RegOrMem16]),
    InstructionVariation(TZCNT, &[Reg32, RegOrMem32]),
    InstructionVariation(TZCNT, &[Reg64, RegOrMem64]),
    InstructionVariation(
        UCOMISD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem64(XMM2)],
    ),
    InstructionVariation(
        VUCOMISD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem64(XMM2)],
    ),
    InstructionVariation(
        VUCOMISD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem64(XMM2)],
    ),
    InstructionVariation(
        UCOMISS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem32(XMM2)],
    ),
    InstructionVariation(
        VUCOMISS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem32(XMM2)],
    ),
    InstructionVariation(
        VUCOMISS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem32(XMM2)],
    ),
    InstructionVariation(UD0, &[]),
    InstructionVariation(UD1, &[Reg32, RegOrMem32]),
    InstructionVariation(UD2, &[]),
    InstructionVariation(
        UNPCKHPD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VUNPCKHPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VUNPCKHPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VUNPCKHPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VUNPCKHPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VUNPCKHPD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        UNPCKHPS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VUNPCKHPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VUNPCKHPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VUNPCKHPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VUNPCKHPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VUNPCKHPS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        UNPCKLPD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VUNPCKLPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VUNPCKLPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VUNPCKLPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VUNPCKLPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VUNPCKLPD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        UNPCKLPS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VUNPCKLPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VUNPCKLPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VUNPCKLPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VUNPCKLPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VUNPCKLPS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VALIGND,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VALIGNQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VALIGND,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VALIGNQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VALIGND,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VALIGNQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VBLENDMPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VBLENDMPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VBLENDMPD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VBLENDMPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VBLENDMPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VBLENDMPS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(VBROADCASTSS, &[SpecificRegister(XMM1), Mem32]),
    InstructionVariation(VBROADCASTSS, &[SpecificRegister(YMM1), Mem32]),
    InstructionVariation(VBROADCASTSD, &[SpecificRegister(YMM1), Mem64]),
    InstructionVariation(VBROADCASTF128, &[SpecificRegister(YMM1), Mem128]),
    InstructionVariation(
        VBROADCASTSS,
        &[SpecificRegister(XMM1), SpecificRegister(XMM2)],
    ),
    InstructionVariation(
        VBROADCASTSS,
        &[SpecificRegister(YMM1), SpecificRegister(XMM2)],
    ),
    InstructionVariation(
        VBROADCASTSD,
        &[SpecificRegister(YMM1), SpecificRegister(XMM2)],
    ),
    InstructionVariation(
        VBROADCASTSD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem64(XMM2),
        ],
    ),
    InstructionVariation(
        VBROADCASTSD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem64(XMM2),
        ],
    ),
    InstructionVariation(
        VBROADCASTF32X2,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem64(XMM2),
        ],
    ),
    InstructionVariation(
        VBROADCASTF32X2,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem64(XMM2),
        ],
    ),
    InstructionVariation(
        VBROADCASTSS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem32(XMM2),
        ],
    ),
    InstructionVariation(
        VBROADCASTSS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem32(XMM2),
        ],
    ),
    InstructionVariation(
        VBROADCASTSS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem32(XMM2),
        ],
    ),
    InstructionVariation(
        VBROADCASTF32X4,
        &[SpecificRegister(YMM1), SpecificRegister(K1), Mem128],
    ),
    InstructionVariation(
        VBROADCASTF32X4,
        &[SpecificRegister(ZMM1), SpecificRegister(K1), Mem128],
    ),
    InstructionVariation(
        VBROADCASTF64X2,
        &[SpecificRegister(YMM1), SpecificRegister(K1), Mem128],
    ),
    InstructionVariation(
        VCOMPRESSPD,
        &[
            SpecificRegisterOrMem128(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
        ],
    ),
    InstructionVariation(
        VCOMPRESSPD,
        &[
            SpecificRegisterOrMem256(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
        ],
    ),
    InstructionVariation(
        VCOMPRESSPD,
        &[
            SpecificRegisterOrMem512(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
        ],
    ),
    InstructionVariation(
        VCOMPRESSPS,
        &[
            SpecificRegisterOrMem128(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
        ],
    ),
    InstructionVariation(
        VCOMPRESSPS,
        &[
            SpecificRegisterOrMem256(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
        ],
    ),
    InstructionVariation(
        VCOMPRESSPS,
        &[
            SpecificRegisterOrMem512(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
        ],
    ),
    InstructionVariation(
        VCVTPD2QQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem64Bcst(XMM2),
        ],
    ),
    InstructionVariation(
        VCVTPD2QQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem64Bcst(YMM2),
        ],
    ),
    InstructionVariation(
        VCVTPD2QQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM2),
        ],
    ),
    InstructionVariation(
        VCVTPD2UDQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem64Bcst(XMM2),
        ],
    ),
    InstructionVariation(
        VCVTPD2UDQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem64Bcst(YMM2),
        ],
    ),
    InstructionVariation(
        VCVTPD2UDQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM2),
        ],
    ),
    InstructionVariation(
        VCVTPD2UQQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem64Bcst(XMM2),
        ],
    ),
    InstructionVariation(
        VCVTPD2UQQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem64Bcst(YMM2),
        ],
    ),
    InstructionVariation(
        VCVTPD2UQQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM2),
        ],
    ),
    InstructionVariation(
        VCVTPH2PS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem64(XMM2)],
    ),
    InstructionVariation(
        VCVTPH2PS,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VCVTPH2PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem64(XMM2),
        ],
    ),
    InstructionVariation(
        VCVTPH2PS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128(XMM2),
        ],
    ),
    InstructionVariation(
        VCVTPH2PS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256(YMM2),
        ],
    ),
    InstructionVariation(
        VCVTPS2PH,
        &[SpecificRegisterOrMem64(XMM1), SpecificRegister(XMM2), Imm8],
    ),
    InstructionVariation(
        VCVTPS2PH,
        &[SpecificRegisterOrMem128(XMM1), SpecificRegister(YMM2), Imm8],
    ),
    InstructionVariation(
        VCVTPS2PH,
        &[
            SpecificRegisterOrMem64(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VCVTPS2PH,
        &[
            SpecificRegisterOrMem128(XMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VCVTPS2PH,
        &[
            SpecificRegisterOrMem256(YMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VCVTPS2QQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem64OrMem32Bcst(XMM2),
        ],
    ),
    InstructionVariation(
        VCVTPS2QQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem32Bcst(XMM2),
        ],
    ),
    InstructionVariation(
        VCVTPS2QQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem32Bcst(YMM2),
        ],
    ),
    InstructionVariation(
        VCVTPS2UDQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem32Bcst(XMM2),
        ],
    ),
    InstructionVariation(
        VCVTPS2UDQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem32Bcst(YMM2),
        ],
    ),
    InstructionVariation(
        VCVTPS2UDQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM2),
        ],
    ),
    InstructionVariation(
        VCVTPS2UQQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem64OrMem32Bcst(XMM2),
        ],
    ),
    InstructionVariation(
        VCVTPS2UQQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem32Bcst(XMM2),
        ],
    ),
    InstructionVariation(
        VCVTPS2UQQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem32Bcst(YMM2),
        ],
    ),
    InstructionVariation(
        VCVTQQ2PD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem64Bcst(XMM2),
        ],
    ),
    InstructionVariation(
        VCVTQQ2PD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem64Bcst(YMM2),
        ],
    ),
    InstructionVariation(
        VCVTQQ2PD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM2),
        ],
    ),
    InstructionVariation(
        VCVTQQ2PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem64Bcst(XMM2),
        ],
    ),
    InstructionVariation(
        VCVTQQ2PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem64Bcst(YMM2),
        ],
    ),
    InstructionVariation(
        VCVTQQ2PS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM2),
        ],
    ),
    InstructionVariation(VCVTSD2USI, &[Reg32, SpecificRegisterOrMem64(XMM1)]),
    InstructionVariation(VCVTSD2USI, &[Reg64, SpecificRegisterOrMem64(XMM1)]),
    InstructionVariation(VCVTSS2USI, &[Reg32, SpecificRegisterOrMem32(XMM1)]),
    InstructionVariation(VCVTSS2USI, &[Reg64, SpecificRegisterOrMem32(XMM1)]),
    InstructionVariation(
        VCVTTPD2QQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem64Bcst(XMM2),
        ],
    ),
    InstructionVariation(
        VCVTTPD2QQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem64Bcst(YMM2),
        ],
    ),
    InstructionVariation(
        VCVTTPD2QQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM2),
        ],
    ),
    InstructionVariation(
        VCVTTPD2UDQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem64Bcst(XMM2),
        ],
    ),
    InstructionVariation(
        VCVTTPD2UDQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem64Bcst(YMM2),
        ],
    ),
    InstructionVariation(
        VCVTTPD2UDQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM2),
        ],
    ),
    InstructionVariation(
        VCVTTPD2UQQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem64Bcst(XMM2),
        ],
    ),
    InstructionVariation(
        VCVTTPD2UQQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem64Bcst(YMM2),
        ],
    ),
    InstructionVariation(
        VCVTTPD2UQQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM2),
        ],
    ),
    InstructionVariation(
        VCVTTPS2QQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem64OrMem32Bcst(XMM2),
        ],
    ),
    InstructionVariation(
        VCVTTPS2QQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem32Bcst(XMM2),
        ],
    ),
    InstructionVariation(
        VCVTTPS2QQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem32Bcst(YMM2),
        ],
    ),
    InstructionVariation(
        VCVTTPS2UDQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem32Bcst(XMM2),
        ],
    ),
    InstructionVariation(
        VCVTTPS2UDQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem32Bcst(YMM2),
        ],
    ),
    InstructionVariation(
        VCVTTPS2UDQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM2),
        ],
    ),
    InstructionVariation(
        VCVTTPS2UQQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem64OrMem32Bcst(XMM2),
        ],
    ),
    InstructionVariation(
        VCVTTPS2UQQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem32Bcst(XMM2),
        ],
    ),
    InstructionVariation(
        VCVTTPS2UQQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem32Bcst(YMM2),
        ],
    ),
    InstructionVariation(VCVTTSD2USI, &[Reg32, SpecificRegisterOrMem64(XMM1)]),
    InstructionVariation(VCVTTSD2USI, &[Reg64, SpecificRegisterOrMem64(XMM1)]),
    InstructionVariation(VCVTTSS2USI, &[Reg32, SpecificRegisterOrMem32(XMM1)]),
    InstructionVariation(VCVTTSS2USI, &[Reg64, SpecificRegisterOrMem32(XMM1)]),
    InstructionVariation(
        VCVTUDQ2PD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem64OrMem32Bcst(XMM2),
        ],
    ),
    InstructionVariation(
        VCVTUDQ2PD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem32Bcst(XMM2),
        ],
    ),
    InstructionVariation(
        VCVTUDQ2PD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem32Bcst(YMM2),
        ],
    ),
    InstructionVariation(
        VCVTUDQ2PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem32Bcst(XMM2),
        ],
    ),
    InstructionVariation(
        VCVTUDQ2PS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem32Bcst(YMM2),
        ],
    ),
    InstructionVariation(
        VCVTUDQ2PS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM2),
        ],
    ),
    InstructionVariation(
        VCVTUQQ2PD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem64Bcst(XMM2),
        ],
    ),
    InstructionVariation(
        VCVTUQQ2PD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem64Bcst(YMM2),
        ],
    ),
    InstructionVariation(
        VCVTUQQ2PD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM2),
        ],
    ),
    InstructionVariation(
        VCVTUQQ2PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem64Bcst(XMM2),
        ],
    ),
    InstructionVariation(
        VCVTUQQ2PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem64Bcst(YMM2),
        ],
    ),
    InstructionVariation(
        VCVTUQQ2PS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM2),
        ],
    ),
    InstructionVariation(
        VCVTUSI2SD,
        &[SpecificRegister(XMM1), SpecificRegister(XMM2), RegOrMem32],
    ),
    InstructionVariation(
        VCVTUSI2SD,
        &[SpecificRegister(XMM1), SpecificRegister(XMM2), RegOrMem64],
    ),
    InstructionVariation(
        VCVTUSI2SS,
        &[SpecificRegister(XMM1), SpecificRegister(XMM2), RegOrMem32],
    ),
    InstructionVariation(
        VCVTUSI2SS,
        &[SpecificRegister(XMM1), SpecificRegister(XMM2), RegOrMem64],
    ),
    InstructionVariation(
        VDBPSADBW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VDBPSADBW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VDBPSADBW,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
            Imm8,
        ],
    ),
    InstructionVariation(VERR, &[RegOrMem16]),
    InstructionVariation(VERW, &[RegOrMem16]),
    InstructionVariation(
        VEXP2PD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM2),
        ],
    ),
    InstructionVariation(
        VEXP2PS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM2),
        ],
    ),
    InstructionVariation(
        VEXPANDPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128(XMM2),
        ],
    ),
    InstructionVariation(
        VEXPANDPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256(YMM2),
        ],
    ),
    InstructionVariation(
        VEXPANDPD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512(ZMM2),
        ],
    ),
    InstructionVariation(
        VEXPANDPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128(XMM2),
        ],
    ),
    InstructionVariation(
        VEXPANDPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256(YMM2),
        ],
    ),
    InstructionVariation(
        VEXPANDPS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512(ZMM2),
        ],
    ),
    InstructionVariation(
        VEXTRACTF128,
        &[SpecificRegisterOrMem128(XMM1), SpecificRegister(YMM2), Imm8],
    ),
    InstructionVariation(
        VEXTRACTF32x4,
        &[
            SpecificRegisterOrMem128(XMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VEXTRACTF64x4,
        &[
            SpecificRegisterOrMem256(YMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VEXTRACTI128,
        &[SpecificRegisterOrMem128(XMM1), SpecificRegister(YMM2), Imm8],
    ),
    InstructionVariation(
        VEXTRACTI32x4,
        &[
            SpecificRegisterOrMem128(XMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VEXTRACTI64x4,
        &[
            SpecificRegisterOrMem256(YMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VFIXUPIMMPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VFIXUPIMMPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VFIXUPIMMPD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VFIXUPIMMPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VFIXUPIMMPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VFIXUPIMMPS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VFIXUPIMMSD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VFIXUPIMMSS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VFMADD132PD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VFMADD213PD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VFMADD231PD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VFMADD132PD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VFMADD213PD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VFMADD231PD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VFMADD132PD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VFMADD213PD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VFMADD231PD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VFMADD132PD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VFMADD213PD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VFMADD231PD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VFMADD132PD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VFMADD213PD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VFMADD231PD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VFMADD132PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VFMADD213PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VFMADD231PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VFMADD132PS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VFMADD213PS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VFMADD231PS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VFMADD132PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VFMADD213PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VFMADD231PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VFMADD132PS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VFMADD213PS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VFMADD231PS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VFMADD132PS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VFMADD213PS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VFMADD231PS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VFMADD132SD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
        ],
    ),
    InstructionVariation(
        VFMADD213SD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
        ],
    ),
    InstructionVariation(
        VFMADD231SD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
        ],
    ),
    InstructionVariation(
        VFMADD132SD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
        ],
    ),
    InstructionVariation(
        VFMADD213SD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
        ],
    ),
    InstructionVariation(
        VFMADD231SD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
        ],
    ),
    InstructionVariation(
        VFMADD132SS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(
        VFMADD213SS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(
        VFMADD231SS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(
        VFMADD132SS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(
        VFMADD213SS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(
        VFMADD231SS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(
        VFMADDSUB132PD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VFMADDSUB213PD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VFMADDSUB231PD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VFMADDSUB132PD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VFMADDSUB213PD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VFMADDSUB231PD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VFMADDSUB213PD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VFMADDSUB231PD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VFMADDSUB132PD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VFMADDSUB213PD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VFMADDSUB231PD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VFMADDSUB132PD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VFMADDSUB213PD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VFMADDSUB231PD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VFMADDSUB132PD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VFMADDSUB132PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VFMADDSUB213PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VFMADDSUB231PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VFMADDSUB132PS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VFMADDSUB213PS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VFMADDSUB231PS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VFMADDSUB213PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VFMADDSUB231PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VFMADDSUB132PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VFMADDSUB213PS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VFMADDSUB231PS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VFMADDSUB132PS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VFMADDSUB213PS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VFMADDSUB231PS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VFMADDSUB132PS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VFMSUB132PD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VFMSUB213PD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VFMSUB231PD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VFMSUB132PD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VFMSUB213PD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VFMSUB231PD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VFMSUB132PD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VFMSUB213PD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VFMSUB231PD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VFMSUB132PD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VFMSUB213PD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VFMSUB231PD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VFMSUB132PD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VFMSUB213PD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VFMSUB231PD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VFMSUB132PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VFMSUB213PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VFMSUB231PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VFMSUB132PS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VFMSUB213PS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VFMSUB231PS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VFMSUB132PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VFMSUB213PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VFMSUB231PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VFMSUB132PS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VFMSUB213PS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VFMSUB231PS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VFMSUB132PS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VFMSUB213PS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VFMSUB231PS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VFMSUB132SD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
        ],
    ),
    InstructionVariation(
        VFMSUB213SD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
        ],
    ),
    InstructionVariation(
        VFMSUB231SD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
        ],
    ),
    InstructionVariation(
        VFMSUB132SD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
        ],
    ),
    InstructionVariation(
        VFMSUB213SD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
        ],
    ),
    InstructionVariation(
        VFMSUB231SD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
        ],
    ),
    InstructionVariation(
        VFMSUB132SS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(
        VFMSUB213SS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(
        VFMSUB231SS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(
        VFMSUB132SS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(
        VFMSUB213SS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(
        VFMSUB231SS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(
        VFMSUBADD132PD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VFMSUBADD213PD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VFMSUBADD231PD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VFMSUBADD132PD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VFMSUBADD213PD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VFMSUBADD231PD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VFMSUBADD132PD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VFMSUBADD213PD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VFMSUBADD231PD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VFMSUBADD132PD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VFMSUBADD213PD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VFMSUBADD231PD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VFMSUBADD132PD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VFMSUBADD213PD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VFMSUBADD231PD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VFMSUBADD132PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VFMSUBADD213PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VFMSUBADD231PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VFMSUBADD132PS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VFMSUBADD213PS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VFMSUBADD231PS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VFMSUBADD132PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VFMSUBADD213PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VFMSUBADD231PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VFMSUBADD132PS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VFMSUBADD213PS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VFMSUBADD231PS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VFMSUBADD132PS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VFMSUBADD213PS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VFMSUBADD231PS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VFNMADD132PD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VFNMADD213PD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VFNMADD231PD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VFNMADD132PD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VFNMADD213PD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VFNMADD231PD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VFNMADD132PD,
        &[
            SpecificRegister(XMM0),
            SpecificRegister(K1),
            SpecificRegister(XMM1),
            SpecificRegisterOrMem128OrMem64Bcst(XMM2),
        ],
    ),
    InstructionVariation(
        VFNMADD213PD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VFNMADD231PD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VFNMADD132PD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VFNMADD213PD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VFNMADD231PD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VFNMADD132PD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VFNMADD213PD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VFNMADD231PD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VFNMADD132PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VFNMADD213PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VFNMADD231PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VFNMADD132PS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VFNMADD213PS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VFNMADD231PS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VFNMADD132PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VFNMADD213PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VFNMADD231PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VFNMADD132PS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VFNMADD213PS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VFNMADD231PS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VFNMADD132PS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VFNMADD213PS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VFNMADD231PS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VFNMADD132SD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
        ],
    ),
    InstructionVariation(
        VFNMADD213SD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
        ],
    ),
    InstructionVariation(
        VFNMADD231SD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
        ],
    ),
    InstructionVariation(
        VFNMADD132SD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
        ],
    ),
    InstructionVariation(
        VFNMADD213SD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
        ],
    ),
    InstructionVariation(
        VFNMADD231SD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
        ],
    ),
    InstructionVariation(
        VFNMADD132SS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(
        VFNMADD213SS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(
        VFNMADD231SS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(
        VFNMADD132SS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(
        VFNMADD213SS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(
        VFNMADD231SS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(
        VFNMSUB132PD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VFNMSUB213PD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VFNMSUB231PD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VFNMSUB132PD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VFNMSUB213PD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VFNMSUB231PD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VFNMSUB132PD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VFNMSUB213PD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VFNMSUB231PD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VFNMSUB132PD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VFNMSUB213PD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VFNMSUB231PD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VFNMSUB132PD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VFNMSUB213PD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VFNMSUB231PD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VFNMSUB132PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VFNMSUB213PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VFNMSUB231PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VFNMSUB132PS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VFNMSUB213PS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VFNMSUB231PS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VFNMSUB132PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VFNMSUB213PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VFNMSUB231PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VFNMSUB132PS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VFNMSUB213PS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VFNMSUB231PS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VFNMSUB132PS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VFNMSUB213PS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VFNMSUB231PS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VFNMSUB132SD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
        ],
    ),
    InstructionVariation(
        VFNMSUB213SD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
        ],
    ),
    InstructionVariation(
        VFNMSUB231SD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
        ],
    ),
    InstructionVariation(
        VFNMSUB132SD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
        ],
    ),
    InstructionVariation(
        VFNMSUB213SD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
        ],
    ),
    InstructionVariation(
        VFNMSUB231SD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
        ],
    ),
    InstructionVariation(
        VFNMSUB132SS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(
        VFNMSUB213SS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(
        VFNMSUB231SS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(
        VFNMSUB132SS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(
        VFNMSUB213SS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(
        VFNMSUB231SS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(
        VFPCLASSPD,
        &[
            SpecificRegister(K2),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem64Bcst(XMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VFPCLASSPD,
        &[
            SpecificRegister(K2),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem64Bcst(YMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VFPCLASSPD,
        &[
            SpecificRegister(K2),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VFPCLASSPS,
        &[
            SpecificRegister(K2),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem32Bcst(XMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VFPCLASSPS,
        &[
            SpecificRegister(K2),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem32Bcst(YMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VFPCLASSPS,
        &[
            SpecificRegister(K2),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VFPCLASSSD,
        &[
            SpecificRegister(K2),
            SpecificRegister(K1),
            SpecificRegisterOrMem64(XMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VFPCLASSSS,
        &[
            SpecificRegister(K2),
            SpecificRegister(K1),
            SpecificRegisterOrMem32(XMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VGATHERDPD,
        &[SpecificRegister(XMM1), Vm32x, SpecificRegister(XMM2)],
    ),
    InstructionVariation(
        VGATHERQPD,
        &[SpecificRegister(XMM1), Vm64x, SpecificRegister(XMM2)],
    ),
    InstructionVariation(
        VGATHERDPD,
        &[SpecificRegister(YMM1), Vm32x, SpecificRegister(YMM2)],
    ),
    InstructionVariation(
        VGATHERQPD,
        &[SpecificRegister(YMM1), Vm64y, SpecificRegister(YMM2)],
    ),
    InstructionVariation(
        VGATHERDPS,
        &[SpecificRegister(XMM1), SpecificRegister(K1), Vm32x],
    ),
    InstructionVariation(
        VGATHERDPS,
        &[SpecificRegister(YMM1), SpecificRegister(K1), Vm32y],
    ),
    InstructionVariation(
        VGATHERDPS,
        &[SpecificRegister(ZMM1), SpecificRegister(K1), Vm32z],
    ),
    InstructionVariation(
        VGATHERDPD,
        &[SpecificRegister(XMM1), SpecificRegister(K1), Vm32x],
    ),
    InstructionVariation(
        VGATHERDPD,
        &[SpecificRegister(YMM1), SpecificRegister(K1), Vm32x],
    ),
    InstructionVariation(
        VGATHERDPD,
        &[SpecificRegister(ZMM1), SpecificRegister(K1), Vm32y],
    ),
    InstructionVariation(
        VGATHERDPS,
        &[SpecificRegister(XMM1), Vm32x, SpecificRegister(XMM2)],
    ),
    InstructionVariation(
        VGATHERQPS,
        &[SpecificRegister(XMM1), Vm64x, SpecificRegister(XMM2)],
    ),
    InstructionVariation(
        VGATHERDPS,
        &[SpecificRegister(YMM1), Vm32y, SpecificRegister(YMM2)],
    ),
    InstructionVariation(
        VGATHERQPS,
        &[SpecificRegister(XMM1), Vm64y, SpecificRegister(XMM2)],
    ),
    InstructionVariation(VGATHERPF0DPS, &[Vm32z, SpecificRegister(K1)]),
    InstructionVariation(VGATHERPF0QPS, &[Vm64z, SpecificRegister(K1)]),
    InstructionVariation(VGATHERPF0DPD, &[Vm32y, SpecificRegister(K1)]),
    InstructionVariation(VGATHERPF0QPD, &[Vm64z, SpecificRegister(K1)]),
    InstructionVariation(VGATHERPF1DPS, &[Vm32z, SpecificRegister(K1)]),
    InstructionVariation(VGATHERPF1QPS, &[Vm64z, SpecificRegister(K1)]),
    InstructionVariation(VGATHERPF1DPD, &[Vm32y, SpecificRegister(K1)]),
    InstructionVariation(VGATHERPF1QPD, &[Vm64z, SpecificRegister(K1)]),
    InstructionVariation(
        VGATHERQPS,
        &[SpecificRegister(XMM1), SpecificRegister(K1), Vm64x],
    ),
    InstructionVariation(
        VGATHERQPS,
        &[SpecificRegister(XMM1), SpecificRegister(K1), Vm64y],
    ),
    InstructionVariation(
        VGATHERQPS,
        &[SpecificRegister(YMM1), SpecificRegister(K1), Vm64z],
    ),
    InstructionVariation(
        VGATHERQPD,
        &[SpecificRegister(XMM1), SpecificRegister(K1), Vm64x],
    ),
    InstructionVariation(
        VGATHERQPD,
        &[SpecificRegister(YMM1), SpecificRegister(K1), Vm64y],
    ),
    InstructionVariation(
        VGATHERQPD,
        &[SpecificRegister(ZMM1), SpecificRegister(K1), Vm64z],
    ),
    InstructionVariation(
        VGETEXPPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem64Bcst(XMM2),
        ],
    ),
    InstructionVariation(
        VGETEXPPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem64Bcst(YMM2),
        ],
    ),
    InstructionVariation(
        VGETEXPPD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM2),
        ],
    ),
    InstructionVariation(
        VGETEXPPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem32Bcst(XMM2),
        ],
    ),
    InstructionVariation(
        VGETEXPPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem32Bcst(YMM2),
        ],
    ),
    InstructionVariation(
        VGETEXPPS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM2),
        ],
    ),
    InstructionVariation(
        VGETEXPSD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
        ],
    ),
    InstructionVariation(
        VGETEXPSS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(
        VGETMANTPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem64Bcst(XMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VGETMANTPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem64Bcst(YMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VGETMANTPD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VGETMANTPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem32Bcst(XMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VGETMANTPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem32Bcst(YMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VGETMANTPS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VGETMANTSD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VGETMANTSS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VINSERTF128,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem128(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VINSERTI128,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem128(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VMASKMOVPS,
        &[SpecificRegister(XMM1), SpecificRegister(XMM2), Mem128],
    ),
    InstructionVariation(
        VMASKMOVPS,
        &[SpecificRegister(YMM1), SpecificRegister(YMM2), Mem256],
    ),
    InstructionVariation(
        VMASKMOVPD,
        &[SpecificRegister(XMM1), SpecificRegister(XMM2), Mem128],
    ),
    InstructionVariation(
        VMASKMOVPD,
        &[SpecificRegister(YMM1), SpecificRegister(YMM2), Mem256],
    ),
    InstructionVariation(
        VMASKMOVPS,
        &[Mem128, SpecificRegister(XMM1), SpecificRegister(XMM2)],
    ),
    InstructionVariation(
        VMASKMOVPS,
        &[Mem256, SpecificRegister(YMM1), SpecificRegister(YMM2)],
    ),
    InstructionVariation(
        VMASKMOVPD,
        &[Mem128, SpecificRegister(XMM1), SpecificRegister(XMM2)],
    ),
    InstructionVariation(
        VMASKMOVPD,
        &[Mem256, SpecificRegister(YMM1), SpecificRegister(YMM2)],
    ),
    InstructionVariation(
        VPBLENDD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPBLENDD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPBLENDMB,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPBLENDMB,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPBLENDMB,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
        ],
    ),
    InstructionVariation(
        VPBLENDMW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPBLENDMW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPBLENDMW,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
        ],
    ),
    InstructionVariation(
        VPBLENDMD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPBLENDMD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPBLENDMD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VPBLENDMQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPBLENDMQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPBLENDMQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VPBROADCASTB,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem8(XMM2)],
    ),
    InstructionVariation(
        VPBROADCASTB,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem8(XMM2)],
    ),
    InstructionVariation(
        VPBROADCASTB,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem8(XMM2),
        ],
    ),
    InstructionVariation(
        VPBROADCASTB,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem8(XMM2),
        ],
    ),
    InstructionVariation(
        VPBROADCASTB,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem8(XMM2),
        ],
    ),
    InstructionVariation(
        VPBROADCASTW,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem16(XMM2)],
    ),
    InstructionVariation(
        VPBROADCASTW,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem16(XMM2)],
    ),
    InstructionVariation(
        VPBROADCASTW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem16(XMM2),
        ],
    ),
    InstructionVariation(
        VPBROADCASTW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem16(XMM2),
        ],
    ),
    InstructionVariation(
        VPBROADCASTW,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem16(XMM2),
        ],
    ),
    InstructionVariation(
        VPBROADCASTD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem32(XMM2)],
    ),
    InstructionVariation(
        VPBROADCASTD,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem32(XMM2)],
    ),
    InstructionVariation(
        VPBROADCASTD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem32(XMM2),
        ],
    ),
    InstructionVariation(
        VPBROADCASTD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem32(XMM2),
        ],
    ),
    InstructionVariation(
        VPBROADCASTD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem32(XMM2),
        ],
    ),
    InstructionVariation(
        VPBROADCASTQ,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem64(XMM2)],
    ),
    InstructionVariation(
        VPBROADCASTQ,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem64(XMM2)],
    ),
    InstructionVariation(
        VPBROADCASTQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem64(XMM2),
        ],
    ),
    InstructionVariation(
        VPBROADCASTQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem64(XMM2),
        ],
    ),
    InstructionVariation(
        VPBROADCASTQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem64(XMM2),
        ],
    ),
    InstructionVariation(
        VBROADCASTI32x2,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem64(XMM2),
        ],
    ),
    InstructionVariation(
        VBROADCASTI32x2,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem64(XMM2),
        ],
    ),
    InstructionVariation(
        VBROADCASTI32x2,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem64(XMM2),
        ],
    ),
    InstructionVariation(VBROADCASTI128, &[SpecificRegister(YMM1), Mem128]),
    InstructionVariation(
        VBROADCASTI32X4,
        &[SpecificRegister(YMM1), SpecificRegister(K1), Mem128],
    ),
    InstructionVariation(
        VBROADCASTI32X4,
        &[SpecificRegister(ZMM1), SpecificRegister(K1), Mem128],
    ),
    InstructionVariation(
        VBROADCASTI64X2,
        &[SpecificRegister(YMM1), SpecificRegister(K1), Mem128],
    ),
    InstructionVariation(
        VBROADCASTI64X2,
        &[SpecificRegister(ZMM1), SpecificRegister(K1), Mem128],
    ),
    InstructionVariation(
        VBROADCASTI32X8,
        &[SpecificRegister(ZMM1), SpecificRegister(K1), Mem256],
    ),
    InstructionVariation(
        VBROADCASTI64X4,
        &[SpecificRegister(ZMM1), SpecificRegister(K1), Mem256],
    ),
    InstructionVariation(
        VPBROADCASTB,
        &[SpecificRegister(XMM1), SpecificRegister(K1), AnyRegister],
    ),
    InstructionVariation(
        VPBROADCASTB,
        &[SpecificRegister(YMM1), SpecificRegister(K1), AnyRegister],
    ),
    InstructionVariation(
        VPBROADCASTB,
        &[SpecificRegister(ZMM1), SpecificRegister(K1), AnyRegister],
    ),
    InstructionVariation(
        VPBROADCASTW,
        &[SpecificRegister(XMM1), SpecificRegister(K1), AnyRegister],
    ),
    InstructionVariation(
        VPBROADCASTW,
        &[SpecificRegister(YMM1), SpecificRegister(K1), AnyRegister],
    ),
    InstructionVariation(
        VPBROADCASTW,
        &[SpecificRegister(ZMM1), SpecificRegister(K1), AnyRegister],
    ),
    InstructionVariation(
        VPBROADCASTD,
        &[SpecificRegister(XMM1), SpecificRegister(K1), Reg32],
    ),
    InstructionVariation(
        VPBROADCASTD,
        &[SpecificRegister(YMM1), SpecificRegister(K1), Reg32],
    ),
    InstructionVariation(
        VPBROADCASTD,
        &[SpecificRegister(ZMM1), SpecificRegister(K1), Reg32],
    ),
    InstructionVariation(
        VPBROADCASTQ,
        &[SpecificRegister(XMM1), SpecificRegister(K1), Reg64],
    ),
    InstructionVariation(
        VPBROADCASTQ,
        &[SpecificRegister(YMM1), SpecificRegister(K1), Reg64],
    ),
    InstructionVariation(
        VPBROADCASTQ,
        &[SpecificRegister(ZMM1), SpecificRegister(K1), Reg64],
    ),
    InstructionVariation(
        VPBROADCASTMB2Q,
        &[SpecificRegister(XMM1), SpecificRegister(K1)],
    ),
    InstructionVariation(
        VPBROADCASTMB2Q,
        &[SpecificRegister(YMM1), SpecificRegister(K1)],
    ),
    InstructionVariation(
        VPBROADCASTMB2Q,
        &[SpecificRegister(ZMM1), SpecificRegister(K1)],
    ),
    InstructionVariation(
        VPBROADCASTMW2D,
        &[SpecificRegister(XMM1), SpecificRegister(K1)],
    ),
    InstructionVariation(
        VPBROADCASTMW2D,
        &[SpecificRegister(YMM1), SpecificRegister(K1)],
    ),
    InstructionVariation(
        VPBROADCASTMW2D,
        &[SpecificRegister(ZMM1), SpecificRegister(K1)],
    ),
    InstructionVariation(
        VPCMPB,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPCMPB,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPCMPB,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPCMPUB,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPCMPUB,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPCMPUB,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPCMPD,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPCMPD,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPCMPD,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPCMPUD,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPCMPUD,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPCMPUD,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPCMPQ,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPCMPQ,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPCMPQ,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPCMPUQ,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPCMPUQ,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPCMPUQ,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPCMPW,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPCMPW,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPCMPW,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPCMPUW,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPCMPUW,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPCMPUW,
        &[
            SpecificRegister(K1),
            SpecificRegister(K2),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPCOMPRESSD,
        &[
            SpecificRegisterOrMem128(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
        ],
    ),
    InstructionVariation(
        VPCOMPRESSD,
        &[
            SpecificRegisterOrMem256(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
        ],
    ),
    InstructionVariation(
        VPCOMPRESSD,
        &[
            SpecificRegisterOrMem512(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
        ],
    ),
    InstructionVariation(
        VPCOMPRESSQ,
        &[
            SpecificRegisterOrMem128(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
        ],
    ),
    InstructionVariation(
        VPCOMPRESSQ,
        &[
            SpecificRegisterOrMem256(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
        ],
    ),
    InstructionVariation(
        VPCOMPRESSQ,
        &[
            SpecificRegisterOrMem512(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
        ],
    ),
    InstructionVariation(
        VPCONFLICTD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem32Bcst(XMM2),
        ],
    ),
    InstructionVariation(
        VPCONFLICTD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem32Bcst(YMM2),
        ],
    ),
    InstructionVariation(
        VPCONFLICTD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM2),
        ],
    ),
    InstructionVariation(
        VPCONFLICTQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem64Bcst(XMM2),
        ],
    ),
    InstructionVariation(
        VPCONFLICTQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem64Bcst(YMM2),
        ],
    ),
    InstructionVariation(
        VPCONFLICTQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM2),
        ],
    ),
    InstructionVariation(
        VPERM2F128,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPERM2I128,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPERMD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPERMD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPERMD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VPERMW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPERMW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPERMW,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
        ],
    ),
    InstructionVariation(
        VPERMI2W,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPERMI2W,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPERMI2W,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
        ],
    ),
    InstructionVariation(
        VPERMI2D,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPERMI2D,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPERMI2D,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VPERMI2Q,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPERMI2Q,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPERMI2Q,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VPERMI2PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPERMI2PS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPERMI2PS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VPERMI2PD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPERMI2PD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPERMI2PD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VPERMILPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPERMILPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPERMILPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPERMILPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPERMILPD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VPERMILPD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2), Imm8],
    ),
    InstructionVariation(
        VPERMILPD,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem256(YMM2), Imm8],
    ),
    InstructionVariation(
        VPERMILPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem64Bcst(XMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPERMILPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem64Bcst(YMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPERMILPD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPERMILPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPERMILPS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2), Imm8],
    ),
    InstructionVariation(
        VPERMILPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPERMILPS,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem256(YMM2), Imm8],
    ),
    InstructionVariation(
        VPERMILPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPERMILPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPERMILPS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VPERMILPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem32Bcst(XMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPERMILPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem32Bcst(YMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPERMILPS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPERMPD,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem256(YMM2), Imm8],
    ),
    InstructionVariation(
        VPERMPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem64Bcst(YMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPERMPD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPERMPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPERMPD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VPERMPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPERMPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPERMPS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VPERMQ,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem256(YMM2), Imm8],
    ),
    InstructionVariation(
        VPERMQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem64Bcst(YMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPERMQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPERMQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPERMQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VPERMT2W,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPERMT2W,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPERMT2W,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
        ],
    ),
    InstructionVariation(
        VPERMT2D,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPERMT2D,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPERMT2D,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VPERMT2Q,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPERMT2Q,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPERMT2Q,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VPERMT2PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPERMT2PS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPERMT2PS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VPERMT2PD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPERMT2PD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPERMT2PD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VPEXPANDD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128(XMM2),
        ],
    ),
    InstructionVariation(
        VPEXPANDD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256(YMM2),
        ],
    ),
    InstructionVariation(
        VPEXPANDD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512(ZMM2),
        ],
    ),
    InstructionVariation(
        VPEXPANDQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128(XMM2),
        ],
    ),
    InstructionVariation(
        VPEXPANDQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256(YMM2),
        ],
    ),
    InstructionVariation(
        VPEXPANDQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512(ZMM2),
        ],
    ),
    InstructionVariation(
        VPGATHERDD,
        &[SpecificRegister(XMM1), SpecificRegister(K1), Vm32x],
    ),
    InstructionVariation(
        VPGATHERDD,
        &[SpecificRegister(YMM1), SpecificRegister(K1), Vm32y],
    ),
    InstructionVariation(
        VPGATHERDD,
        &[SpecificRegister(ZMM1), SpecificRegister(K1), Vm32z],
    ),
    InstructionVariation(
        VPGATHERDQ,
        &[SpecificRegister(XMM1), SpecificRegister(K1), Vm32x],
    ),
    InstructionVariation(
        VPGATHERDQ,
        &[SpecificRegister(YMM1), SpecificRegister(K1), Vm32x],
    ),
    InstructionVariation(
        VPGATHERDQ,
        &[SpecificRegister(ZMM1), SpecificRegister(K1), Vm32y],
    ),
    InstructionVariation(
        VPGATHERDD,
        &[SpecificRegister(XMM1), Vm32x, SpecificRegister(XMM2)],
    ),
    InstructionVariation(
        VPGATHERQD,
        &[SpecificRegister(XMM1), Vm64x, SpecificRegister(XMM2)],
    ),
    InstructionVariation(
        VPGATHERDD,
        &[SpecificRegister(YMM1), Vm32y, SpecificRegister(YMM2)],
    ),
    InstructionVariation(
        VPGATHERQD,
        &[SpecificRegister(XMM1), Vm64y, SpecificRegister(XMM2)],
    ),
    InstructionVariation(
        VPGATHERDQ,
        &[SpecificRegister(XMM1), Vm32x, SpecificRegister(XMM2)],
    ),
    InstructionVariation(
        VPGATHERQQ,
        &[SpecificRegister(XMM1), Vm64x, SpecificRegister(XMM2)],
    ),
    InstructionVariation(
        VPGATHERDQ,
        &[SpecificRegister(YMM1), Vm32x, SpecificRegister(YMM2)],
    ),
    InstructionVariation(
        VPGATHERQQ,
        &[SpecificRegister(YMM1), Vm64y, SpecificRegister(YMM2)],
    ),
    InstructionVariation(
        VPGATHERQD,
        &[SpecificRegister(XMM1), SpecificRegister(K1), Vm64x],
    ),
    InstructionVariation(
        VPGATHERQD,
        &[SpecificRegister(XMM1), SpecificRegister(K1), Vm64y],
    ),
    InstructionVariation(
        VPGATHERQD,
        &[SpecificRegister(YMM1), SpecificRegister(K1), Vm64z],
    ),
    InstructionVariation(
        VPGATHERQQ,
        &[SpecificRegister(XMM1), SpecificRegister(K1), Vm64x],
    ),
    InstructionVariation(
        VPGATHERQQ,
        &[SpecificRegister(YMM1), SpecificRegister(K1), Vm64y],
    ),
    InstructionVariation(
        VPGATHERQQ,
        &[SpecificRegister(ZMM1), SpecificRegister(K1), Vm64z],
    ),
    InstructionVariation(
        VPLZCNTD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem32Bcst(XMM2),
        ],
    ),
    InstructionVariation(
        VPLZCNTD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem32Bcst(YMM2),
        ],
    ),
    InstructionVariation(
        VPLZCNTD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM2),
        ],
    ),
    InstructionVariation(
        VPLZCNTQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem64Bcst(XMM2),
        ],
    ),
    InstructionVariation(
        VPLZCNTQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem64Bcst(YMM2),
        ],
    ),
    InstructionVariation(
        VPLZCNTQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM2),
        ],
    ),
    InstructionVariation(
        VPMASKMOVD,
        &[SpecificRegister(XMM1), SpecificRegister(XMM2), Mem128],
    ),
    InstructionVariation(
        VPMASKMOVD,
        &[SpecificRegister(YMM1), SpecificRegister(YMM2), Mem256],
    ),
    InstructionVariation(
        VPMASKMOVQ,
        &[SpecificRegister(XMM1), SpecificRegister(XMM2), Mem128],
    ),
    InstructionVariation(
        VPMASKMOVQ,
        &[SpecificRegister(YMM1), SpecificRegister(YMM2), Mem256],
    ),
    InstructionVariation(
        VPMASKMOVD,
        &[Mem128, SpecificRegister(XMM1), SpecificRegister(XMM2)],
    ),
    InstructionVariation(
        VPMASKMOVD,
        &[Mem256, SpecificRegister(YMM1), SpecificRegister(YMM2)],
    ),
    InstructionVariation(
        VPMASKMOVQ,
        &[Mem128, SpecificRegister(XMM1), SpecificRegister(XMM2)],
    ),
    InstructionVariation(
        VPMASKMOVQ,
        &[Mem256, SpecificRegister(YMM1), SpecificRegister(YMM2)],
    ),
    InstructionVariation(VPMOVB2M, &[SpecificRegister(K1), SpecificRegister(XMM1)]),
    InstructionVariation(VPMOVB2M, &[SpecificRegister(K1), SpecificRegister(YMM1)]),
    InstructionVariation(VPMOVB2M, &[SpecificRegister(K1), SpecificRegister(ZMM1)]),
    InstructionVariation(VPMOVW2M, &[SpecificRegister(K1), SpecificRegister(XMM1)]),
    InstructionVariation(VPMOVW2M, &[SpecificRegister(K1), SpecificRegister(YMM1)]),
    InstructionVariation(VPMOVW2M, &[SpecificRegister(K1), SpecificRegister(ZMM1)]),
    InstructionVariation(VPMOVD2M, &[SpecificRegister(K1), SpecificRegister(XMM1)]),
    InstructionVariation(VPMOVD2M, &[SpecificRegister(K1), SpecificRegister(YMM1)]),
    InstructionVariation(VPMOVD2M, &[SpecificRegister(K1), SpecificRegister(ZMM1)]),
    InstructionVariation(VPMOVQ2M, &[SpecificRegister(K1), SpecificRegister(XMM1)]),
    InstructionVariation(VPMOVQ2M, &[SpecificRegister(K1), SpecificRegister(YMM1)]),
    InstructionVariation(VPMOVQ2M, &[SpecificRegister(K1), SpecificRegister(ZMM1)]),
    InstructionVariation(
        VPMOVDB,
        &[
            SpecificRegisterOrMem32(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
        ],
    ),
    InstructionVariation(
        VPMOVSDB,
        &[
            SpecificRegisterOrMem32(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
        ],
    ),
    InstructionVariation(
        VPMOVUSDB,
        &[
            SpecificRegisterOrMem32(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
        ],
    ),
    InstructionVariation(
        VPMOVDB,
        &[
            SpecificRegisterOrMem64(XMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
        ],
    ),
    InstructionVariation(
        VPMOVSDB,
        &[
            SpecificRegisterOrMem64(XMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
        ],
    ),
    InstructionVariation(
        VPMOVUSDB,
        &[
            SpecificRegisterOrMem64(XMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
        ],
    ),
    InstructionVariation(
        VPMOVDB,
        &[
            SpecificRegisterOrMem128(XMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
        ],
    ),
    InstructionVariation(
        VPMOVSDB,
        &[
            SpecificRegisterOrMem128(XMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
        ],
    ),
    InstructionVariation(
        VPMOVUSDB,
        &[
            SpecificRegisterOrMem128(XMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
        ],
    ),
    InstructionVariation(
        VPMOVDW,
        &[
            SpecificRegisterOrMem64(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
        ],
    ),
    InstructionVariation(
        VPMOVSDW,
        &[
            SpecificRegisterOrMem64(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
        ],
    ),
    InstructionVariation(
        VPMOVUSDW,
        &[
            SpecificRegisterOrMem64(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
        ],
    ),
    InstructionVariation(
        VPMOVDW,
        &[
            SpecificRegisterOrMem128(XMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
        ],
    ),
    InstructionVariation(
        VPMOVSDW,
        &[
            SpecificRegisterOrMem128(XMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
        ],
    ),
    InstructionVariation(
        VPMOVUSDW,
        &[
            SpecificRegisterOrMem128(XMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
        ],
    ),
    InstructionVariation(
        VPMOVDW,
        &[
            SpecificRegisterOrMem256(YMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
        ],
    ),
    InstructionVariation(
        VPMOVSDW,
        &[
            SpecificRegisterOrMem256(YMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
        ],
    ),
    InstructionVariation(
        VPMOVUSDW,
        &[
            SpecificRegisterOrMem256(YMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
        ],
    ),
    InstructionVariation(VPMOVM2B, &[SpecificRegister(XMM1), SpecificRegister(K1)]),
    InstructionVariation(VPMOVM2B, &[SpecificRegister(YMM1), SpecificRegister(K1)]),
    InstructionVariation(VPMOVM2B, &[SpecificRegister(ZMM1), SpecificRegister(K1)]),
    InstructionVariation(VPMOVM2W, &[SpecificRegister(XMM1), SpecificRegister(K1)]),
    InstructionVariation(VPMOVM2W, &[SpecificRegister(YMM1), SpecificRegister(K1)]),
    InstructionVariation(VPMOVM2W, &[SpecificRegister(ZMM1), SpecificRegister(K1)]),
    InstructionVariation(VPMOVM2D, &[SpecificRegister(XMM1), SpecificRegister(K1)]),
    InstructionVariation(VPMOVM2D, &[SpecificRegister(YMM1), SpecificRegister(K1)]),
    InstructionVariation(VPMOVM2D, &[SpecificRegister(ZMM1), SpecificRegister(K1)]),
    InstructionVariation(VPMOVM2Q, &[SpecificRegister(XMM1), SpecificRegister(K1)]),
    InstructionVariation(VPMOVM2Q, &[SpecificRegister(YMM1), SpecificRegister(K1)]),
    InstructionVariation(VPMOVM2Q, &[SpecificRegister(ZMM1), SpecificRegister(K1)]),
    InstructionVariation(
        VPMOVQB,
        &[
            SpecificRegisterOrMem16(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
        ],
    ),
    InstructionVariation(
        VPMOVSQB,
        &[
            SpecificRegisterOrMem16(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
        ],
    ),
    InstructionVariation(
        VPMOVUSQB,
        &[
            SpecificRegisterOrMem16(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
        ],
    ),
    InstructionVariation(
        VPMOVQB,
        &[
            SpecificRegisterOrMem32(XMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
        ],
    ),
    InstructionVariation(
        VPMOVSQB,
        &[
            SpecificRegisterOrMem32(XMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
        ],
    ),
    InstructionVariation(
        VPMOVUSQB,
        &[
            SpecificRegisterOrMem32(XMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
        ],
    ),
    InstructionVariation(
        VPMOVQB,
        &[
            SpecificRegisterOrMem64(XMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
        ],
    ),
    InstructionVariation(
        VPMOVSQB,
        &[
            SpecificRegisterOrMem64(XMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
        ],
    ),
    InstructionVariation(
        VPMOVUSQB,
        &[
            SpecificRegisterOrMem64(XMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
        ],
    ),
    InstructionVariation(
        VPMOVQD,
        &[
            SpecificRegisterOrMem128(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
        ],
    ),
    InstructionVariation(
        VPMOVSQD,
        &[
            SpecificRegisterOrMem64(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
        ],
    ),
    InstructionVariation(
        VPMOVUSQD,
        &[
            SpecificRegisterOrMem64(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
        ],
    ),
    InstructionVariation(
        VPMOVQD,
        &[
            SpecificRegisterOrMem128(XMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
        ],
    ),
    InstructionVariation(
        VPMOVSQD,
        &[
            SpecificRegisterOrMem128(XMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
        ],
    ),
    InstructionVariation(
        VPMOVUSQD,
        &[
            SpecificRegisterOrMem128(XMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
        ],
    ),
    InstructionVariation(
        VPMOVQD,
        &[
            SpecificRegisterOrMem256(YMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
        ],
    ),
    InstructionVariation(
        VPMOVSQD,
        &[
            SpecificRegisterOrMem256(YMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
        ],
    ),
    InstructionVariation(
        VPMOVUSQD,
        &[
            SpecificRegisterOrMem256(YMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
        ],
    ),
    InstructionVariation(
        VPMOVQW,
        &[
            SpecificRegisterOrMem32(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
        ],
    ),
    InstructionVariation(
        VPMOVSQW,
        &[
            SpecificRegisterOrMem32(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
        ],
    ),
    InstructionVariation(
        VPMOVUSQW,
        &[
            SpecificRegisterOrMem32(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
        ],
    ),
    InstructionVariation(
        VPMOVQW,
        &[
            SpecificRegisterOrMem64(XMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
        ],
    ),
    InstructionVariation(
        VPMOVSQW,
        &[
            SpecificRegisterOrMem64(XMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
        ],
    ),
    InstructionVariation(
        VPMOVUSQW,
        &[
            SpecificRegisterOrMem64(XMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
        ],
    ),
    InstructionVariation(
        VPMOVQW,
        &[
            SpecificRegisterOrMem128(XMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
        ],
    ),
    InstructionVariation(
        VPMOVSQW,
        &[
            SpecificRegisterOrMem128(XMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
        ],
    ),
    InstructionVariation(
        VPMOVUSQW,
        &[
            SpecificRegisterOrMem128(XMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
        ],
    ),
    InstructionVariation(
        VPMOVWB,
        &[
            SpecificRegisterOrMem64(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
        ],
    ),
    InstructionVariation(
        VPMOVSWB,
        &[
            SpecificRegisterOrMem64(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
        ],
    ),
    InstructionVariation(
        VPMOVUSWB,
        &[
            SpecificRegisterOrMem64(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
        ],
    ),
    InstructionVariation(
        VPMOVWB,
        &[
            SpecificRegisterOrMem128(XMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
        ],
    ),
    InstructionVariation(
        VPMOVSWB,
        &[
            SpecificRegisterOrMem128(XMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
        ],
    ),
    InstructionVariation(
        VPMOVUSWB,
        &[
            SpecificRegisterOrMem128(XMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
        ],
    ),
    InstructionVariation(
        VPMOVWB,
        &[
            SpecificRegisterOrMem256(YMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
        ],
    ),
    InstructionVariation(
        VPMOVSWB,
        &[
            SpecificRegisterOrMem256(YMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
        ],
    ),
    InstructionVariation(
        VPMOVUSWB,
        &[
            SpecificRegisterOrMem256(YMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
        ],
    ),
    InstructionVariation(
        VPROLVD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPROLD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem32Bcst(XMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPROLVQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPROLQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem64Bcst(XMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPROLVD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPROLD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem32Bcst(YMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPROLVQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPROLQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem64Bcst(YMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPROLVD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VPROLD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPROLVQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VPROLQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPRORVD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPRORD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem32Bcst(XMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPRORVQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPRORQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem32Bcst(XMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPRORVD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPRORD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem32Bcst(YMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPRORVQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPRORQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem64Bcst(YMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPRORVD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VPRORD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPRORVQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VPRORQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPSCATTERDD,
        &[Vm32x, SpecificRegister(K1), SpecificRegister(XMM1)],
    ),
    InstructionVariation(
        VPSCATTERDD,
        &[Vm32y, SpecificRegister(K1), SpecificRegister(YMM1)],
    ),
    InstructionVariation(
        VPSCATTERDD,
        &[Vm32z, SpecificRegister(K1), SpecificRegister(ZMM1)],
    ),
    InstructionVariation(
        VPSCATTERDQ,
        &[Vm32x, SpecificRegister(K1), SpecificRegister(XMM1)],
    ),
    InstructionVariation(
        VPSCATTERDQ,
        &[Vm32x, SpecificRegister(K1), SpecificRegister(YMM1)],
    ),
    InstructionVariation(
        VPSCATTERDQ,
        &[Vm32y, SpecificRegister(K1), SpecificRegister(ZMM1)],
    ),
    InstructionVariation(
        VPSCATTERQD,
        &[Vm64x, SpecificRegister(K1), SpecificRegister(XMM1)],
    ),
    InstructionVariation(
        VPSCATTERQD,
        &[Vm64y, SpecificRegister(K1), SpecificRegister(XMM1)],
    ),
    InstructionVariation(
        VPSCATTERQD,
        &[Vm64z, SpecificRegister(K1), SpecificRegister(YMM1)],
    ),
    InstructionVariation(
        VPSCATTERQQ,
        &[Vm64x, SpecificRegister(K1), SpecificRegister(XMM1)],
    ),
    InstructionVariation(
        VPSCATTERQQ,
        &[Vm64y, SpecificRegister(K1), SpecificRegister(YMM1)],
    ),
    InstructionVariation(
        VPSCATTERQQ,
        &[Vm64z, SpecificRegister(K1), SpecificRegister(ZMM1)],
    ),
    InstructionVariation(
        VPSLLVD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSLLVQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSLLVD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPSLLVQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPSLLVW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSLLVW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPSLLVW,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
        ],
    ),
    InstructionVariation(
        VPSLLVD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPSLLVD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPSLLVD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VPSLLVQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPSLLVQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPSLLVQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VPSRAVD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSRAVD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPSRAVW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSRAVW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPSRAVW,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
        ],
    ),
    InstructionVariation(
        VPSRAVD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPSRAVD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPSRAVD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VPSRAVQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPSRAVQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPSRAVQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VPSRLVD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSRLVQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSRLVD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPSRLVQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPSRLVW,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPSRLVW,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPSRLVW,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
        ],
    ),
    InstructionVariation(
        VPSRLVD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPSRLVD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPSRLVD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VPSRLVQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPSRLVQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPSRLVQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VPTERNLOGD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPTERNLOGD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPTERNLOGD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPTERNLOGQ,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPTERNLOGQ,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPTERNLOGQ,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VPTESTMB,
        &[
            SpecificRegister(K2),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPTESTMB,
        &[
            SpecificRegister(K2),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPTESTMB,
        &[
            SpecificRegister(K2),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
        ],
    ),
    InstructionVariation(
        VPTESTMW,
        &[
            SpecificRegister(K2),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPTESTMW,
        &[
            SpecificRegister(K2),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPTESTMW,
        &[
            SpecificRegister(K2),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
        ],
    ),
    InstructionVariation(
        VPTESTMD,
        &[
            SpecificRegister(K2),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPTESTMD,
        &[
            SpecificRegister(K2),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPTESTMD,
        &[
            SpecificRegister(K2),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VPTESTMQ,
        &[
            SpecificRegister(K2),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPTESTMQ,
        &[
            SpecificRegister(K2),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPTESTMQ,
        &[
            SpecificRegister(K2),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VPTESTNMB,
        &[
            SpecificRegister(K2),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPTESTNMB,
        &[
            SpecificRegister(K2),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPTESTNMB,
        &[
            SpecificRegister(K2),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
        ],
    ),
    InstructionVariation(
        VPTESTNMW,
        &[
            SpecificRegister(K2),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VPTESTNMW,
        &[
            SpecificRegister(K2),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VPTESTNMW,
        &[
            SpecificRegister(K2),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512(ZMM3),
        ],
    ),
    InstructionVariation(
        VPTESTNMD,
        &[
            SpecificRegister(K2),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPTESTNMD,
        &[
            SpecificRegister(K2),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPTESTNMD,
        &[
            SpecificRegister(K2),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VPTESTNMQ,
        &[
            SpecificRegister(K2),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VPTESTNMQ,
        &[
            SpecificRegister(K2),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VPTESTNMQ,
        &[
            SpecificRegister(K2),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VRANGEPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VRANGEPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VRANGEPD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VRANGEPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VRANGEPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VRANGEPS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VRANGESD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VRANGESS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VRCP14PD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem64Bcst(XMM2),
        ],
    ),
    InstructionVariation(
        VRCP14PD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem64Bcst(YMM2),
        ],
    ),
    InstructionVariation(
        VRCP14PD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM2),
        ],
    ),
    InstructionVariation(
        VRCP14PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem32Bcst(XMM2),
        ],
    ),
    InstructionVariation(
        VRCP14PS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem32Bcst(YMM2),
        ],
    ),
    InstructionVariation(
        VRCP14PS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM2),
        ],
    ),
    InstructionVariation(
        VRCP14SD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
        ],
    ),
    InstructionVariation(
        VRCP14SS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(
        VRCP28PD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM2),
        ],
    ),
    InstructionVariation(
        VRCP28PS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM2),
        ],
    ),
    InstructionVariation(
        VRCP28SD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
        ],
    ),
    InstructionVariation(
        VRCP28SS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(
        VREDUCEPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem64Bcst(XMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VREDUCEPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem64Bcst(YMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VREDUCEPD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VREDUCEPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem32Bcst(XMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VREDUCEPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem32Bcst(YMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VREDUCEPS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VREDUCESD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VREDUCESS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VRNDSCALEPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem64Bcst(XMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VRNDSCALEPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem64Bcst(YMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VRNDSCALEPD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VRNDSCALEPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem32Bcst(XMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VRNDSCALEPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem32Bcst(YMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VRNDSCALEPS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM2),
            Imm8,
        ],
    ),
    InstructionVariation(
        VRNDSCALESD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VRNDSCALESS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VRSQRT14PD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem64Bcst(XMM2),
        ],
    ),
    InstructionVariation(
        VRSQRT14PD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem64Bcst(YMM2),
        ],
    ),
    InstructionVariation(
        VRSQRT14PD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM2),
        ],
    ),
    InstructionVariation(
        VRSQRT14PS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem128OrMem32Bcst(XMM2),
        ],
    ),
    InstructionVariation(
        VRSQRT14PS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem256OrMem32Bcst(YMM2),
        ],
    ),
    InstructionVariation(
        VRSQRT14PS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM2),
        ],
    ),
    InstructionVariation(
        VRSQRT14SD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
        ],
    ),
    InstructionVariation(
        VRSQRT14SS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(
        VRSQRT28PD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM2),
        ],
    ),
    InstructionVariation(
        VRSQRT28PS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM2),
        ],
    ),
    InstructionVariation(
        VRSQRT28SD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
        ],
    ),
    InstructionVariation(
        VRSQRT28SS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(
        VSCALEFPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VSCALEFPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VSCALEFPD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VSCALEFPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VSCALEFPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VSCALEFPS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        VSCALEFSD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem64(XMM3),
        ],
    ),
    InstructionVariation(
        VSCALEFSS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem32(XMM3),
        ],
    ),
    InstructionVariation(
        VSCATTERDPS,
        &[Vm32x, SpecificRegister(K1), SpecificRegister(XMM1)],
    ),
    InstructionVariation(
        VSCATTERDPS,
        &[Vm32y, SpecificRegister(K1), SpecificRegister(YMM1)],
    ),
    InstructionVariation(
        VSCATTERDPS,
        &[Vm32z, SpecificRegister(K1), SpecificRegister(ZMM1)],
    ),
    InstructionVariation(
        VSCATTERDPD,
        &[Vm32x, SpecificRegister(K1), SpecificRegister(XMM1)],
    ),
    InstructionVariation(
        VSCATTERDPD,
        &[Vm32x, SpecificRegister(K1), SpecificRegister(YMM1)],
    ),
    InstructionVariation(
        VSCATTERDPD,
        &[Vm32y, SpecificRegister(K1), SpecificRegister(ZMM1)],
    ),
    InstructionVariation(
        VSCATTERQPS,
        &[Vm64x, SpecificRegister(K1), SpecificRegister(XMM1)],
    ),
    InstructionVariation(
        VSCATTERQPS,
        &[Vm64y, SpecificRegister(K1), SpecificRegister(XMM1)],
    ),
    InstructionVariation(
        VSCATTERQPS,
        &[Vm64z, SpecificRegister(K1), SpecificRegister(YMM1)],
    ),
    InstructionVariation(
        VSCATTERQPD,
        &[Vm64x, SpecificRegister(K1), SpecificRegister(XMM1)],
    ),
    InstructionVariation(
        VSCATTERQPD,
        &[Vm64y, SpecificRegister(K1), SpecificRegister(YMM1)],
    ),
    InstructionVariation(
        VSCATTERQPD,
        &[Vm64z, SpecificRegister(K1), SpecificRegister(ZMM1)],
    ),
    InstructionVariation(VSCATTERPF0DPS, &[Vm32z, SpecificRegister(K1)]),
    InstructionVariation(VSCATTERPF0QPS, &[Vm64z, SpecificRegister(K1)]),
    InstructionVariation(VSCATTERPF0DPD, &[Vm32y, SpecificRegister(K1)]),
    InstructionVariation(VSCATTERPF0QPD, &[Vm64z, SpecificRegister(K1)]),
    InstructionVariation(VSCATTERPF1DPS, &[Vm32z, SpecificRegister(K1)]),
    InstructionVariation(VSCATTERPF1QPS, &[Vm64z, SpecificRegister(K1)]),
    InstructionVariation(VSCATTERPF1DPD, &[Vm32y, SpecificRegister(K1)]),
    InstructionVariation(VSCATTERPF1QPD, &[Vm64z, SpecificRegister(K1)]),
    InstructionVariation(
        VSHUFF32x4,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VSHUFF64x2,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VSHUFI32x4,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VSHUFI64x2,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
            Imm8,
        ],
    ),
    InstructionVariation(
        VTESTPS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VTESTPS,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem256(YMM2)],
    ),
    InstructionVariation(
        VTESTPD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VTESTPD,
        &[SpecificRegister(YMM1), SpecificRegisterOrMem256(YMM2)],
    ),
    InstructionVariation(VZEROALL, &[]),
    InstructionVariation(VZEROUPPER, &[]),
    InstructionVariation(WAIT, &[]),
    InstructionVariation(FWAIT, &[]),
    InstructionVariation(WBINVD, &[]),
    InstructionVariation(WRFSBASE, &[Reg32]),
    InstructionVariation(WRFSBASE, &[Reg64]),
    InstructionVariation(WRGSBASE, &[Reg32]),
    InstructionVariation(WRGSBASE, &[Reg64]),
    InstructionVariation(WRMSR, &[]),
    InstructionVariation(WRPKRU, &[]),
    InstructionVariation(XABORT, &[Imm8]),
    InstructionVariation(XACQUIRE, &[]),
    InstructionVariation(XRELEASE, &[]),
    InstructionVariation(XADD, &[RegOrMem8, Reg8]),
    InstructionVariation(XADD, &[RegOrMem8, Reg8]),
    InstructionVariation(XADD, &[RegOrMem16, Reg16]),
    InstructionVariation(XADD, &[RegOrMem32, Reg32]),
    InstructionVariation(XADD, &[RegOrMem64, Reg64]),
    InstructionVariation(XBEGIN, &[Rel16]),
    InstructionVariation(XBEGIN, &[Rel32]),
    InstructionVariation(XCHG, &[SpecificRegister(AX), Reg16]),
    InstructionVariation(XCHG, &[Reg16, SpecificRegister(AX)]),
    InstructionVariation(XCHG, &[SpecificRegister(EAX), Reg32]),
    InstructionVariation(XCHG, &[SpecificRegister(RAX), Reg64]),
    InstructionVariation(XCHG, &[Reg32, SpecificRegister(EAX)]),
    InstructionVariation(XCHG, &[Reg64, SpecificRegister(RAX)]),
    InstructionVariation(XCHG, &[RegOrMem8, Reg8]),
    InstructionVariation(XCHG, &[RegOrMem8, Reg8]),
    InstructionVariation(XCHG, &[Reg8, RegOrMem8]),
    InstructionVariation(XCHG, &[Reg8, RegOrMem8]),
    InstructionVariation(XCHG, &[RegOrMem16, Reg16]),
    InstructionVariation(XCHG, &[Reg16, RegOrMem16]),
    InstructionVariation(XCHG, &[RegOrMem32, Reg32]),
    InstructionVariation(XCHG, &[RegOrMem64, Reg64]),
    InstructionVariation(XCHG, &[Reg32, RegOrMem32]),
    InstructionVariation(XCHG, &[Reg64, RegOrMem64]),
    InstructionVariation(XEND, &[]),
    InstructionVariation(XGETBV, &[]),
    InstructionVariation(XLAT, &[Mem8]),
    InstructionVariation(XLATB, &[]),
    InstructionVariation(XLATB, &[]),
    InstructionVariation(XOR, &[SpecificRegister(AL), Imm8]),
    InstructionVariation(XOR, &[SpecificRegister(AX), Imm16]),
    InstructionVariation(XOR, &[SpecificRegister(EAX), Imm32]),
    InstructionVariation(XOR, &[SpecificRegister(RAX), Imm32]),
    InstructionVariation(XOR, &[RegOrMem8, Imm8]),
    InstructionVariation(XOR, &[RegOrMem8, Imm8]),
    InstructionVariation(XOR, &[RegOrMem16, Imm16]),
    InstructionVariation(XOR, &[RegOrMem32, Imm32]),
    InstructionVariation(XOR, &[RegOrMem64, Imm32]),
    InstructionVariation(XOR, &[RegOrMem16, Imm8]),
    InstructionVariation(XOR, &[RegOrMem32, Imm8]),
    InstructionVariation(XOR, &[RegOrMem64, Imm8]),
    InstructionVariation(XOR, &[RegOrMem8, Reg8]),
    InstructionVariation(XOR, &[RegOrMem8, Reg8]),
    InstructionVariation(XOR, &[RegOrMem16, Reg16]),
    InstructionVariation(XOR, &[RegOrMem32, Reg32]),
    InstructionVariation(XOR, &[RegOrMem64, Reg64]),
    InstructionVariation(XOR, &[Reg8, RegOrMem8]),
    InstructionVariation(XOR, &[Reg8, RegOrMem8]),
    InstructionVariation(XOR, &[Reg16, RegOrMem16]),
    InstructionVariation(XOR, &[Reg32, RegOrMem32]),
    InstructionVariation(XOR, &[Reg64, RegOrMem64]),
    InstructionVariation(
        XORPD,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VXORPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VXORPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VXORPD,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem64Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VXORPD,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem64Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VXORPD,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem64Bcst(ZMM3),
        ],
    ),
    InstructionVariation(
        XORPS,
        &[SpecificRegister(XMM1), SpecificRegisterOrMem128(XMM2)],
    ),
    InstructionVariation(
        VXORPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128(XMM3),
        ],
    ),
    InstructionVariation(
        VXORPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256(YMM3),
        ],
    ),
    InstructionVariation(
        VXORPS,
        &[
            SpecificRegister(XMM1),
            SpecificRegister(K1),
            SpecificRegister(XMM2),
            SpecificRegisterOrMem128OrMem32Bcst(XMM3),
        ],
    ),
    InstructionVariation(
        VXORPS,
        &[
            SpecificRegister(YMM1),
            SpecificRegister(K1),
            SpecificRegister(YMM2),
            SpecificRegisterOrMem256OrMem32Bcst(YMM3),
        ],
    ),
    InstructionVariation(
        VXORPS,
        &[
            SpecificRegister(ZMM1),
            SpecificRegister(K1),
            SpecificRegister(ZMM2),
            SpecificRegisterOrMem512OrMem32Bcst(ZMM3),
        ],
    ),
    InstructionVariation(XRSTOR, &[Mem]),
    InstructionVariation(XRSTOR64, &[Mem]),
    InstructionVariation(XRSTORS, &[Mem]),
    InstructionVariation(XRSTORS64, &[Mem]),
    InstructionVariation(XSAVE, &[Mem]),
    InstructionVariation(XSAVE64, &[Mem]),
    InstructionVariation(XSAVEC, &[Mem]),
    InstructionVariation(XSAVEC64, &[Mem]),
    InstructionVariation(XSAVEOPT, &[Mem]),
    InstructionVariation(XSAVEOPT64, &[Mem]),
    InstructionVariation(XSAVES, &[Mem]),
    InstructionVariation(XSAVES64, &[Mem]),
    InstructionVariation(XSETBV, &[]),
    InstructionVariation(XTEST, &[]),
];
